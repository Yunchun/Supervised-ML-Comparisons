{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Chess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasnaek/chess\n",
    "chess_df = pd.read_csv('Data/games.csv')\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_ply</th>\n",
       "      <th>winner_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>1500</td>\n",
       "      <td>1191</td>\n",
       "      <td>D10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>B00</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>C20</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>1439</td>\n",
       "      <td>1454</td>\n",
       "      <td>D02</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>1523</td>\n",
       "      <td>1469</td>\n",
       "      <td>C41</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated  turns victory_status  white_rating  black_rating opening_eco  \\\n",
       "0  False     13      outoftime          1500          1191         D10   \n",
       "1   True     16         resign          1322          1261         B00   \n",
       "2   True     61           mate          1496          1500         C20   \n",
       "3   True     61           mate          1439          1454         D02   \n",
       "4   True     95           mate          1523          1469         C41   \n",
       "\n",
       "   opening_ply  winner_white  \n",
       "0            5          True  \n",
       "1            4         False  \n",
       "2            3          True  \n",
       "3            3          True  \n",
       "4            5          True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_df['winner_white'] = chess_df['winner'] == 'white'\n",
    "chess_df = chess_df[['rated', 'turns', 'victory_status',\n",
    "                     'white_rating', 'black_rating', 'opening_eco', 'opening_ply', 'winner_white']]\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_df_X = chess_df.drop(columns=['winner_white'])\n",
    "chess_df_y = chess_df['winner_white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_X_cat_col = ['rated', 'victory_status', 'opening_eco']\n",
    "chess_X = pd.get_dummies(columns=chess_X_cat_col, data=chess_df_X)\n",
    "\n",
    "chess_y = chess_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Mushrooms Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: edible(e), poisonous(p)\n",
    "\n",
    "cap-shape: bell(b), conical(c), convex(x), flat(f), knobbed(k), sunken(s)\n",
    "\n",
    "cap-surface: fibrous(f), grooves(g), scaly(y), smooth(s)\n",
    "\n",
    "cap-color: brown(n), buff(b), cinnamon(c), gray(g), green(r), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "bruises: bruises(t), no(f)\n",
    "\n",
    "odor: almond(a), anise(l), creosote(c), fishy(y), foul(f), musty(m), none(n), pungent(p), spicy(s)\n",
    "\n",
    "gill-attachment: attached(a), descending(d), free(f), notched(n)\n",
    "\n",
    "gill-spacing: close(c), crowded(w), distant(d)\n",
    "\n",
    "gill-size: broad(b), narrow(n)\n",
    "\n",
    "gill-color: black(k), brown(n), buff(b), chocolate(h), gray(g), green(r), orange(o), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-shape: enlarging(e), tapering(t)\n",
    "\n",
    "stalk-root: bulbous(b), club(c), cup(u), equal(e), rhizomorphs(z), rooted(r), missing(?)\n",
    "\n",
    "stalk-surface-above-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-surface-below-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-color-above-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-color-below-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "veil-type: partial(p), universal(u)\n",
    "\n",
    "veil-color: brown(n), orange(o), white(w), yellow(y)\n",
    "\n",
    "ring-number: none(n), one(o), two(t)\n",
    "\n",
    "ring-type: cobwebby(c), evanescent(e), flaring(f), large(l), none(n), pendant(p), sheathing(s), zone(z)\n",
    "\n",
    "spore-print-color: black(k), brown(n), buff(b), chocolate(h), green(r), orange(o), purple(u), white(w), yellow(y)\n",
    "\n",
    "population: abundant(a), clustered(c), numerous(n), scattered(s), several(v), solitary(y)\n",
    "\n",
    "habitat: grasses(g), leaves(l), meadows(m), paths(p), urban(u), waste(w), woods(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/uciml/mushroom-classification\n",
    "shrooms = pd.read_csv('Data/mushrooms.csv')\n",
    "shrooms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_df_X = shrooms.drop(columns=['class'])\n",
    "shrooms_df_y = shrooms['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_X = pd.get_dummies(data=shrooms_df_X)\n",
    "shrooms_y = shrooms_df_y.replace({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Cardio Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Rain Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean BnB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Olympic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree_params = [\n",
    "    {\n",
    "        'max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "        'min_samples_split':[2,3,5,7,10,15,20],\n",
    "        'min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "    }\n",
    "]\n",
    "\n",
    "log_reg_params = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': 10 **np.array(np.arange(-8, 5, 1), dtype='float32')\n",
    "    }\n",
    "]\n",
    "\n",
    "perceptron_params = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_params = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'degree': [2, 3],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "        'gamma': [0.001,0.01,0.1,1,2]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_params = [\n",
    "    {\n",
    "        'n_neighbors': np.arange(1, 106, 4),\n",
    "        'metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "forest_params = [\n",
    "    {\n",
    "        'n_estimators': [1024],\n",
    "        'min_samples_split': [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    }\n",
    "]\n",
    "\n",
    "models_without_svm = {\n",
    "    'tree': (DecisionTreeClassifier(), tree_params),\n",
    "    'log_reg': (LogisticRegression(), log_reg_params),\n",
    "    'perceptron': (Perceptron(), perceptron_params),\n",
    "    'knn': (KNeighborsClassifier(), knn_params),\n",
    "    'forest': (RandomForestClassifier(), forest_params)\n",
    "}\n",
    "\n",
    "models_only_svm = {\n",
    "    'svm': (SVC(), svc_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform trials on dataset\n",
    "def perform_trials(dataset_name, models, data_X, data_y):\n",
    "    results_columns = ['dataset', 'model', 'trial',\n",
    "                       'train_accuracy', 'train_precision', 'train_recall', 'train_specificity',\n",
    "                       'train_f1', 'train_auc', 'train_logloss',\n",
    "                       'test_accuracy', 'test_precision', 'test_recall', 'test_specificity',\n",
    "                       'test_f1', 'test_auc', 'test_logloss']\n",
    "    num_trials = 5\n",
    "    \n",
    "    data_results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "    # perform trials using each model\n",
    "    for model_name in models.keys():\n",
    "        \n",
    "        model = models[model_name][0]\n",
    "        model_params = models[model_name][1]\n",
    "        \n",
    "        train_metrics = np.zeros(7)\n",
    "        test_metrics =  np.zeros(7)\n",
    "        \n",
    "        model_results = pd.DataFrame(columns=results_columns)\n",
    "        \n",
    "        # perform 5 trials on each dataset\n",
    "        for trial_count in range(num_trials):\n",
    "            # pick 5000 samples with replacement to be in the training set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, train_size=5000, random_state=trial_count)\n",
    "            \n",
    "            # grid search with 5 k-folds\n",
    "            search = GridSearchCV(model, model_params, cv=5, verbose=3, n_jobs=-1)\n",
    "            \n",
    "            # find the best parameters for the model\n",
    "            # grid search automatically refits a model on the entire validation set using the best parameters\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # use metrics to evaluate model performance on the test set\n",
    "            y_train_pred = search.predict(X_train)\n",
    "            y_test_pred = search.predict(X_test)\n",
    "            \n",
    "            # compute metrics\n",
    "            model_result = {\n",
    "                'dataset': dataset_name,\n",
    "                'model': model_name,\n",
    "                'trial': trial_count + 1,\n",
    "\n",
    "                'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "                'train_precision': precision_score(y_train, y_train_pred),\n",
    "                'train_recall': recall_score(y_train, y_train_pred),\n",
    "                'train_specificity': recall_score(y_train, y_train_pred, pos_label=0),\n",
    "                'train_f1': f1_score(y_train, y_train_pred),\n",
    "                'train_auc': roc_auc_score(y_train, y_train_pred),\n",
    "                'train_logloss': log_loss(y_train, y_train_pred),\n",
    "\n",
    "                'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "                'test_precision': precision_score(y_test, y_test_pred),\n",
    "                'test_recall': recall_score(y_test, y_test_pred),\n",
    "                'test_specificity': recall_score(y_test, y_test_pred, pos_label=0),\n",
    "                'test_f1': f1_score(y_test, y_test_pred),\n",
    "                'test_auc': roc_auc_score(y_test, y_test_pred),\n",
    "                'test_logloss': log_loss(y_test, y_test_pred)\n",
    "            }\n",
    "            \n",
    "            # append model_result to the model_results dataframe\n",
    "            model_results = model_results.append(model_result, ignore_index=True)\n",
    "        \n",
    "        # append model_results to data_results\n",
    "        data_results = data_results.append(model_results, ignore_index=True)\n",
    "        \n",
    "        avg_result = {\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'trial': 'avg',\n",
    "            \n",
    "            'train_accuracy': model_results.train_accuracy.mean(),\n",
    "            'train_precision': model_results.train_precision.mean(),\n",
    "            'train_recall': model_results.train_recall.mean(),\n",
    "            'train_specificity': model_results.train_specificity.mean(),\n",
    "            'train_f1': model_results.train_f1.mean(),\n",
    "            'train_auc': model_results.train_auc.mean(),\n",
    "            'train_logloss': model_results.train_logloss.mean(),\n",
    "            \n",
    "            'test_accuracy': model_results.test_accuracy.mean(),\n",
    "            'test_precision': model_results.test_precision.mean(),\n",
    "            'test_recall': model_results.test_recall.mean(),\n",
    "            'test_specificity': model_results.test_specificity.mean(),\n",
    "            'test_f1': model_results.test_f1.mean(),\n",
    "            'test_auc': model_results.test_auc.mean(),\n",
    "            'test_logloss': model_results.test_logloss.mean()\n",
    "        }\n",
    "        \n",
    "        # append avg_result to the data_results dataframe\n",
    "        data_results = data_results.append(avg_result, ignore_index=True)\n",
    "    \n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duy Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   22.7s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   21.8s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   22.4s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   22.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   22.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    3.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66640</td>\n",
       "      <td>0.634031</td>\n",
       "      <td>0.762794</td>\n",
       "      <td>0.572892</td>\n",
       "      <td>0.692478</td>\n",
       "      <td>0.667843</td>\n",
       "      <td>11.522309</td>\n",
       "      <td>0.636339</td>\n",
       "      <td>0.615471</td>\n",
       "      <td>0.729274</td>\n",
       "      <td>0.543157</td>\n",
       "      <td>0.667557</td>\n",
       "      <td>0.636216</td>\n",
       "      <td>12.560572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.68960</td>\n",
       "      <td>0.717603</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.757865</td>\n",
       "      <td>0.665661</td>\n",
       "      <td>0.689298</td>\n",
       "      <td>10.720933</td>\n",
       "      <td>0.646035</td>\n",
       "      <td>0.664754</td>\n",
       "      <td>0.585996</td>\n",
       "      <td>0.705804</td>\n",
       "      <td>0.622895</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>12.225624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68180</td>\n",
       "      <td>0.657639</td>\n",
       "      <td>0.757903</td>\n",
       "      <td>0.605758</td>\n",
       "      <td>0.704220</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>10.990396</td>\n",
       "      <td>0.645106</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.731272</td>\n",
       "      <td>0.559555</td>\n",
       "      <td>0.672469</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>12.257795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.658244</td>\n",
       "      <td>0.638409</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>0.654927</td>\n",
       "      <td>11.916010</td>\n",
       "      <td>0.637402</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>0.627396</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>0.633212</td>\n",
       "      <td>0.637380</td>\n",
       "      <td>12.523831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67540</td>\n",
       "      <td>0.645061</td>\n",
       "      <td>0.810493</td>\n",
       "      <td>0.534342</td>\n",
       "      <td>0.718376</td>\n",
       "      <td>0.672418</td>\n",
       "      <td>11.211469</td>\n",
       "      <td>0.648492</td>\n",
       "      <td>0.611398</td>\n",
       "      <td>0.793742</td>\n",
       "      <td>0.506372</td>\n",
       "      <td>0.690739</td>\n",
       "      <td>0.650057</td>\n",
       "      <td>12.140839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67364</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.718066</td>\n",
       "      <td>0.628461</td>\n",
       "      <td>0.685782</td>\n",
       "      <td>0.673263</td>\n",
       "      <td>11.272224</td>\n",
       "      <td>0.642675</td>\n",
       "      <td>0.630636</td>\n",
       "      <td>0.693536</td>\n",
       "      <td>0.592450</td>\n",
       "      <td>0.657374</td>\n",
       "      <td>0.642993</td>\n",
       "      <td>12.341732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67300</td>\n",
       "      <td>0.664283</td>\n",
       "      <td>0.679123</td>\n",
       "      <td>0.667061</td>\n",
       "      <td>0.671621</td>\n",
       "      <td>0.673092</td>\n",
       "      <td>11.294315</td>\n",
       "      <td>0.666423</td>\n",
       "      <td>0.664444</td>\n",
       "      <td>0.674227</td>\n",
       "      <td>0.658598</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>0.666413</td>\n",
       "      <td>11.521472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67220</td>\n",
       "      <td>0.661474</td>\n",
       "      <td>0.699478</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.679945</td>\n",
       "      <td>0.672319</td>\n",
       "      <td>11.321953</td>\n",
       "      <td>0.667087</td>\n",
       "      <td>0.655740</td>\n",
       "      <td>0.700346</td>\n",
       "      <td>0.633978</td>\n",
       "      <td>0.677309</td>\n",
       "      <td>0.667162</td>\n",
       "      <td>11.498545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67180</td>\n",
       "      <td>0.660795</td>\n",
       "      <td>0.705482</td>\n",
       "      <td>0.638145</td>\n",
       "      <td>0.682408</td>\n",
       "      <td>0.671813</td>\n",
       "      <td>11.335771</td>\n",
       "      <td>0.669345</td>\n",
       "      <td>0.655760</td>\n",
       "      <td>0.707945</td>\n",
       "      <td>0.631022</td>\n",
       "      <td>0.680854</td>\n",
       "      <td>0.669483</td>\n",
       "      <td>11.420560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.68160</td>\n",
       "      <td>0.669181</td>\n",
       "      <td>0.712736</td>\n",
       "      <td>0.650737</td>\n",
       "      <td>0.690272</td>\n",
       "      <td>0.681736</td>\n",
       "      <td>10.997287</td>\n",
       "      <td>0.667154</td>\n",
       "      <td>0.651699</td>\n",
       "      <td>0.714856</td>\n",
       "      <td>0.619666</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.667261</td>\n",
       "      <td>11.496257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67120</td>\n",
       "      <td>0.657767</td>\n",
       "      <td>0.742756</td>\n",
       "      <td>0.596484</td>\n",
       "      <td>0.697683</td>\n",
       "      <td>0.669620</td>\n",
       "      <td>11.356508</td>\n",
       "      <td>0.660978</td>\n",
       "      <td>0.637830</td>\n",
       "      <td>0.727676</td>\n",
       "      <td>0.595717</td>\n",
       "      <td>0.679797</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>11.709584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67396</td>\n",
       "      <td>0.662700</td>\n",
       "      <td>0.707915</td>\n",
       "      <td>0.639518</td>\n",
       "      <td>0.684386</td>\n",
       "      <td>0.673716</td>\n",
       "      <td>11.261167</td>\n",
       "      <td>0.666197</td>\n",
       "      <td>0.653095</td>\n",
       "      <td>0.705010</td>\n",
       "      <td>0.627796</td>\n",
       "      <td>0.677816</td>\n",
       "      <td>0.666403</td>\n",
       "      <td>11.529284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53020</td>\n",
       "      <td>0.511988</td>\n",
       "      <td>0.980097</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.672613</td>\n",
       "      <td>0.536936</td>\n",
       "      <td>16.226685</td>\n",
       "      <td>0.543631</td>\n",
       "      <td>0.523701</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.681999</td>\n",
       "      <td>0.543054</td>\n",
       "      <td>15.762773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50280</td>\n",
       "      <td>0.500302</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.666756</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>17.173077</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>0.500901</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.667319</td>\n",
       "      <td>0.504040</td>\n",
       "      <td>17.168862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.52940</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>0.070828</td>\n",
       "      <td>0.987605</td>\n",
       "      <td>0.130772</td>\n",
       "      <td>0.529217</td>\n",
       "      <td>16.253953</td>\n",
       "      <td>0.536326</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.083178</td>\n",
       "      <td>0.986236</td>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.534707</td>\n",
       "      <td>16.014731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.52160</td>\n",
       "      <td>0.510023</td>\n",
       "      <td>0.991563</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.673581</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>16.523730</td>\n",
       "      <td>0.522181</td>\n",
       "      <td>0.510899</td>\n",
       "      <td>0.989084</td>\n",
       "      <td>0.057381</td>\n",
       "      <td>0.673770</td>\n",
       "      <td>0.523233</td>\n",
       "      <td>16.503665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.58340</td>\n",
       "      <td>0.553608</td>\n",
       "      <td>0.952232</td>\n",
       "      <td>0.198283</td>\n",
       "      <td>0.700158</td>\n",
       "      <td>0.575257</td>\n",
       "      <td>14.389168</td>\n",
       "      <td>0.562027</td>\n",
       "      <td>0.531939</td>\n",
       "      <td>0.952733</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>0.682704</td>\n",
       "      <td>0.566236</td>\n",
       "      <td>15.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.53348</td>\n",
       "      <td>0.585376</td>\n",
       "      <td>0.798783</td>\n",
       "      <td>0.269234</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.534009</td>\n",
       "      <td>16.113323</td>\n",
       "      <td>0.533417</td>\n",
       "      <td>0.584916</td>\n",
       "      <td>0.800356</td>\n",
       "      <td>0.268152</td>\n",
       "      <td>0.571486</td>\n",
       "      <td>0.534254</td>\n",
       "      <td>16.115484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66240</td>\n",
       "      <td>0.668701</td>\n",
       "      <td>0.623071</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.645080</td>\n",
       "      <td>0.661811</td>\n",
       "      <td>11.660412</td>\n",
       "      <td>0.633550</td>\n",
       "      <td>0.644213</td>\n",
       "      <td>0.598753</td>\n",
       "      <td>0.668440</td>\n",
       "      <td>0.620652</td>\n",
       "      <td>0.633597</td>\n",
       "      <td>12.656858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.65660</td>\n",
       "      <td>0.667100</td>\n",
       "      <td>0.619124</td>\n",
       "      <td>0.693748</td>\n",
       "      <td>0.642217</td>\n",
       "      <td>0.656436</td>\n",
       "      <td>11.860739</td>\n",
       "      <td>0.639394</td>\n",
       "      <td>0.643665</td>\n",
       "      <td>0.620873</td>\n",
       "      <td>0.657832</td>\n",
       "      <td>0.632064</td>\n",
       "      <td>0.639353</td>\n",
       "      <td>12.455015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.66260</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.678129</td>\n",
       "      <td>0.657183</td>\n",
       "      <td>0.662594</td>\n",
       "      <td>11.653512</td>\n",
       "      <td>0.639859</td>\n",
       "      <td>0.639962</td>\n",
       "      <td>0.633564</td>\n",
       "      <td>0.646109</td>\n",
       "      <td>0.636747</td>\n",
       "      <td>0.639837</td>\n",
       "      <td>12.438964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65720</td>\n",
       "      <td>0.655560</td>\n",
       "      <td>0.656087</td>\n",
       "      <td>0.658303</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.657195</td>\n",
       "      <td>11.840030</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.639719</td>\n",
       "      <td>0.641507</td>\n",
       "      <td>0.640339</td>\n",
       "      <td>0.640611</td>\n",
       "      <td>0.640923</td>\n",
       "      <td>12.402267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65860</td>\n",
       "      <td>0.655527</td>\n",
       "      <td>0.698904</td>\n",
       "      <td>0.616517</td>\n",
       "      <td>0.676521</td>\n",
       "      <td>0.657710</td>\n",
       "      <td>11.791688</td>\n",
       "      <td>0.636672</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>0.595454</td>\n",
       "      <td>0.648867</td>\n",
       "      <td>0.637125</td>\n",
       "      <td>12.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.65948</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.648849</td>\n",
       "      <td>0.669450</td>\n",
       "      <td>0.655365</td>\n",
       "      <td>0.659149</td>\n",
       "      <td>11.761276</td>\n",
       "      <td>0.638079</td>\n",
       "      <td>0.637805</td>\n",
       "      <td>0.634699</td>\n",
       "      <td>0.641635</td>\n",
       "      <td>0.635788</td>\n",
       "      <td>0.638167</td>\n",
       "      <td>12.500438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91820</td>\n",
       "      <td>0.911423</td>\n",
       "      <td>0.923639</td>\n",
       "      <td>0.912924</td>\n",
       "      <td>0.917490</td>\n",
       "      <td>0.918281</td>\n",
       "      <td>2.825307</td>\n",
       "      <td>0.664099</td>\n",
       "      <td>0.659550</td>\n",
       "      <td>0.680196</td>\n",
       "      <td>0.647959</td>\n",
       "      <td>0.669714</td>\n",
       "      <td>0.664077</td>\n",
       "      <td>11.601756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95460</td>\n",
       "      <td>0.947389</td>\n",
       "      <td>0.962234</td>\n",
       "      <td>0.947033</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.954633</td>\n",
       "      <td>1.568082</td>\n",
       "      <td>0.663966</td>\n",
       "      <td>0.658480</td>\n",
       "      <td>0.678115</td>\n",
       "      <td>0.649881</td>\n",
       "      <td>0.668153</td>\n",
       "      <td>0.663998</td>\n",
       "      <td>11.606344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92560</td>\n",
       "      <td>0.920522</td>\n",
       "      <td>0.931573</td>\n",
       "      <td>0.919632</td>\n",
       "      <td>0.926014</td>\n",
       "      <td>0.925602</td>\n",
       "      <td>2.569717</td>\n",
       "      <td>0.666290</td>\n",
       "      <td>0.657590</td>\n",
       "      <td>0.688883</td>\n",
       "      <td>0.643859</td>\n",
       "      <td>0.672873</td>\n",
       "      <td>0.666371</td>\n",
       "      <td>11.526066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95340</td>\n",
       "      <td>0.947619</td>\n",
       "      <td>0.959421</td>\n",
       "      <td>0.947431</td>\n",
       "      <td>0.953484</td>\n",
       "      <td>0.953426</td>\n",
       "      <td>1.609528</td>\n",
       "      <td>0.668349</td>\n",
       "      <td>0.655894</td>\n",
       "      <td>0.705138</td>\n",
       "      <td>0.631725</td>\n",
       "      <td>0.679625</td>\n",
       "      <td>0.668432</td>\n",
       "      <td>11.454966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.97560</td>\n",
       "      <td>0.971318</td>\n",
       "      <td>0.981206</td>\n",
       "      <td>0.969747</td>\n",
       "      <td>0.976237</td>\n",
       "      <td>0.975476</td>\n",
       "      <td>0.842758</td>\n",
       "      <td>0.662439</td>\n",
       "      <td>0.646106</td>\n",
       "      <td>0.701893</td>\n",
       "      <td>0.623834</td>\n",
       "      <td>0.672845</td>\n",
       "      <td>0.662864</td>\n",
       "      <td>11.659111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.94548</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.951615</td>\n",
       "      <td>0.939353</td>\n",
       "      <td>0.945596</td>\n",
       "      <td>0.945484</td>\n",
       "      <td>1.883078</td>\n",
       "      <td>0.665029</td>\n",
       "      <td>0.655524</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.639452</td>\n",
       "      <td>0.672642</td>\n",
       "      <td>0.665148</td>\n",
       "      <td>11.569648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0    chess        tree     1         0.66640         0.634031      0.762794   \n",
       "1    chess        tree     2         0.68960         0.717603      0.620731   \n",
       "2    chess        tree     3         0.68180         0.657639      0.757903   \n",
       "3    chess        tree     4         0.65500         0.658244      0.638409   \n",
       "4    chess        tree     5         0.67540         0.645061      0.810493   \n",
       "5    chess        tree   avg         0.67364         0.662516      0.718066   \n",
       "6    chess     log_reg     1         0.67300         0.664283      0.679123   \n",
       "7    chess     log_reg     2         0.67220         0.661474      0.699478   \n",
       "8    chess     log_reg     3         0.67180         0.660795      0.705482   \n",
       "9    chess     log_reg     4         0.68160         0.669181      0.712736   \n",
       "10   chess     log_reg     5         0.67120         0.657767      0.742756   \n",
       "11   chess     log_reg   avg         0.67396         0.662700      0.707915   \n",
       "12   chess  perceptron     1         0.53020         0.511988      0.980097   \n",
       "13   chess  perceptron     2         0.50280         0.500302      0.999196   \n",
       "14   chess  perceptron     3         0.52940         0.850962      0.070828   \n",
       "15   chess  perceptron     4         0.52160         0.510023      0.991563   \n",
       "16   chess  perceptron     5         0.58340         0.553608      0.952232   \n",
       "17   chess  perceptron   avg         0.53348         0.585376      0.798783   \n",
       "18   chess         knn     1         0.66240         0.668701      0.623071   \n",
       "19   chess         knn     2         0.65660         0.667100      0.619124   \n",
       "20   chess         knn     3         0.66260         0.667630      0.647059   \n",
       "21   chess         knn     4         0.65720         0.655560      0.656087   \n",
       "22   chess         knn     5         0.65860         0.655527      0.698904   \n",
       "23   chess         knn   avg         0.65948         0.662904      0.648849   \n",
       "24   chess      forest     1         0.91820         0.911423      0.923639   \n",
       "25   chess      forest     2         0.95460         0.947389      0.962234   \n",
       "26   chess      forest     3         0.92560         0.920522      0.931573   \n",
       "27   chess      forest     4         0.95340         0.947619      0.959421   \n",
       "28   chess      forest     5         0.97560         0.971318      0.981206   \n",
       "29   chess      forest   avg         0.94548         0.939654      0.951615   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.572892  0.692478   0.667843      11.522309       0.636339   \n",
       "1            0.757865  0.665661   0.689298      10.720933       0.646035   \n",
       "2            0.605758  0.704220   0.681830      10.990396       0.645106   \n",
       "3            0.671446  0.648175   0.654927      11.916010       0.637402   \n",
       "4            0.534342  0.718376   0.672418      11.211469       0.648492   \n",
       "5            0.628461  0.685782   0.673263      11.272224       0.642675   \n",
       "6            0.667061  0.671621   0.673092      11.294315       0.666423   \n",
       "7            0.645161  0.679945   0.672319      11.321953       0.667087   \n",
       "8            0.638145  0.682408   0.671813      11.335771       0.669345   \n",
       "9            0.650737  0.690272   0.681736      10.997287       0.667154   \n",
       "10           0.596484  0.697683   0.669620      11.356508       0.660978   \n",
       "11           0.639518  0.684386   0.673716      11.261167       0.666197   \n",
       "12           0.093775  0.672613   0.536936      16.226685       0.543631   \n",
       "13           0.010753  0.666756   0.504975      17.173077       0.502922   \n",
       "14           0.987605  0.130772   0.529217      16.253953       0.536326   \n",
       "15           0.055755  0.673581   0.523659      16.523730       0.522181   \n",
       "16           0.198283  0.700158   0.575257      14.389168       0.562027   \n",
       "17           0.269234  0.568776   0.534009      16.113323       0.533417   \n",
       "18           0.700552  0.645080   0.661811      11.660412       0.633550   \n",
       "19           0.693748  0.642217   0.656436      11.860739       0.639394   \n",
       "20           0.678129  0.657183   0.662594      11.653512       0.639859   \n",
       "21           0.658303  0.655823   0.657195      11.840030       0.640922   \n",
       "22           0.616517  0.676521   0.657710      11.791688       0.636672   \n",
       "23           0.669450  0.655365   0.659149      11.761276       0.638079   \n",
       "24           0.912924  0.917490   0.918281       2.825307       0.664099   \n",
       "25           0.947033  0.954754   0.954633       1.568082       0.663966   \n",
       "26           0.919632  0.926014   0.925602       2.569717       0.666290   \n",
       "27           0.947431  0.953484   0.953426       1.609528       0.668349   \n",
       "28           0.969747  0.976237   0.975476       0.842758       0.662439   \n",
       "29           0.939353  0.945596   0.945484       1.883078       0.665029   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.615471     0.729274          0.543157  0.667557  0.636216   \n",
       "1         0.664754     0.585996          0.705804  0.622895  0.645900   \n",
       "2         0.622419     0.731272          0.559555  0.672469  0.645413   \n",
       "3         0.639138     0.627396          0.647363  0.633212  0.637380   \n",
       "4         0.611398     0.793742          0.506372  0.690739  0.650057   \n",
       "5         0.630636     0.693536          0.592450  0.657374  0.642993   \n",
       "6         0.664444     0.674227          0.658598  0.669300  0.666413   \n",
       "7         0.655740     0.700346          0.633978  0.677309  0.667162   \n",
       "8         0.655760     0.707945          0.631022  0.680854  0.669483   \n",
       "9         0.651699     0.714856          0.619666  0.681818  0.667261   \n",
       "10        0.637830     0.727676          0.595717  0.679797  0.661696   \n",
       "11        0.653095     0.705010          0.627796  0.677816  0.666403   \n",
       "12        0.523701     0.977451          0.108658  0.681999  0.543054   \n",
       "13        0.500901     0.999334          0.008746  0.667319  0.504040   \n",
       "14        0.857143     0.083178          0.986236  0.151640  0.534707   \n",
       "15        0.510899     0.989084          0.057381  0.673770  0.523233   \n",
       "16        0.531939     0.952733          0.179740  0.682704  0.566236   \n",
       "17        0.584916     0.800356          0.268152  0.571486  0.534254   \n",
       "18        0.644213     0.598753          0.668440  0.620652  0.633597   \n",
       "19        0.643665     0.620873          0.657832  0.632064  0.639353   \n",
       "20        0.639962     0.633564          0.646109  0.636747  0.639837   \n",
       "21        0.639719     0.641507          0.640339  0.640611  0.640923   \n",
       "22        0.621465     0.678797          0.595454  0.648867  0.637125   \n",
       "23        0.637805     0.634699          0.641635  0.635788  0.638167   \n",
       "24        0.659550     0.680196          0.647959  0.669714  0.664077   \n",
       "25        0.658480     0.678115          0.649881  0.668153  0.663998   \n",
       "26        0.657590     0.688883          0.643859  0.672873  0.666371   \n",
       "27        0.655894     0.705138          0.631725  0.679625  0.668432   \n",
       "28        0.646106     0.701893          0.623834  0.672845  0.662864   \n",
       "29        0.655524     0.690845          0.639452  0.672642  0.665148   \n",
       "\n",
       "    test_logloss  \n",
       "0      12.560572  \n",
       "1      12.225624  \n",
       "2      12.257795  \n",
       "3      12.523831  \n",
       "4      12.140839  \n",
       "5      12.341732  \n",
       "6      11.521472  \n",
       "7      11.498545  \n",
       "8      11.420560  \n",
       "9      11.496257  \n",
       "10     11.709584  \n",
       "11     11.529284  \n",
       "12     15.762773  \n",
       "13     17.168862  \n",
       "14     16.014731  \n",
       "15     16.503665  \n",
       "16     15.127389  \n",
       "17     16.115484  \n",
       "18     12.656858  \n",
       "19     12.455015  \n",
       "20     12.438964  \n",
       "21     12.402267  \n",
       "22     12.549084  \n",
       "23     12.500438  \n",
       "24     11.601756  \n",
       "25     11.606344  \n",
       "26     11.526066  \n",
       "27     11.454966  \n",
       "28     11.659111  \n",
       "29     11.569648  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_results_no_svm = perform_trials('chess', models_without_svm, chess_X, chess_y)\n",
    "chess_results_no_svm.to_csv('results/chess_no_svm')\n",
    "chess_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   19.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   21.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   22.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   21.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   21.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    3.5s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 260 | elapsed:    3.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    3.5s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 260 | elapsed:    3.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    3.4s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    3.6s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    3.4s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    0.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   46.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   51.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   52.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   41.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   43.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>2.072327e-02</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>5.527973e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>4.144653e-03</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>1.105595e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.105595e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>2.211189e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   shrooms        tree     1         1.00000              1.0       1.00000   \n",
       "1   shrooms        tree     2         0.99940              1.0       0.99875   \n",
       "2   shrooms        tree     3         1.00000              1.0       1.00000   \n",
       "3   shrooms        tree     4         1.00000              1.0       1.00000   \n",
       "4   shrooms        tree     5         1.00000              1.0       1.00000   \n",
       "5   shrooms        tree   avg         0.99988              1.0       0.99975   \n",
       "6   shrooms     log_reg     1         1.00000              1.0       1.00000   \n",
       "7   shrooms     log_reg     2         1.00000              1.0       1.00000   \n",
       "8   shrooms     log_reg     3         1.00000              1.0       1.00000   \n",
       "9   shrooms     log_reg     4         1.00000              1.0       1.00000   \n",
       "10  shrooms     log_reg     5         1.00000              1.0       1.00000   \n",
       "11  shrooms     log_reg   avg         1.00000              1.0       1.00000   \n",
       "12  shrooms  perceptron     1         1.00000              1.0       1.00000   \n",
       "13  shrooms  perceptron     2         1.00000              1.0       1.00000   \n",
       "14  shrooms  perceptron     3         1.00000              1.0       1.00000   \n",
       "15  shrooms  perceptron     4         1.00000              1.0       1.00000   \n",
       "16  shrooms  perceptron     5         1.00000              1.0       1.00000   \n",
       "17  shrooms  perceptron   avg         1.00000              1.0       1.00000   \n",
       "18  shrooms         knn     1         1.00000              1.0       1.00000   \n",
       "19  shrooms         knn     2         1.00000              1.0       1.00000   \n",
       "20  shrooms         knn     3         1.00000              1.0       1.00000   \n",
       "21  shrooms         knn     4         1.00000              1.0       1.00000   \n",
       "22  shrooms         knn     5         1.00000              1.0       1.00000   \n",
       "23  shrooms         knn   avg         1.00000              1.0       1.00000   \n",
       "24  shrooms      forest     1         1.00000              1.0       1.00000   \n",
       "25  shrooms      forest     2         1.00000              1.0       1.00000   \n",
       "26  shrooms      forest     3         1.00000              1.0       1.00000   \n",
       "27  shrooms      forest     4         1.00000              1.0       1.00000   \n",
       "28  shrooms      forest     5         1.00000              1.0       1.00000   \n",
       "29  shrooms      forest   avg         1.00000              1.0       1.00000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1                 1.0  0.999375   0.999375   2.072327e-02       0.998399   \n",
       "2                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5                 1.0  0.999875   0.999875   4.144653e-03       0.999680   \n",
       "6                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "7                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "8                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "9                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "10                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "11                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "12                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14                1.0  1.000000   1.000000   9.992007e-16       0.999680   \n",
       "15                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "16                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17                1.0  1.000000   1.000000   9.992007e-16       0.999936   \n",
       "18                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "19                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "20                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "21                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "22                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "23                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "24                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "28                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "1              1.0     0.996702               1.0  0.998348  0.998351   \n",
       "2              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "3              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "4              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "5              1.0     0.999340               1.0  0.999670  0.999670   \n",
       "6              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "7              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "8              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "9              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "10             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "11             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "12             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "13             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "14             1.0     0.999316               1.0  0.999658  0.999658   \n",
       "15             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "16             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "17             1.0     0.999863               1.0  0.999932  0.999932   \n",
       "18             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "19             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "20             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "21             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "22             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "23             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "24             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "25             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "26             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "27             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "28             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "29             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   5.527973e-02  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   1.105595e-02  \n",
       "6   9.992007e-16  \n",
       "7   9.992007e-16  \n",
       "8   9.992007e-16  \n",
       "9   9.992007e-16  \n",
       "10  9.992007e-16  \n",
       "11  9.992007e-16  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  1.105595e-02  \n",
       "15  9.992007e-16  \n",
       "16  9.992007e-16  \n",
       "17  2.211189e-03  \n",
       "18  9.992007e-16  \n",
       "19  9.992007e-16  \n",
       "20  9.992007e-16  \n",
       "21  9.992007e-16  \n",
       "22  9.992007e-16  \n",
       "23  9.992007e-16  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  9.992007e-16  \n",
       "28  9.992007e-16  \n",
       "29  9.992007e-16  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_results_no_svm = perform_trials('shrooms', models_without_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_no_svm.to_csv('results/shrooms_no_svm')\n",
    "shrooms_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  8.1min\n"
     ]
    }
   ],
   "source": [
    "chess_results_svm = perform_trials('chess', models_only_svm, chess_X, chess_y)\n",
    "chess_results_svm.to_csv('results/chess_svm')\n",
    "chess_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_svm = perform_trials('shrooms', models_only_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_svm.to_csv('results/shrooms_svm')\n",
    "shrooms_results_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
