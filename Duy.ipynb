{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Chess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasnaek/chess\n",
    "chess_df = pd.read_csv('Data/games.csv')\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_ply</th>\n",
       "      <th>winner_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>1500</td>\n",
       "      <td>1191</td>\n",
       "      <td>other</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>B00</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>C20</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>1439</td>\n",
       "      <td>1454</td>\n",
       "      <td>D02</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>1523</td>\n",
       "      <td>1469</td>\n",
       "      <td>C41</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated  turns victory_status  white_rating  black_rating opening_eco  \\\n",
       "0  False     13      outoftime          1500          1191       other   \n",
       "1   True     16         resign          1322          1261         B00   \n",
       "2   True     61           mate          1496          1500         C20   \n",
       "3   True     61           mate          1439          1454         D02   \n",
       "4   True     95           mate          1523          1469         C41   \n",
       "\n",
       "   opening_ply  winner_white  \n",
       "0            5          True  \n",
       "1            4         False  \n",
       "2            3          True  \n",
       "3            3          True  \n",
       "4            5          True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_df['winner_white'] = chess_df['winner'] == 'white'\n",
    "chess_df = chess_df[['rated', 'turns', 'victory_status',\n",
    "                     'white_rating', 'black_rating', 'opening_eco', 'opening_ply', 'winner_white']]\n",
    "\n",
    "max_openings = 15\n",
    "popular_opennings = chess_df['opening_eco'].value_counts()[:max_openings].index.tolist()\n",
    "def replace_opening(x):\n",
    "    if (x in popular_opennings):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "chess_df['opening_eco'] = chess_df['opening_eco'].apply(replace_opening)\n",
    "\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_df_X = chess_df.drop(columns=['winner_white'])\n",
    "chess_df_y = chess_df['winner_white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_X_cat_col = ['rated', 'victory_status', 'opening_eco']\n",
    "chess_X = pd.get_dummies(columns=chess_X_cat_col, data=chess_df_X)\n",
    "\n",
    "chess_y = chess_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Mushrooms Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: edible(e), poisonous(p)\n",
    "\n",
    "cap-shape: bell(b), conical(c), convex(x), flat(f), knobbed(k), sunken(s)\n",
    "\n",
    "cap-surface: fibrous(f), grooves(g), scaly(y), smooth(s)\n",
    "\n",
    "cap-color: brown(n), buff(b), cinnamon(c), gray(g), green(r), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "bruises: bruises(t), no(f)\n",
    "\n",
    "odor: almond(a), anise(l), creosote(c), fishy(y), foul(f), musty(m), none(n), pungent(p), spicy(s)\n",
    "\n",
    "gill-attachment: attached(a), descending(d), free(f), notched(n)\n",
    "\n",
    "gill-spacing: close(c), crowded(w), distant(d)\n",
    "\n",
    "gill-size: broad(b), narrow(n)\n",
    "\n",
    "gill-color: black(k), brown(n), buff(b), chocolate(h), gray(g), green(r), orange(o), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-shape: enlarging(e), tapering(t)\n",
    "\n",
    "stalk-root: bulbous(b), club(c), cup(u), equal(e), rhizomorphs(z), rooted(r), missing(?)\n",
    "\n",
    "stalk-surface-above-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-surface-below-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-color-above-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-color-below-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "veil-type: partial(p), universal(u)\n",
    "\n",
    "veil-color: brown(n), orange(o), white(w), yellow(y)\n",
    "\n",
    "ring-number: none(n), one(o), two(t)\n",
    "\n",
    "ring-type: cobwebby(c), evanescent(e), flaring(f), large(l), none(n), pendant(p), sheathing(s), zone(z)\n",
    "\n",
    "spore-print-color: black(k), brown(n), buff(b), chocolate(h), green(r), orange(o), purple(u), white(w), yellow(y)\n",
    "\n",
    "population: abundant(a), clustered(c), numerous(n), scattered(s), several(v), solitary(y)\n",
    "\n",
    "habitat: grasses(g), leaves(l), meadows(m), paths(p), urban(u), waste(w), woods(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/uciml/mushroom-classification\n",
    "shrooms = pd.read_csv('Data/mushrooms.csv')\n",
    "shrooms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_df_X = shrooms.drop(columns=['class'])\n",
    "shrooms_df_y = shrooms['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_X = pd.get_dummies(data=shrooms_df_X)\n",
    "shrooms_y = shrooms_df_y.replace({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Cardio Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/sulianova/cardiovascular-disease-dataset, this cardio dataset has 70000 samples and 12 variables, which were collected at the moment of medical examination. It contains a target variable that indicates the presence or absence of cardiovascular disease, as well as 11 features that might be associated with the presence of cardiovascular disease, such as age, gender, and blood pressure. There are 3 types of 11 input features:\n",
    "- objective feature: factual information\n",
    "- examination feature: results of medical examination\n",
    "- subjective feature: information given by the patient\n",
    "\n",
    "A more detailed description of 11 features are shown below:\n",
    "\n",
    "- age: objective feature, int (days)\n",
    "- height: objective feature, int (cm)\n",
    "- weight: objective feature, float (kg)\n",
    "- gender: objective feature, categorical code, 1: male, 2:female\n",
    "- ap_hi: systolic blood pressure, examination feature, int\n",
    "- ap_lo: diastolic blood pressure, examination feature, int\n",
    "- cholesterol: examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- gluc: glucose, examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- smoke: subjective feature, binary, 0: do not smoke, 1: smoke\n",
    "- alco: alcohol intake, subjective feature, binary, 0: do not drink alcohol, 1: drink alcohol\n",
    "- active: physical activity, subjective feature, binary, 0: not physically active, 1: physically active\n",
    "\n",
    "A detailed description of the target variable is shown below: \n",
    "\n",
    "- cardio: presence or absence of cardiovascular disease, binary, 0: disease not present, 1: disease present\n",
    "\n",
    "For this dataset, we want use those 11 input features and apply machine learning algorithms to predict whether a person has cardiovascular disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the cardio dataset\n",
    "cardio = pd.read_csv('data/cardio.csv', delimiter = ';')\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values in cardio dataset\n",
    "cardio.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary column \"id\"\n",
    "cardio = cardio.drop(columns = ['id'])\n",
    "# convert age in days to age in years\n",
    "cardio['age'] = cardio['age'].apply(lambda x: int(x/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding categorical input features stored in cate_cols\n",
    "cate_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "cardio = pd.get_dummies(columns = cate_cols, data = cardio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cardio</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "      <th>smoke_0</th>\n",
       "      <th>smoke_1</th>\n",
       "      <th>alco_0</th>\n",
       "      <th>alco_1</th>\n",
       "      <th>active_0</th>\n",
       "      <th>active_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight  ap_hi  ap_lo  cardio  gender_1  gender_2  \\\n",
       "0   50     168    62.0    110     80       0         0         1   \n",
       "1   55     156    85.0    140     90       1         1         0   \n",
       "2   51     165    64.0    130     70       1         1         0   \n",
       "3   48     169    82.0    150    100       1         0         1   \n",
       "4   47     156    56.0    100     60       0         1         0   \n",
       "\n",
       "   cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  gluc_3  \\\n",
       "0              1              0              0       1       0       0   \n",
       "1              0              0              1       1       0       0   \n",
       "2              0              0              1       1       0       0   \n",
       "3              1              0              0       1       0       0   \n",
       "4              1              0              0       1       0       0   \n",
       "\n",
       "   smoke_0  smoke_1  alco_0  alco_1  active_0  active_1  \n",
       "0        1        0       1       0         0         1  \n",
       "1        1        0       1       0         0         1  \n",
       "2        1        0       1       0         1         0  \n",
       "3        1        0       1       0         0         1  \n",
       "4        1        0       1       0         1         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at cleaned dataset\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the cardio dataset into input features and labels \n",
    "cardio_X = cardio.drop(columns=['cardio']) # input features\n",
    "cardio_y = cardio['cardio'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Rain Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/jsphyg/weather-dataset-rattle-package, this Rain in Australia dataset contains about 10 years of daily weather observations from many locations across Australia. There are 145460 samples and 23 variables in this dataset. It contains a target variable that indicates whether it rained the next day, as well as 22 features that might be associated with the target variable, such as minimum temperature, maximum temperature, rainfall of the day.\n",
    "\n",
    "A more detailed description of 22 features are shown below:\n",
    "\n",
    "- Date: the date of observation\n",
    "- Location: the common name of the location of the weather station\n",
    "- MinTemp: the minimum temperature in degrees celsius\n",
    "- MaxTemp: the maximum temperature in degrees celsius\n",
    "- Rainfall: the amount of rainfall recorded for the day in mm\n",
    "- Evaporation: the so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "- Sunshine: the number of hours of bright sunshine in the day\n",
    "- WindGustDir: the direction of the strongest wind gust in the 24 hours to midnight\n",
    "- WindGustSpeed: the speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "- WindDir9am: direction of the wind at 9am\n",
    "- WindDir3pm: direction of the wind at 3pm\n",
    "- WindSpeed9am: wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "- WindSpeed3pm: wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "- Humidity9am: humidity (percent) at 9am\n",
    "- Humidity3pm: humidity (percent) at 3pm\n",
    "- Pressure9am: atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "- Pressure3pm: atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "- Cloud9am: fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast\n",
    "- Cloud3pm: fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n",
    "- Temp9am: temperature (degrees C) at 9am\n",
    "- Temp3pm: temperature (degrees C) at 3pm\n",
    "- RainToday: whether the precipitation (mm) in the 24 hours to 9am exceeded 1mm, Yes: the precipitation exceeded 1mm, No: it did not exceed 1mm\n",
    "\n",
    "A detailed description of the target variable is shown below: \n",
    "\n",
    "- RainTomorrow: whether amount of next day rain exceeded 1mm, Yes: next day precipitation exceeded 1mm, No: it did not exceed 1mm\n",
    "\n",
    "For this dataset, we want use those 22 input features and apply machine learning algorithms to predict whether it rained the next day or not.\n",
    "\n",
    "Data source: http://www.bom.gov.au/climate/dwo/ and http://www.bom.gov.au/climate/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Australian rain dataset\n",
    "aus = pd.read_csv('Data/weatherAUS.csv')\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the number of missing values in each column\n",
    "aus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in categorical columns with the mode \n",
    "cate_cols = aus.dtypes.index[aus.dtypes == \"object\"].tolist()\n",
    "for cate_col in cate_cols:\n",
    "    aus[cate_col] = aus[cate_col].fillna(aus[cate_col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in numerical columns with the mean\n",
    "num_cols = aus.dtypes.index[aus.dtypes == \"float64\"].tolist()\n",
    "for num_col in num_cols:\n",
    "    aus[num_col] = aus[num_col].fillna(aus[num_col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Location         0\n",
       "MinTemp          0\n",
       "MaxTemp          0\n",
       "Rainfall         0\n",
       "Evaporation      0\n",
       "Sunshine         0\n",
       "WindGustDir      0\n",
       "WindGustSpeed    0\n",
       "WindDir9am       0\n",
       "WindDir3pm       0\n",
       "WindSpeed9am     0\n",
       "WindSpeed3pm     0\n",
       "Humidity9am      0\n",
       "Humidity3pm      0\n",
       "Pressure9am      0\n",
       "Pressure3pm      0\n",
       "Cloud9am         0\n",
       "Cloud3pm         0\n",
       "Temp9am          0\n",
       "Temp3pm          0\n",
       "RainToday        0\n",
       "RainTomorrow     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all missing values are filled\n",
    "aus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the date of each observation into year, month, and day\n",
    "splitted_date = aus['Date'].str.split('-')\n",
    "\n",
    "# create 'Year', 'Month', 'Day' columns using splitted results of the date\n",
    "aus['Year'] = splitted_date.str[0].astype(int)\n",
    "aus['Month'] = splitted_date.str[1].astype(int)\n",
    "aus['Day'] = splitted_date.str[2].astype(int)\n",
    "\n",
    "# drop original 'Date' column\n",
    "aus = aus.drop(columns = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0 and 1 to indicate whether it rained or not\n",
    "# 0: it rained, 1: it did not rain\n",
    "aus['RainToday'] = aus['RainToday'].replace({'No': 0, 'Yes': 1})\n",
    "aus['RainTomorrow'] = aus['RainTomorrow'].replace({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0     13.4     22.9       0.6     5.468232  7.611178           44.0   \n",
       "1      7.4     25.1       0.0     5.468232  7.611178           44.0   \n",
       "2     12.9     25.7       0.0     5.468232  7.611178           46.0   \n",
       "3      9.2     28.0       0.0     5.468232  7.611178           24.0   \n",
       "4     17.5     32.3       1.0     5.468232  7.611178           41.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
       "0          20.0          24.0         71.0         22.0  ...               0   \n",
       "1           4.0          22.0         44.0         25.0  ...               0   \n",
       "2          19.0          26.0         38.0         30.0  ...               0   \n",
       "3          11.0           9.0         45.0         16.0  ...               0   \n",
       "4           7.0          20.0         82.0         33.0  ...               0   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
       "0              0             0              0               0               0   \n",
       "1              0             0              0               0               0   \n",
       "2              0             0              0               0               0   \n",
       "3              0             0              0               0               0   \n",
       "4              1             0              0               0               0   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0              0             0               1               0  \n",
       "1              0             0               0               1  \n",
       "2              0             0               0               1  \n",
       "3              0             0               0               0  \n",
       "4              0             0               0               0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding all categorical columns\n",
    "cate_cols = aus.dtypes.index[aus.dtypes == \"object\"].tolist()\n",
    "aus = pd.get_dummies(columns = cate_cols, data = aus)\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the rain dataset into input features and labels \n",
    "aus_X = aus.drop(columns=['RainTomorrow']) # input features\n",
    "aus_y = aus['RainTomorrow'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean BnB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Olympic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "tree_params = [\n",
    "    {\n",
    "        'max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "        'min_samples_split':[2,3,5,7,10,15,20],\n",
    "        'min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "    }\n",
    "]\n",
    "\n",
    "log_reg_params = [\n",
    "    {\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': 10 **np.array(np.arange(-8, 5, 1), dtype='float32')\n",
    "    }\n",
    "]\n",
    "\n",
    "perceptron_params = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_params = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'degree': [2, 3],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "        'gamma': [0.001,0.01,0.1,1,2]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_params = [\n",
    "    {\n",
    "        'n_neighbors': np.arange(1, 106, 4),\n",
    "        'metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "forest_params = [\n",
    "    {\n",
    "        'n_estimators': [1024],\n",
    "        'min_samples_split': [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    }\n",
    "]\n",
    "\n",
    "models_without_svm = {\n",
    "    'tree': (DecisionTreeClassifier(), tree_params),\n",
    "    'log_reg': (LogisticRegression(), log_reg_params),\n",
    "    'perceptron': (Perceptron(), perceptron_params),\n",
    "    'knn': (KNeighborsClassifier(), knn_params),\n",
    "    'forest': (RandomForestClassifier(), forest_params)\n",
    "}\n",
    "\n",
    "models_only_svm = {\n",
    "    'svm': (SVC(), svc_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform trials on dataset\n",
    "def perform_trials(dataset_name, models, data_X, data_y):\n",
    "    results_columns = ['dataset', 'model', 'trial',\n",
    "                       'train_accuracy', 'train_precision', 'train_recall', 'train_specificity',\n",
    "                       'train_f1', 'train_auc', 'train_logloss',\n",
    "                       'test_accuracy', 'test_precision', 'test_recall', 'test_specificity',\n",
    "                       'test_f1', 'test_auc', 'test_logloss']\n",
    "    num_trials = 5\n",
    "    \n",
    "    data_results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "    # perform trials using each model\n",
    "    for model_name in models.keys():\n",
    "        \n",
    "        model = models[model_name][0]\n",
    "        model_params = models[model_name][1]\n",
    "        \n",
    "        train_metrics = np.zeros(7)\n",
    "        test_metrics =  np.zeros(7)\n",
    "        \n",
    "        model_results = pd.DataFrame(columns=results_columns)\n",
    "        \n",
    "        # perform 5 trials on each dataset\n",
    "        for trial_count in range(num_trials):\n",
    "            # pick 5000 samples with replacement to be in the training set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, train_size=5000, random_state=trial_count)\n",
    "            \n",
    "            # grid search with 5 k-folds\n",
    "            search = GridSearchCV(model, model_params, cv=5, verbose=3, n_jobs=-1)\n",
    "            \n",
    "            # find the best parameters for the model\n",
    "            # grid search automatically refits a model on the entire validation set using the best parameters\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # use metrics to evaluate model performance on the test set\n",
    "            y_train_pred = search.predict(X_train)\n",
    "            y_test_pred = search.predict(X_test)\n",
    "            \n",
    "            # compute metrics\n",
    "            model_result = {\n",
    "                'dataset': dataset_name,\n",
    "                'model': model_name,\n",
    "                'trial': trial_count + 1,\n",
    "\n",
    "                'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "                'train_precision': precision_score(y_train, y_train_pred),\n",
    "                'train_recall': recall_score(y_train, y_train_pred),\n",
    "                'train_specificity': recall_score(y_train, y_train_pred, pos_label=0),\n",
    "                'train_f1': f1_score(y_train, y_train_pred),\n",
    "                'train_auc': roc_auc_score(y_train, y_train_pred),\n",
    "                'train_logloss': log_loss(y_train, y_train_pred),\n",
    "\n",
    "                'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "                'test_precision': precision_score(y_test, y_test_pred),\n",
    "                'test_recall': recall_score(y_test, y_test_pred),\n",
    "                'test_specificity': recall_score(y_test, y_test_pred, pos_label=0),\n",
    "                'test_f1': f1_score(y_test, y_test_pred),\n",
    "                'test_auc': roc_auc_score(y_test, y_test_pred),\n",
    "                'test_logloss': log_loss(y_test, y_test_pred)\n",
    "            }\n",
    "            \n",
    "            # append model_result to the model_results dataframe\n",
    "            model_results = model_results.append(model_result, ignore_index=True)\n",
    "        \n",
    "        # append model_results to data_results\n",
    "        data_results = data_results.append(model_results, ignore_index=True)\n",
    "        \n",
    "        avg_result = {\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'trial': 'avg',\n",
    "            \n",
    "            'train_accuracy': model_results.train_accuracy.mean(),\n",
    "            'train_precision': model_results.train_precision.mean(),\n",
    "            'train_recall': model_results.train_recall.mean(),\n",
    "            'train_specificity': model_results.train_specificity.mean(),\n",
    "            'train_f1': model_results.train_f1.mean(),\n",
    "            'train_auc': model_results.train_auc.mean(),\n",
    "            'train_logloss': model_results.train_logloss.mean(),\n",
    "            \n",
    "            'test_accuracy': model_results.test_accuracy.mean(),\n",
    "            'test_precision': model_results.test_precision.mean(),\n",
    "            'test_recall': model_results.test_recall.mean(),\n",
    "            'test_specificity': model_results.test_specificity.mean(),\n",
    "            'test_f1': model_results.test_f1.mean(),\n",
    "            'test_auc': model_results.test_auc.mean(),\n",
    "            'test_logloss': model_results.test_logloss.mean()\n",
    "        }\n",
    "        \n",
    "        # append avg_result to the data_results dataframe\n",
    "        data_results = data_results.append(avg_result, ignore_index=True)\n",
    "    \n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duy Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 400 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1680 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2435 out of 2450 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2435 out of 2450 | elapsed:   10.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    7.8s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 260 | elapsed:    7.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    7.8s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 260 | elapsed:    7.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    7.4s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    7.8s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 390 out of 405 | elapsed:   11.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 390 out of 405 | elapsed:    9.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 390 out of 405 | elapsed:    9.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 390 out of 405 | elapsed:    9.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 390 out of 405 | elapsed:    9.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   54.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   56.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   54.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   58.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66640</td>\n",
       "      <td>0.634031</td>\n",
       "      <td>0.762794</td>\n",
       "      <td>0.572892</td>\n",
       "      <td>0.692478</td>\n",
       "      <td>0.667843</td>\n",
       "      <td>11.522309</td>\n",
       "      <td>0.636339</td>\n",
       "      <td>0.615471</td>\n",
       "      <td>0.729274</td>\n",
       "      <td>0.543157</td>\n",
       "      <td>0.667557</td>\n",
       "      <td>0.636216</td>\n",
       "      <td>12.560572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.68960</td>\n",
       "      <td>0.717603</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.757865</td>\n",
       "      <td>0.665661</td>\n",
       "      <td>0.689298</td>\n",
       "      <td>10.720933</td>\n",
       "      <td>0.646035</td>\n",
       "      <td>0.664754</td>\n",
       "      <td>0.585996</td>\n",
       "      <td>0.705804</td>\n",
       "      <td>0.622895</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>12.225624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68180</td>\n",
       "      <td>0.657639</td>\n",
       "      <td>0.757903</td>\n",
       "      <td>0.605758</td>\n",
       "      <td>0.704220</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>10.990396</td>\n",
       "      <td>0.645106</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.731272</td>\n",
       "      <td>0.559555</td>\n",
       "      <td>0.672469</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>12.257795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.658244</td>\n",
       "      <td>0.638409</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>0.654927</td>\n",
       "      <td>11.916010</td>\n",
       "      <td>0.637402</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>0.627396</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>0.633212</td>\n",
       "      <td>0.637380</td>\n",
       "      <td>12.523831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67580</td>\n",
       "      <td>0.645645</td>\n",
       "      <td>0.809710</td>\n",
       "      <td>0.535977</td>\n",
       "      <td>0.718430</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>11.197653</td>\n",
       "      <td>0.649489</td>\n",
       "      <td>0.612558</td>\n",
       "      <td>0.792534</td>\n",
       "      <td>0.509526</td>\n",
       "      <td>0.691020</td>\n",
       "      <td>0.651030</td>\n",
       "      <td>12.106432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67372</td>\n",
       "      <td>0.662632</td>\n",
       "      <td>0.717910</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>0.673349</td>\n",
       "      <td>11.269460</td>\n",
       "      <td>0.642874</td>\n",
       "      <td>0.630868</td>\n",
       "      <td>0.693294</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>0.657431</td>\n",
       "      <td>0.643188</td>\n",
       "      <td>12.334851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64680</td>\n",
       "      <td>0.658038</td>\n",
       "      <td>0.588546</td>\n",
       "      <td>0.703310</td>\n",
       "      <td>0.621355</td>\n",
       "      <td>0.645928</td>\n",
       "      <td>12.199216</td>\n",
       "      <td>0.648559</td>\n",
       "      <td>0.670098</td>\n",
       "      <td>0.587081</td>\n",
       "      <td>0.710201</td>\n",
       "      <td>0.625848</td>\n",
       "      <td>0.648641</td>\n",
       "      <td>12.138461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.65640</td>\n",
       "      <td>0.664533</td>\n",
       "      <td>0.625552</td>\n",
       "      <td>0.686977</td>\n",
       "      <td>0.644454</td>\n",
       "      <td>0.656265</td>\n",
       "      <td>11.867649</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>0.649202</td>\n",
       "      <td>0.628461</td>\n",
       "      <td>0.661940</td>\n",
       "      <td>0.638663</td>\n",
       "      <td>0.645201</td>\n",
       "      <td>12.253167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.64820</td>\n",
       "      <td>0.654553</td>\n",
       "      <td>0.627051</td>\n",
       "      <td>0.669332</td>\n",
       "      <td>0.640507</td>\n",
       "      <td>0.648192</td>\n",
       "      <td>12.150874</td>\n",
       "      <td>0.648559</td>\n",
       "      <td>0.651536</td>\n",
       "      <td>0.633298</td>\n",
       "      <td>0.663711</td>\n",
       "      <td>0.642287</td>\n",
       "      <td>0.648504</td>\n",
       "      <td>12.138480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.64560</td>\n",
       "      <td>0.650694</td>\n",
       "      <td>0.621937</td>\n",
       "      <td>0.669056</td>\n",
       "      <td>0.635990</td>\n",
       "      <td>0.645496</td>\n",
       "      <td>12.240675</td>\n",
       "      <td>0.649024</td>\n",
       "      <td>0.651558</td>\n",
       "      <td>0.637247</td>\n",
       "      <td>0.660747</td>\n",
       "      <td>0.644323</td>\n",
       "      <td>0.648997</td>\n",
       "      <td>12.122425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.64900</td>\n",
       "      <td>0.653124</td>\n",
       "      <td>0.667189</td>\n",
       "      <td>0.630008</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>0.648598</td>\n",
       "      <td>12.123255</td>\n",
       "      <td>0.650153</td>\n",
       "      <td>0.641807</td>\n",
       "      <td>0.662146</td>\n",
       "      <td>0.638418</td>\n",
       "      <td>0.651818</td>\n",
       "      <td>0.650282</td>\n",
       "      <td>12.083442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.64920</td>\n",
       "      <td>0.656188</td>\n",
       "      <td>0.626055</td>\n",
       "      <td>0.671737</td>\n",
       "      <td>0.640477</td>\n",
       "      <td>0.648896</td>\n",
       "      <td>12.116334</td>\n",
       "      <td>0.648307</td>\n",
       "      <td>0.652840</td>\n",
       "      <td>0.629646</td>\n",
       "      <td>0.667003</td>\n",
       "      <td>0.640588</td>\n",
       "      <td>0.648325</td>\n",
       "      <td>12.147195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53020</td>\n",
       "      <td>0.511988</td>\n",
       "      <td>0.980097</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.672613</td>\n",
       "      <td>0.536936</td>\n",
       "      <td>16.226685</td>\n",
       "      <td>0.543631</td>\n",
       "      <td>0.523701</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.681999</td>\n",
       "      <td>0.543054</td>\n",
       "      <td>15.762773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50280</td>\n",
       "      <td>0.500302</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.666756</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>17.173077</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>0.500901</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.667319</td>\n",
       "      <td>0.504040</td>\n",
       "      <td>17.168862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.52940</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>0.070828</td>\n",
       "      <td>0.987605</td>\n",
       "      <td>0.130772</td>\n",
       "      <td>0.529217</td>\n",
       "      <td>16.253953</td>\n",
       "      <td>0.536326</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.083178</td>\n",
       "      <td>0.986236</td>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.534707</td>\n",
       "      <td>16.014731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.51660</td>\n",
       "      <td>0.507389</td>\n",
       "      <td>0.993170</td>\n",
       "      <td>0.044205</td>\n",
       "      <td>0.671648</td>\n",
       "      <td>0.518688</td>\n",
       "      <td>16.696428</td>\n",
       "      <td>0.519126</td>\n",
       "      <td>0.509261</td>\n",
       "      <td>0.991880</td>\n",
       "      <td>0.048503</td>\n",
       "      <td>0.672989</td>\n",
       "      <td>0.520191</td>\n",
       "      <td>16.609179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.51420</td>\n",
       "      <td>0.512548</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.677638</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>16.779326</td>\n",
       "      <td>0.498406</td>\n",
       "      <td>0.496464</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>0.663339</td>\n",
       "      <td>0.503802</td>\n",
       "      <td>17.324838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.51864</td>\n",
       "      <td>0.576638</td>\n",
       "      <td>0.808580</td>\n",
       "      <td>0.228739</td>\n",
       "      <td>0.563885</td>\n",
       "      <td>0.518660</td>\n",
       "      <td>16.625894</td>\n",
       "      <td>0.520082</td>\n",
       "      <td>0.577494</td>\n",
       "      <td>0.810207</td>\n",
       "      <td>0.232110</td>\n",
       "      <td>0.567457</td>\n",
       "      <td>0.521159</td>\n",
       "      <td>16.576077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66240</td>\n",
       "      <td>0.668701</td>\n",
       "      <td>0.623071</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.645080</td>\n",
       "      <td>0.661811</td>\n",
       "      <td>11.660412</td>\n",
       "      <td>0.633617</td>\n",
       "      <td>0.644305</td>\n",
       "      <td>0.598753</td>\n",
       "      <td>0.668573</td>\n",
       "      <td>0.620694</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>12.654564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.65460</td>\n",
       "      <td>0.663660</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.641478</td>\n",
       "      <td>0.654452</td>\n",
       "      <td>11.929819</td>\n",
       "      <td>0.639859</td>\n",
       "      <td>0.644688</td>\n",
       "      <td>0.619542</td>\n",
       "      <td>0.660085</td>\n",
       "      <td>0.631865</td>\n",
       "      <td>0.639813</td>\n",
       "      <td>12.438958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.66100</td>\n",
       "      <td>0.665705</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.675730</td>\n",
       "      <td>0.655838</td>\n",
       "      <td>0.660994</td>\n",
       "      <td>11.708775</td>\n",
       "      <td>0.639262</td>\n",
       "      <td>0.639001</td>\n",
       "      <td>0.634231</td>\n",
       "      <td>0.644256</td>\n",
       "      <td>0.636607</td>\n",
       "      <td>0.639244</td>\n",
       "      <td>12.459608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65720</td>\n",
       "      <td>0.655560</td>\n",
       "      <td>0.656087</td>\n",
       "      <td>0.658303</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.657195</td>\n",
       "      <td>11.840030</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.639719</td>\n",
       "      <td>0.641507</td>\n",
       "      <td>0.640339</td>\n",
       "      <td>0.640611</td>\n",
       "      <td>0.640923</td>\n",
       "      <td>12.402267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65280</td>\n",
       "      <td>0.651706</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>0.616108</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.652024</td>\n",
       "      <td>11.992013</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.623028</td>\n",
       "      <td>0.678663</td>\n",
       "      <td>0.598213</td>\n",
       "      <td>0.649656</td>\n",
       "      <td>0.638438</td>\n",
       "      <td>12.503209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.65760</td>\n",
       "      <td>0.661066</td>\n",
       "      <td>0.646818</td>\n",
       "      <td>0.667773</td>\n",
       "      <td>0.653510</td>\n",
       "      <td>0.657295</td>\n",
       "      <td>11.826210</td>\n",
       "      <td>0.638332</td>\n",
       "      <td>0.638148</td>\n",
       "      <td>0.634539</td>\n",
       "      <td>0.642293</td>\n",
       "      <td>0.635887</td>\n",
       "      <td>0.638416</td>\n",
       "      <td>12.491721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87920</td>\n",
       "      <td>0.867194</td>\n",
       "      <td>0.891145</td>\n",
       "      <td>0.867612</td>\n",
       "      <td>0.879006</td>\n",
       "      <td>0.879379</td>\n",
       "      <td>4.172338</td>\n",
       "      <td>0.673330</td>\n",
       "      <td>0.666540</td>\n",
       "      <td>0.695450</td>\n",
       "      <td>0.651150</td>\n",
       "      <td>0.680688</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>11.282929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91320</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.922057</td>\n",
       "      <td>0.904421</td>\n",
       "      <td>0.913615</td>\n",
       "      <td>0.913239</td>\n",
       "      <td>2.998004</td>\n",
       "      <td>0.670408</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.685570</td>\n",
       "      <td>0.655314</td>\n",
       "      <td>0.674835</td>\n",
       "      <td>0.670442</td>\n",
       "      <td>11.383851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.88580</td>\n",
       "      <td>0.878039</td>\n",
       "      <td>0.895958</td>\n",
       "      <td>0.875650</td>\n",
       "      <td>0.886908</td>\n",
       "      <td>0.885804</td>\n",
       "      <td>3.944378</td>\n",
       "      <td>0.674326</td>\n",
       "      <td>0.665393</td>\n",
       "      <td>0.696614</td>\n",
       "      <td>0.652197</td>\n",
       "      <td>0.680646</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>11.248523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.88780</td>\n",
       "      <td>0.881933</td>\n",
       "      <td>0.894335</td>\n",
       "      <td>0.881322</td>\n",
       "      <td>0.888091</td>\n",
       "      <td>0.887829</td>\n",
       "      <td>3.875298</td>\n",
       "      <td>0.672998</td>\n",
       "      <td>0.660109</td>\n",
       "      <td>0.710197</td>\n",
       "      <td>0.635966</td>\n",
       "      <td>0.684238</td>\n",
       "      <td>0.673082</td>\n",
       "      <td>11.294404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93660</td>\n",
       "      <td>0.927398</td>\n",
       "      <td>0.950274</td>\n",
       "      <td>0.922322</td>\n",
       "      <td>0.938697</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>2.189789</td>\n",
       "      <td>0.667286</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.709413</td>\n",
       "      <td>0.626068</td>\n",
       "      <td>0.678351</td>\n",
       "      <td>0.667740</td>\n",
       "      <td>11.491669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.90052</td>\n",
       "      <td>0.891978</td>\n",
       "      <td>0.910754</td>\n",
       "      <td>0.890265</td>\n",
       "      <td>0.901263</td>\n",
       "      <td>0.900510</td>\n",
       "      <td>3.435961</td>\n",
       "      <td>0.671670</td>\n",
       "      <td>0.661274</td>\n",
       "      <td>0.699449</td>\n",
       "      <td>0.644139</td>\n",
       "      <td>0.679751</td>\n",
       "      <td>0.671794</td>\n",
       "      <td>11.340275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0    chess        tree     1         0.66640         0.634031      0.762794   \n",
       "1    chess        tree     2         0.68960         0.717603      0.620731   \n",
       "2    chess        tree     3         0.68180         0.657639      0.757903   \n",
       "3    chess        tree     4         0.65500         0.658244      0.638409   \n",
       "4    chess        tree     5         0.67580         0.645645      0.809710   \n",
       "5    chess        tree   avg         0.67372         0.662632      0.717910   \n",
       "6    chess     log_reg     1         0.64680         0.658038      0.588546   \n",
       "7    chess     log_reg     2         0.65640         0.664533      0.625552   \n",
       "8    chess     log_reg     3         0.64820         0.654553      0.627051   \n",
       "9    chess     log_reg     4         0.64560         0.650694      0.621937   \n",
       "10   chess     log_reg     5         0.64900         0.653124      0.667189   \n",
       "11   chess     log_reg   avg         0.64920         0.656188      0.626055   \n",
       "12   chess  perceptron     1         0.53020         0.511988      0.980097   \n",
       "13   chess  perceptron     2         0.50280         0.500302      0.999196   \n",
       "14   chess  perceptron     3         0.52940         0.850962      0.070828   \n",
       "15   chess  perceptron     4         0.51660         0.507389      0.993170   \n",
       "16   chess  perceptron     5         0.51420         0.512548      0.999608   \n",
       "17   chess  perceptron   avg         0.51864         0.576638      0.808580   \n",
       "18   chess         knn     1         0.66240         0.668701      0.623071   \n",
       "19   chess         knn     2         0.65460         0.663660      0.620731   \n",
       "20   chess         knn     3         0.66100         0.665705      0.646259   \n",
       "21   chess         knn     4         0.65720         0.655560      0.656087   \n",
       "22   chess         knn     5         0.65280         0.651706      0.687940   \n",
       "23   chess         knn   avg         0.65760         0.661066      0.646818   \n",
       "24   chess      forest     1         0.87920         0.867194      0.891145   \n",
       "25   chess      forest     2         0.91320         0.905325      0.922057   \n",
       "26   chess      forest     3         0.88580         0.878039      0.895958   \n",
       "27   chess      forest     4         0.88780         0.881933      0.894335   \n",
       "28   chess      forest     5         0.93660         0.927398      0.950274   \n",
       "29   chess      forest   avg         0.90052         0.891978      0.910754   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.572892  0.692478   0.667843      11.522309       0.636339   \n",
       "1            0.757865  0.665661   0.689298      10.720933       0.646035   \n",
       "2            0.605758  0.704220   0.681830      10.990396       0.645106   \n",
       "3            0.671446  0.648175   0.654927      11.916010       0.637402   \n",
       "4            0.535977  0.718430   0.672844      11.197653       0.649489   \n",
       "5            0.628788  0.685793   0.673349      11.269460       0.642874   \n",
       "6            0.703310  0.621355   0.645928      12.199216       0.648559   \n",
       "7            0.686977  0.644454   0.656265      11.867649       0.645238   \n",
       "8            0.669332  0.640507   0.648192      12.150874       0.648559   \n",
       "9            0.669056  0.635990   0.645496      12.240675       0.649024   \n",
       "10           0.630008  0.660081   0.648598      12.123255       0.650153   \n",
       "11           0.671737  0.640477   0.648896      12.116334       0.648307   \n",
       "12           0.093775  0.672613   0.536936      16.226685       0.543631   \n",
       "13           0.010753  0.666756   0.504975      17.173077       0.502922   \n",
       "14           0.987605  0.130772   0.529217      16.253953       0.536326   \n",
       "15           0.044205  0.671648   0.518688      16.696428       0.519126   \n",
       "16           0.007359  0.677638   0.503484      16.779326       0.498406   \n",
       "17           0.228739  0.563885   0.518660      16.625894       0.520082   \n",
       "18           0.700552  0.645080   0.661811      11.660412       0.633617   \n",
       "19           0.688172  0.641478   0.654452      11.929819       0.639859   \n",
       "20           0.675730  0.655838   0.660994      11.708775       0.639262   \n",
       "21           0.658303  0.655823   0.657195      11.840030       0.640922   \n",
       "22           0.616108  0.669333   0.652024      11.992013       0.638000   \n",
       "23           0.667773  0.653510   0.657295      11.826210       0.638332   \n",
       "24           0.867612  0.879006   0.879379       4.172338       0.673330   \n",
       "25           0.904421  0.913615   0.913239       2.998004       0.670408   \n",
       "26           0.875650  0.886908   0.885804       3.944378       0.674326   \n",
       "27           0.881322  0.888091   0.887829       3.875298       0.672998   \n",
       "28           0.922322  0.938697   0.936298       2.189789       0.667286   \n",
       "29           0.890265  0.901263   0.900510       3.435961       0.671670   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.615471     0.729274          0.543157  0.667557  0.636216   \n",
       "1         0.664754     0.585996          0.705804  0.622895  0.645900   \n",
       "2         0.622419     0.731272          0.559555  0.672469  0.645413   \n",
       "3         0.639138     0.627396          0.647363  0.633212  0.637380   \n",
       "4         0.612558     0.792534          0.509526  0.691020  0.651030   \n",
       "5         0.630868     0.693294          0.593081  0.657431  0.643188   \n",
       "6         0.670098     0.587081          0.710201  0.625848  0.648641   \n",
       "7         0.649202     0.628461          0.661940  0.638663  0.645201   \n",
       "8         0.651536     0.633298          0.663711  0.642287  0.648504   \n",
       "9         0.651558     0.637247          0.660747  0.644323  0.648997   \n",
       "10        0.641807     0.662146          0.638418  0.651818  0.650282   \n",
       "11        0.652840     0.629646          0.667003  0.640588  0.648325   \n",
       "12        0.523701     0.977451          0.108658  0.681999  0.543054   \n",
       "13        0.500901     0.999334          0.008746  0.667319  0.504040   \n",
       "14        0.857143     0.083178          0.986236  0.151640  0.534707   \n",
       "15        0.509261     0.991880          0.048503  0.672989  0.520191   \n",
       "16        0.496464     0.999194          0.008409  0.663339  0.503802   \n",
       "17        0.577494     0.810207          0.232110  0.567457  0.521159   \n",
       "18        0.644305     0.598753          0.668573  0.620694  0.633663   \n",
       "19        0.644688     0.619542          0.660085  0.631865  0.639813   \n",
       "20        0.639001     0.634231          0.644256  0.636607  0.639244   \n",
       "21        0.639719     0.641507          0.640339  0.640611  0.640923   \n",
       "22        0.623028     0.678663          0.598213  0.649656  0.638438   \n",
       "23        0.638148     0.634539          0.642293  0.635887  0.638416   \n",
       "24        0.666540     0.695450          0.651150  0.680688  0.673300   \n",
       "25        0.664430     0.685570          0.655314  0.674835  0.670442   \n",
       "26        0.665393     0.696614          0.652197  0.680646  0.674406   \n",
       "27        0.660109     0.710197          0.635966  0.684238  0.673082   \n",
       "28        0.649895     0.709413          0.626068  0.678351  0.667740   \n",
       "29        0.661274     0.699449          0.644139  0.679751  0.671794   \n",
       "\n",
       "    test_logloss  \n",
       "0      12.560572  \n",
       "1      12.225624  \n",
       "2      12.257795  \n",
       "3      12.523831  \n",
       "4      12.106432  \n",
       "5      12.334851  \n",
       "6      12.138461  \n",
       "7      12.253167  \n",
       "8      12.138480  \n",
       "9      12.122425  \n",
       "10     12.083442  \n",
       "11     12.147195  \n",
       "12     15.762773  \n",
       "13     17.168862  \n",
       "14     16.014731  \n",
       "15     16.609179  \n",
       "16     17.324838  \n",
       "17     16.576077  \n",
       "18     12.654564  \n",
       "19     12.438958  \n",
       "20     12.459608  \n",
       "21     12.402267  \n",
       "22     12.503209  \n",
       "23     12.491721  \n",
       "24     11.282929  \n",
       "25     11.383851  \n",
       "26     11.248523  \n",
       "27     11.294404  \n",
       "28     11.491669  \n",
       "29     11.340275  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_results_no_svm = perform_trials('chess', models_without_svm, chess_X, chess_y)\n",
    "chess_results_no_svm.to_csv('results/chess_no_svm.csv')\n",
    "chess_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   16.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   15.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   15.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   26.0s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   25.9s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   25.5s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   25.7s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   25.3s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   37.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   33.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   32.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   31.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   32.6s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>2.072327e-02</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>5.527973e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>4.144653e-03</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>1.105595e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.105595e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>2.211189e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   shrooms        tree     1         1.00000              1.0       1.00000   \n",
       "1   shrooms        tree     2         0.99940              1.0       0.99875   \n",
       "2   shrooms        tree     3         1.00000              1.0       1.00000   \n",
       "3   shrooms        tree     4         1.00000              1.0       1.00000   \n",
       "4   shrooms        tree     5         1.00000              1.0       1.00000   \n",
       "5   shrooms        tree   avg         0.99988              1.0       0.99975   \n",
       "6   shrooms     log_reg     1         1.00000              1.0       1.00000   \n",
       "7   shrooms     log_reg     2         1.00000              1.0       1.00000   \n",
       "8   shrooms     log_reg     3         1.00000              1.0       1.00000   \n",
       "9   shrooms     log_reg     4         1.00000              1.0       1.00000   \n",
       "10  shrooms     log_reg     5         1.00000              1.0       1.00000   \n",
       "11  shrooms     log_reg   avg         1.00000              1.0       1.00000   \n",
       "12  shrooms  perceptron     1         1.00000              1.0       1.00000   \n",
       "13  shrooms  perceptron     2         1.00000              1.0       1.00000   \n",
       "14  shrooms  perceptron     3         1.00000              1.0       1.00000   \n",
       "15  shrooms  perceptron     4         1.00000              1.0       1.00000   \n",
       "16  shrooms  perceptron     5         1.00000              1.0       1.00000   \n",
       "17  shrooms  perceptron   avg         1.00000              1.0       1.00000   \n",
       "18  shrooms         knn     1         1.00000              1.0       1.00000   \n",
       "19  shrooms         knn     2         1.00000              1.0       1.00000   \n",
       "20  shrooms         knn     3         1.00000              1.0       1.00000   \n",
       "21  shrooms         knn     4         1.00000              1.0       1.00000   \n",
       "22  shrooms         knn     5         1.00000              1.0       1.00000   \n",
       "23  shrooms         knn   avg         1.00000              1.0       1.00000   \n",
       "24  shrooms      forest     1         1.00000              1.0       1.00000   \n",
       "25  shrooms      forest     2         1.00000              1.0       1.00000   \n",
       "26  shrooms      forest     3         1.00000              1.0       1.00000   \n",
       "27  shrooms      forest     4         1.00000              1.0       1.00000   \n",
       "28  shrooms      forest     5         1.00000              1.0       1.00000   \n",
       "29  shrooms      forest   avg         1.00000              1.0       1.00000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1                 1.0  0.999375   0.999375   2.072327e-02       0.998399   \n",
       "2                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5                 1.0  0.999875   0.999875   4.144653e-03       0.999680   \n",
       "6                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "7                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "8                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "9                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "10                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "11                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "12                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14                1.0  1.000000   1.000000   9.992007e-16       0.999680   \n",
       "15                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "16                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17                1.0  1.000000   1.000000   9.992007e-16       0.999936   \n",
       "18                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "19                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "20                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "21                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "22                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "23                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "24                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "28                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "1              1.0     0.996702               1.0  0.998348  0.998351   \n",
       "2              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "3              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "4              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "5              1.0     0.999340               1.0  0.999670  0.999670   \n",
       "6              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "7              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "8              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "9              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "10             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "11             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "12             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "13             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "14             1.0     0.999316               1.0  0.999658  0.999658   \n",
       "15             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "16             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "17             1.0     0.999863               1.0  0.999932  0.999932   \n",
       "18             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "19             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "20             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "21             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "22             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "23             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "24             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "25             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "26             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "27             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "28             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "29             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   5.527973e-02  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   1.105595e-02  \n",
       "6   9.992007e-16  \n",
       "7   9.992007e-16  \n",
       "8   9.992007e-16  \n",
       "9   9.992007e-16  \n",
       "10  9.992007e-16  \n",
       "11  9.992007e-16  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  1.105595e-02  \n",
       "15  9.992007e-16  \n",
       "16  9.992007e-16  \n",
       "17  2.211189e-03  \n",
       "18  9.992007e-16  \n",
       "19  9.992007e-16  \n",
       "20  9.992007e-16  \n",
       "21  9.992007e-16  \n",
       "22  9.992007e-16  \n",
       "23  9.992007e-16  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  9.992007e-16  \n",
       "28  9.992007e-16  \n",
       "29  9.992007e-16  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_results_no_svm = perform_trials('shrooms', models_without_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_no_svm.to_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.1min\n"
     ]
    }
   ],
   "source": [
    "chess_results_svm = perform_trials('chess', models_only_svm, chess_X, chess_y)\n",
    "chess_results_svm.to_csv('results/chess_svm.csv')\n",
    "chess_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_svm = perform_trials('shrooms', models_only_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_svm.to_csv('results/shrooms_svm.csv')\n",
    "shrooms_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_results_no_svm = pd.read_csv('results/chess_no_svm.csv')\n",
    "chess_results_svm = pd.read_csv('results/chess_svm.csv')\n",
    "shrooms_results_no_svm = pd.read_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_svm = pd.read_csv('results/shrooms_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_results = chess_results_no_svm.append(chess_results_svm, ignore_index=True)\n",
    "shrooms_results = shrooms_results_no_svm.append(shrooms_results_svm, ignore_index=True)\n",
    "chess_results.to_csv('results/chess.csv')\n",
    "shrooms_results.to_csv('results/shrooms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Cardio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.502  0.497     nan 0.7066 0.502  0.5376    nan 0.7066 0.502  0.7072\n",
      "    nan 0.7066 0.5032 0.71      nan 0.7066 0.498  0.7086    nan 0.7066\n",
      " 0.7098 0.707     nan 0.7066 0.7068 0.7066    nan 0.7066 0.7064 0.7066\n",
      "    nan 0.7066 0.7066 0.7066    nan 0.7066 0.7066 0.7066    nan 0.7066\n",
      " 0.7066 0.7066    nan 0.7066 0.7066 0.7066    nan 0.7066 0.7066 0.7066\n",
      "    nan 0.7066]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.5096 0.5096    nan 0.6474 0.5096 0.509     nan 0.6474 0.5096 0.6106\n",
      "    nan 0.647  0.5096 0.6476    nan 0.6476 0.5094 0.647     nan 0.6472\n",
      " 0.6328 0.6472    nan 0.6476 0.6476 0.6476    nan 0.6474 0.647  0.6474\n",
      "    nan 0.6474 0.6474 0.6472    nan 0.6474 0.6472 0.6474    nan 0.6474\n",
      " 0.6476 0.6472    nan 0.6474 0.6472 0.6472    nan 0.647  0.6474 0.6472\n",
      "    nan 0.6474]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.5082 0.5082    nan 0.6798 0.505  0.5078    nan 0.6796 0.5082 0.6412\n",
      "    nan 0.68   0.5082 0.6804    nan 0.6796 0.5082 0.6802    nan 0.6792\n",
      " 0.6746 0.6802    nan 0.6794 0.6796 0.68      nan 0.6796 0.6796 0.6792\n",
      "    nan 0.6796 0.6798 0.6796    nan 0.6798 0.6802 0.68      nan 0.6798\n",
      " 0.6796 0.68      nan 0.68   0.6794 0.6802    nan 0.6802 0.68   0.6798\n",
      "    nan 0.6798]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.5024 0.5044    nan 0.6594 0.5024 0.5058    nan 0.6598 0.5012 0.6504\n",
      "    nan 0.6596 0.5024 0.66      nan 0.66   0.5046 0.6594    nan 0.6596\n",
      " 0.66   0.6592    nan 0.6592 0.6596 0.6592    nan 0.6594 0.659  0.6598\n",
      "    nan 0.6596 0.6592 0.6598    nan 0.6598 0.66   0.6594    nan 0.6598\n",
      " 0.6596 0.6594    nan 0.6596 0.6596 0.6602    nan 0.6594 0.6598 0.6598\n",
      "    nan 0.6596]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.4982 0.5026    nan 0.6966 0.5006 0.5078    nan 0.6966 0.5006 0.6794\n",
      "    nan 0.6968 0.5014 0.6964    nan 0.6966 0.5026 0.6966    nan 0.697\n",
      " 0.6896 0.6968    nan 0.6968 0.6964 0.6966    nan 0.6968 0.6968 0.6966\n",
      "    nan 0.6966 0.6968 0.6968    nan 0.6966 0.6966 0.6966    nan 0.6966\n",
      " 0.6966 0.6964    nan 0.6968 0.6968 0.6966    nan 0.6966 0.6968 0.6966\n",
      "    nan 0.6966]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7146 0.7182 0.7238 0.7276 0.7338 0.7358 0.7384]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.705  0.7108 0.7142 0.7136 0.718  0.718  0.719 ]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7148 0.721  0.7222 0.7244 0.7272 0.7264 0.7286]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7048 0.7082 0.7118 0.7154 0.719  0.7198 0.7226]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7042 0.7102 0.7118 0.7156 0.7206 0.7224 0.7234]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72720</td>\n",
       "      <td>0.760951</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.796105</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>9.422260</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.784402</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>9.736833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.73080</td>\n",
       "      <td>0.735317</td>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.724307</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>9.297947</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.720638</td>\n",
       "      <td>0.712518</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>9.789467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72760</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.656041</td>\n",
       "      <td>0.801545</td>\n",
       "      <td>0.709966</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>9.408441</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.784166</td>\n",
       "      <td>0.705842</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>9.533320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73720</td>\n",
       "      <td>0.768923</td>\n",
       "      <td>0.684774</td>\n",
       "      <td>0.790557</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>9.076873</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.741616</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>9.513137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.647831</td>\n",
       "      <td>0.823080</td>\n",
       "      <td>0.710762</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>9.152846</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.773141</td>\n",
       "      <td>0.641379</td>\n",
       "      <td>0.812196</td>\n",
       "      <td>0.701123</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>9.433412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.73156</td>\n",
       "      <td>0.765195</td>\n",
       "      <td>0.676620</td>\n",
       "      <td>0.787119</td>\n",
       "      <td>0.717344</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>9.271673</td>\n",
       "      <td>0.722018</td>\n",
       "      <td>0.746792</td>\n",
       "      <td>0.673105</td>\n",
       "      <td>0.770831</td>\n",
       "      <td>0.707236</td>\n",
       "      <td>0.721968</td>\n",
       "      <td>9.601234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71200</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.785374</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.711527</td>\n",
       "      <td>9.947254</td>\n",
       "      <td>0.704323</td>\n",
       "      <td>0.737496</td>\n",
       "      <td>0.634344</td>\n",
       "      <td>0.774281</td>\n",
       "      <td>0.682042</td>\n",
       "      <td>0.704312</td>\n",
       "      <td>10.212409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64640</td>\n",
       "      <td>0.622257</td>\n",
       "      <td>0.779042</td>\n",
       "      <td>0.508564</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>0.643803</td>\n",
       "      <td>12.213104</td>\n",
       "      <td>0.644538</td>\n",
       "      <td>0.611887</td>\n",
       "      <td>0.786316</td>\n",
       "      <td>0.503362</td>\n",
       "      <td>0.688221</td>\n",
       "      <td>0.644839</td>\n",
       "      <td>12.277406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68040</td>\n",
       "      <td>0.675999</td>\n",
       "      <td>0.712712</td>\n",
       "      <td>0.647011</td>\n",
       "      <td>0.693870</td>\n",
       "      <td>0.679861</td>\n",
       "      <td>11.038732</td>\n",
       "      <td>0.686446</td>\n",
       "      <td>0.672761</td>\n",
       "      <td>0.723719</td>\n",
       "      <td>0.649315</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>10.829907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65080</td>\n",
       "      <td>0.650504</td>\n",
       "      <td>0.664948</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.657647</td>\n",
       "      <td>0.650674</td>\n",
       "      <td>12.061085</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>0.685738</td>\n",
       "      <td>0.635467</td>\n",
       "      <td>0.668609</td>\n",
       "      <td>0.660602</td>\n",
       "      <td>11.723669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.69780</td>\n",
       "      <td>0.717071</td>\n",
       "      <td>0.658575</td>\n",
       "      <td>0.737435</td>\n",
       "      <td>0.686580</td>\n",
       "      <td>0.698005</td>\n",
       "      <td>10.437723</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.713969</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>0.730620</td>\n",
       "      <td>0.693310</td>\n",
       "      <td>0.702216</td>\n",
       "      <td>10.284161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67748</td>\n",
       "      <td>0.682319</td>\n",
       "      <td>0.690592</td>\n",
       "      <td>0.662957</td>\n",
       "      <td>0.683495</td>\n",
       "      <td>0.676774</td>\n",
       "      <td>11.139579</td>\n",
       "      <td>0.679625</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.700786</td>\n",
       "      <td>0.658609</td>\n",
       "      <td>0.685898</td>\n",
       "      <td>0.679697</td>\n",
       "      <td>11.065510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67060</td>\n",
       "      <td>0.793684</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.883148</td>\n",
       "      <td>0.578665</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>11.377120</td>\n",
       "      <td>0.666985</td>\n",
       "      <td>0.790375</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>0.879526</td>\n",
       "      <td>0.577028</td>\n",
       "      <td>0.666952</td>\n",
       "      <td>11.501992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66180</td>\n",
       "      <td>0.641372</td>\n",
       "      <td>0.762951</td>\n",
       "      <td>0.556688</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.659820</td>\n",
       "      <td>11.681188</td>\n",
       "      <td>0.663754</td>\n",
       "      <td>0.633959</td>\n",
       "      <td>0.771577</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>0.696031</td>\n",
       "      <td>0.663982</td>\n",
       "      <td>11.613708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69340</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.660465</td>\n",
       "      <td>0.695178</td>\n",
       "      <td>10.589666</td>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.745791</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>0.797371</td>\n",
       "      <td>0.662990</td>\n",
       "      <td>0.697055</td>\n",
       "      <td>10.456829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46200</td>\n",
       "      <td>0.481530</td>\n",
       "      <td>0.868358</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.619519</td>\n",
       "      <td>0.458392</td>\n",
       "      <td>18.582239</td>\n",
       "      <td>0.458985</td>\n",
       "      <td>0.477269</td>\n",
       "      <td>0.876236</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.617952</td>\n",
       "      <td>0.459536</td>\n",
       "      <td>18.686393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65920</td>\n",
       "      <td>0.636333</td>\n",
       "      <td>0.751293</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.658719</td>\n",
       "      <td>11.770988</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>0.629263</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.553882</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>0.656338</td>\n",
       "      <td>11.873547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.62940</td>\n",
       "      <td>0.661648</td>\n",
       "      <td>0.684939</td>\n",
       "      <td>0.571597</td>\n",
       "      <td>0.648920</td>\n",
       "      <td>0.628268</td>\n",
       "      <td>12.800240</td>\n",
       "      <td>0.628640</td>\n",
       "      <td>0.655331</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.566001</td>\n",
       "      <td>0.648397</td>\n",
       "      <td>0.628773</td>\n",
       "      <td>12.826494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73200</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.654187</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.708061</td>\n",
       "      <td>0.731505</td>\n",
       "      <td>9.256469</td>\n",
       "      <td>0.719692</td>\n",
       "      <td>0.758315</td>\n",
       "      <td>0.644807</td>\n",
       "      <td>0.794555</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.719681</td>\n",
       "      <td>9.681567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71840</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.639717</td>\n",
       "      <td>0.800163</td>\n",
       "      <td>0.698372</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>9.726198</td>\n",
       "      <td>0.721292</td>\n",
       "      <td>0.763579</td>\n",
       "      <td>0.639357</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.695969</td>\n",
       "      <td>0.721119</td>\n",
       "      <td>9.626302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72720</td>\n",
       "      <td>0.773848</td>\n",
       "      <td>0.654467</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>0.709168</td>\n",
       "      <td>0.728413</td>\n",
       "      <td>9.422256</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.751721</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.785118</td>\n",
       "      <td>0.698944</td>\n",
       "      <td>0.719105</td>\n",
       "      <td>9.697512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.72880</td>\n",
       "      <td>0.763087</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.713803</td>\n",
       "      <td>0.729318</td>\n",
       "      <td>9.367000</td>\n",
       "      <td>0.715015</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.665958</td>\n",
       "      <td>0.763943</td>\n",
       "      <td>0.700036</td>\n",
       "      <td>0.714951</td>\n",
       "      <td>9.843114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72820</td>\n",
       "      <td>0.753292</td>\n",
       "      <td>0.682849</td>\n",
       "      <td>0.774025</td>\n",
       "      <td>0.716343</td>\n",
       "      <td>0.728437</td>\n",
       "      <td>9.387729</td>\n",
       "      <td>0.720754</td>\n",
       "      <td>0.736901</td>\n",
       "      <td>0.685764</td>\n",
       "      <td>0.755671</td>\n",
       "      <td>0.710413</td>\n",
       "      <td>0.720717</td>\n",
       "      <td>9.644918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.72692</td>\n",
       "      <td>0.766140</td>\n",
       "      <td>0.660344</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>0.709150</td>\n",
       "      <td>0.727523</td>\n",
       "      <td>9.431930</td>\n",
       "      <td>0.719197</td>\n",
       "      <td>0.749661</td>\n",
       "      <td>0.657796</td>\n",
       "      <td>0.780433</td>\n",
       "      <td>0.700466</td>\n",
       "      <td>0.719114</td>\n",
       "      <td>9.698683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81500</td>\n",
       "      <td>0.823042</td>\n",
       "      <td>0.799517</td>\n",
       "      <td>0.830286</td>\n",
       "      <td>0.811109</td>\n",
       "      <td>0.814902</td>\n",
       "      <td>6.389742</td>\n",
       "      <td>0.728723</td>\n",
       "      <td>0.737109</td>\n",
       "      <td>0.710909</td>\n",
       "      <td>0.746531</td>\n",
       "      <td>0.723772</td>\n",
       "      <td>0.728720</td>\n",
       "      <td>9.369674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.81860</td>\n",
       "      <td>0.835035</td>\n",
       "      <td>0.802590</td>\n",
       "      <td>0.835237</td>\n",
       "      <td>0.818491</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>6.265399</td>\n",
       "      <td>0.727477</td>\n",
       "      <td>0.734280</td>\n",
       "      <td>0.711141</td>\n",
       "      <td>0.743744</td>\n",
       "      <td>0.722525</td>\n",
       "      <td>0.727442</td>\n",
       "      <td>9.412716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.82020</td>\n",
       "      <td>0.846121</td>\n",
       "      <td>0.789847</td>\n",
       "      <td>0.851566</td>\n",
       "      <td>0.817016</td>\n",
       "      <td>0.820706</td>\n",
       "      <td>6.210130</td>\n",
       "      <td>0.728785</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.712436</td>\n",
       "      <td>0.745071</td>\n",
       "      <td>0.723895</td>\n",
       "      <td>0.728753</td>\n",
       "      <td>9.367550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.82560</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.802934</td>\n",
       "      <td>0.848668</td>\n",
       "      <td>0.822836</td>\n",
       "      <td>0.825801</td>\n",
       "      <td>6.023623</td>\n",
       "      <td>0.726969</td>\n",
       "      <td>0.732518</td>\n",
       "      <td>0.713898</td>\n",
       "      <td>0.740006</td>\n",
       "      <td>0.723088</td>\n",
       "      <td>0.726952</td>\n",
       "      <td>9.430253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.81320</td>\n",
       "      <td>0.819765</td>\n",
       "      <td>0.805412</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.812525</td>\n",
       "      <td>0.813241</td>\n",
       "      <td>6.451915</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.721278</td>\n",
       "      <td>0.735907</td>\n",
       "      <td>0.726390</td>\n",
       "      <td>0.728592</td>\n",
       "      <td>9.373930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.81852</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.800060</td>\n",
       "      <td>0.837365</td>\n",
       "      <td>0.816395</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>6.268162</td>\n",
       "      <td>0.728111</td>\n",
       "      <td>0.734242</td>\n",
       "      <td>0.713932</td>\n",
       "      <td>0.742252</td>\n",
       "      <td>0.723934</td>\n",
       "      <td>0.728092</td>\n",
       "      <td>9.390825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1         0.72720         0.760951      0.657407   \n",
       "1   cardio        tree     2         0.73080         0.735317      0.737049   \n",
       "2   cardio        tree     3         0.72760         0.773550      0.656041   \n",
       "3   cardio        tree     4         0.73720         0.768923      0.684774   \n",
       "4   cardio        tree     5         0.73500         0.787234      0.647831   \n",
       "5   cardio        tree   avg         0.73156         0.765195      0.676620   \n",
       "6   cardio     log_reg     1         0.71200         0.745763      0.637681   \n",
       "7   cardio     log_reg     2         0.64640         0.622257      0.779042   \n",
       "8   cardio     log_reg     3         0.68040         0.675999      0.712712   \n",
       "9   cardio     log_reg     4         0.65080         0.650504      0.664948   \n",
       "10  cardio     log_reg     5         0.69780         0.717071      0.658575   \n",
       "11  cardio     log_reg   avg         0.67748         0.682319      0.690592   \n",
       "12  cardio  perceptron     1         0.67060         0.793684      0.455314   \n",
       "13  cardio  perceptron     2         0.66180         0.641372      0.762951   \n",
       "14  cardio  perceptron     3         0.69340         0.755319      0.586777   \n",
       "15  cardio  perceptron     4         0.46200         0.481530      0.868358   \n",
       "16  cardio  perceptron     5         0.65920         0.636333      0.751293   \n",
       "17  cardio  perceptron   avg         0.62940         0.661648      0.684939   \n",
       "18  cardio         knn     1         0.73200         0.771605      0.654187   \n",
       "19  cardio         knn     2         0.71840         0.768868      0.639717   \n",
       "20  cardio         knn     3         0.72720         0.773848      0.654467   \n",
       "21  cardio         knn     4         0.72880         0.763087      0.670500   \n",
       "22  cardio         knn     5         0.72820         0.753292      0.682849   \n",
       "23  cardio         knn   avg         0.72692         0.766140      0.660344   \n",
       "24  cardio      forest     1         0.81500         0.823042      0.799517   \n",
       "25  cardio      forest     2         0.81860         0.835035      0.802590   \n",
       "26  cardio      forest     3         0.82020         0.846121      0.789847   \n",
       "27  cardio      forest     4         0.82560         0.843750      0.802934   \n",
       "28  cardio      forest     5         0.81320         0.819765      0.805412   \n",
       "29  cardio      forest   avg         0.81852         0.833543      0.800060   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.796105  0.705400   0.726756       9.422260       0.718092   \n",
       "1            0.724307  0.736182   0.730678       9.297947       0.716569   \n",
       "2            0.801545  0.709966   0.728793       9.408441       0.723985   \n",
       "3            0.790557  0.724413   0.737665       9.076873       0.724569   \n",
       "4            0.823080  0.710762   0.735456       9.152846       0.726877   \n",
       "5            0.787119  0.717344   0.731870       9.271673       0.722018   \n",
       "6            0.785374  0.687500   0.711527       9.947254       0.704323   \n",
       "7            0.508564  0.691879   0.643803      12.213104       0.644538   \n",
       "8            0.647011  0.693870   0.679861      11.038732       0.686446   \n",
       "9            0.636400  0.657647   0.650674      12.061085       0.660569   \n",
       "10           0.737435  0.686580   0.698005      10.437723       0.702246   \n",
       "11           0.662957  0.683495   0.676774      11.139579       0.679625   \n",
       "12           0.883148  0.578665   0.669231      11.377120       0.666985   \n",
       "13           0.556688  0.696899   0.659820      11.681188       0.663754   \n",
       "14           0.803579  0.660465   0.695178      10.589666       0.697246   \n",
       "15           0.048426  0.619519   0.458392      18.582239       0.458985   \n",
       "16           0.566144  0.689051   0.658719      11.770988       0.656231   \n",
       "17           0.571597  0.648920   0.628268      12.800240       0.628640   \n",
       "18           0.808824  0.708061   0.731505       9.256469       0.719692   \n",
       "19           0.800163  0.698372   0.719940       9.726198       0.721292   \n",
       "20           0.802359  0.709168   0.728413       9.422256       0.719231   \n",
       "21           0.788136  0.713803   0.729318       9.367000       0.715015   \n",
       "22           0.774025  0.716343   0.728437       9.387729       0.720754   \n",
       "23           0.794701  0.709150   0.727523       9.431930       0.719197   \n",
       "24           0.830286  0.811109   0.814902       6.389742       0.728723   \n",
       "25           0.835237  0.818491   0.818913       6.265399       0.727477   \n",
       "26           0.851566  0.817016   0.820706       6.210130       0.728785   \n",
       "27           0.848668  0.822836   0.825801       6.023623       0.726969   \n",
       "28           0.821070  0.812525   0.813241       6.451915       0.728600   \n",
       "29           0.837365  0.816395   0.818713       6.268162       0.728111   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.751375     0.651762          0.784402  0.698032  0.718082   \n",
       "1         0.713967     0.720638          0.712518  0.717287  0.716578   \n",
       "2         0.753861     0.663574          0.784166  0.705842  0.723870   \n",
       "3         0.741616     0.688172          0.760870  0.713895  0.724521   \n",
       "4         0.773141     0.641379          0.812196  0.701123  0.726788   \n",
       "5         0.746792     0.673105          0.770831  0.707236  0.721968   \n",
       "6         0.737496     0.634344          0.774281  0.682042  0.704312   \n",
       "7         0.611887     0.786316          0.503362  0.688221  0.644839   \n",
       "8         0.672761     0.723719          0.649315  0.697310  0.686517   \n",
       "9         0.652315     0.685738          0.635467  0.668609  0.660602   \n",
       "10        0.713969     0.673813          0.730620  0.693310  0.702216   \n",
       "11        0.677686     0.700786          0.658609  0.685898  0.679697   \n",
       "12        0.790375     0.454378          0.879526  0.577028  0.666952   \n",
       "13        0.633959     0.771577          0.556388  0.696031  0.663982   \n",
       "14        0.745791     0.596738          0.797371  0.662990  0.697055   \n",
       "15        0.477269     0.876236          0.042836  0.617952  0.459536   \n",
       "16        0.629263     0.758794          0.553882  0.687984  0.656338   \n",
       "17        0.655331     0.691545          0.566001  0.648397  0.628773   \n",
       "18        0.758315     0.644807          0.794555  0.696970  0.719681   \n",
       "19        0.763579     0.639357          0.802880  0.695969  0.721119   \n",
       "20        0.751721     0.653092          0.785118  0.698944  0.719105   \n",
       "21        0.737789     0.665958          0.763943  0.700036  0.714951   \n",
       "22        0.736901     0.685764          0.755671  0.710413  0.720717   \n",
       "23        0.749661     0.657796          0.780433  0.700466  0.719114   \n",
       "24        0.737109     0.710909          0.746531  0.723772  0.728720   \n",
       "25        0.734280     0.711141          0.743744  0.722525  0.727442   \n",
       "26        0.735730     0.712436          0.745071  0.723895  0.728753   \n",
       "27        0.732518     0.713898          0.740006  0.723088  0.726952   \n",
       "28        0.731575     0.721278          0.735907  0.726390  0.728592   \n",
       "29        0.734242     0.713932          0.742252  0.723934  0.728092   \n",
       "\n",
       "    test_logloss  \n",
       "0       9.736833  \n",
       "1       9.789467  \n",
       "2       9.533320  \n",
       "3       9.513137  \n",
       "4       9.433412  \n",
       "5       9.601234  \n",
       "6      10.212409  \n",
       "7      12.277406  \n",
       "8      10.829907  \n",
       "9      11.723669  \n",
       "10     10.284161  \n",
       "11     11.065510  \n",
       "12     11.501992  \n",
       "13     11.613708  \n",
       "14     10.456829  \n",
       "15     18.686393  \n",
       "16     11.873547  \n",
       "17     12.826494  \n",
       "18      9.681567  \n",
       "19      9.626302  \n",
       "20      9.697512  \n",
       "21      9.843114  \n",
       "22      9.644918  \n",
       "23      9.698683  \n",
       "24      9.369674  \n",
       "25      9.412716  \n",
       "26      9.367550  \n",
       "27      9.430253  \n",
       "28      9.373930  \n",
       "29      9.390825  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on cardio dataset\n",
    "cardio_results_no_svm = perform_trials('cardio', models_without_svm, cardio_X, cardio_y)\n",
    "cardio_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74720</td>\n",
       "      <td>0.778793</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>0.807631</td>\n",
       "      <td>0.729452</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>8.731480</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.752822</td>\n",
       "      <td>0.662933</td>\n",
       "      <td>0.782403</td>\n",
       "      <td>0.705024</td>\n",
       "      <td>0.722668</td>\n",
       "      <td>9.578487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.73520</td>\n",
       "      <td>0.774933</td>\n",
       "      <td>0.677002</td>\n",
       "      <td>0.795677</td>\n",
       "      <td>0.722664</td>\n",
       "      <td>0.736339</td>\n",
       "      <td>9.145948</td>\n",
       "      <td>0.728338</td>\n",
       "      <td>0.757845</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.787006</td>\n",
       "      <td>0.710894</td>\n",
       "      <td>0.728214</td>\n",
       "      <td>9.382942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.74400</td>\n",
       "      <td>0.792575</td>\n",
       "      <td>0.672176</td>\n",
       "      <td>0.818219</td>\n",
       "      <td>0.727428</td>\n",
       "      <td>0.745198</td>\n",
       "      <td>8.841998</td>\n",
       "      <td>0.727431</td>\n",
       "      <td>0.752808</td>\n",
       "      <td>0.675689</td>\n",
       "      <td>0.778975</td>\n",
       "      <td>0.712167</td>\n",
       "      <td>0.727332</td>\n",
       "      <td>9.414296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.74440</td>\n",
       "      <td>0.779928</td>\n",
       "      <td>0.687153</td>\n",
       "      <td>0.802663</td>\n",
       "      <td>0.730607</td>\n",
       "      <td>0.744908</td>\n",
       "      <td>8.828189</td>\n",
       "      <td>0.726185</td>\n",
       "      <td>0.749125</td>\n",
       "      <td>0.679052</td>\n",
       "      <td>0.773192</td>\n",
       "      <td>0.712370</td>\n",
       "      <td>0.726122</td>\n",
       "      <td>9.457339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73800</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.684441</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>0.724211</td>\n",
       "      <td>0.738280</td>\n",
       "      <td>9.049242</td>\n",
       "      <td>0.728062</td>\n",
       "      <td>0.748655</td>\n",
       "      <td>0.685794</td>\n",
       "      <td>0.770240</td>\n",
       "      <td>0.715847</td>\n",
       "      <td>0.728017</td>\n",
       "      <td>9.392514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.74176</td>\n",
       "      <td>0.779023</td>\n",
       "      <td>0.681352</td>\n",
       "      <td>0.803262</td>\n",
       "      <td>0.726872</td>\n",
       "      <td>0.742307</td>\n",
       "      <td>8.919372</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>0.752251</td>\n",
       "      <td>0.674578</td>\n",
       "      <td>0.778363</td>\n",
       "      <td>0.711260</td>\n",
       "      <td>0.726471</td>\n",
       "      <td>9.445116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  cardio   svm     1         0.74720         0.778793      0.685990   \n",
       "1  cardio   svm     2         0.73520         0.774933      0.677002   \n",
       "2  cardio   svm     3         0.74400         0.792575      0.672176   \n",
       "3  cardio   svm     4         0.74440         0.779928      0.687153   \n",
       "4  cardio   svm     5         0.73800         0.768887      0.684441   \n",
       "5  cardio   svm   avg         0.74176         0.779023      0.681352   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0           0.807631  0.729452   0.746811       8.731480       0.722677   \n",
       "1           0.795677  0.722664   0.736339       9.145948       0.728338   \n",
       "2           0.818219  0.727428   0.745198       8.841998       0.727431   \n",
       "3           0.802663  0.730607   0.744908       8.828189       0.726185   \n",
       "4           0.792119  0.724211   0.738280       9.049242       0.728062   \n",
       "5           0.803262  0.726872   0.742307       8.919372       0.726538   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.752822     0.662933          0.782403  0.705024  0.722668   \n",
       "1        0.757845     0.669421          0.787006  0.710894  0.728214   \n",
       "2        0.752808     0.675689          0.778975  0.712167  0.727332   \n",
       "3        0.749125     0.679052          0.773192  0.712370  0.726122   \n",
       "4        0.748655     0.685794          0.770240  0.715847  0.728017   \n",
       "5        0.752251     0.674578          0.778363  0.711260  0.726471   \n",
       "\n",
       "   test_logloss  \n",
       "0      9.578487  \n",
       "1      9.382942  \n",
       "2      9.414296  \n",
       "3      9.457339  \n",
       "4      9.392514  \n",
       "5      9.445116  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running SVM algorithm on cardio dataset, generally take longer time to run than other algorithms combined\n",
    "cardio_results_svm = perform_trials('cardio', models_only_svm, cardio_X, cardio_y)\n",
    "cardio_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results of svm and non-svm algorithms and save as a csv file\n",
    "cardio_final_results = cardio_results_no_svm.append(cardio_results_svm, ignore_index=True)\n",
    "cardio_final_results.to_csv('results/cardio_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72720</td>\n",
       "      <td>0.760951</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.796105</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>9.422260</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.784402</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>9.736833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.73080</td>\n",
       "      <td>0.735317</td>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.724307</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>9.297947</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.720638</td>\n",
       "      <td>0.712518</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>9.789467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72760</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.656041</td>\n",
       "      <td>0.801545</td>\n",
       "      <td>0.709966</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>9.408441</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.784166</td>\n",
       "      <td>0.705842</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>9.533320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73720</td>\n",
       "      <td>0.768923</td>\n",
       "      <td>0.684774</td>\n",
       "      <td>0.790557</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>9.076873</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.741616</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>9.513137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.647831</td>\n",
       "      <td>0.823080</td>\n",
       "      <td>0.710762</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>9.152846</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.773141</td>\n",
       "      <td>0.641379</td>\n",
       "      <td>0.812196</td>\n",
       "      <td>0.701123</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>9.433412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.73156</td>\n",
       "      <td>0.765195</td>\n",
       "      <td>0.676620</td>\n",
       "      <td>0.787119</td>\n",
       "      <td>0.717344</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>9.271673</td>\n",
       "      <td>0.722018</td>\n",
       "      <td>0.746792</td>\n",
       "      <td>0.673105</td>\n",
       "      <td>0.770831</td>\n",
       "      <td>0.707236</td>\n",
       "      <td>0.721968</td>\n",
       "      <td>9.601234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71200</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.785374</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.711527</td>\n",
       "      <td>9.947254</td>\n",
       "      <td>0.704323</td>\n",
       "      <td>0.737496</td>\n",
       "      <td>0.634344</td>\n",
       "      <td>0.774281</td>\n",
       "      <td>0.682042</td>\n",
       "      <td>0.704312</td>\n",
       "      <td>10.212409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64640</td>\n",
       "      <td>0.622257</td>\n",
       "      <td>0.779042</td>\n",
       "      <td>0.508564</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>0.643803</td>\n",
       "      <td>12.213104</td>\n",
       "      <td>0.644538</td>\n",
       "      <td>0.611887</td>\n",
       "      <td>0.786316</td>\n",
       "      <td>0.503362</td>\n",
       "      <td>0.688221</td>\n",
       "      <td>0.644839</td>\n",
       "      <td>12.277406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68040</td>\n",
       "      <td>0.675999</td>\n",
       "      <td>0.712712</td>\n",
       "      <td>0.647011</td>\n",
       "      <td>0.693870</td>\n",
       "      <td>0.679861</td>\n",
       "      <td>11.038732</td>\n",
       "      <td>0.686446</td>\n",
       "      <td>0.672761</td>\n",
       "      <td>0.723719</td>\n",
       "      <td>0.649315</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>10.829907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65080</td>\n",
       "      <td>0.650504</td>\n",
       "      <td>0.664948</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.657647</td>\n",
       "      <td>0.650674</td>\n",
       "      <td>12.061085</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>0.685738</td>\n",
       "      <td>0.635467</td>\n",
       "      <td>0.668609</td>\n",
       "      <td>0.660602</td>\n",
       "      <td>11.723669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.69780</td>\n",
       "      <td>0.717071</td>\n",
       "      <td>0.658575</td>\n",
       "      <td>0.737435</td>\n",
       "      <td>0.686580</td>\n",
       "      <td>0.698005</td>\n",
       "      <td>10.437723</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.713969</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>0.730620</td>\n",
       "      <td>0.693310</td>\n",
       "      <td>0.702216</td>\n",
       "      <td>10.284161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67748</td>\n",
       "      <td>0.682319</td>\n",
       "      <td>0.690592</td>\n",
       "      <td>0.662957</td>\n",
       "      <td>0.683495</td>\n",
       "      <td>0.676774</td>\n",
       "      <td>11.139579</td>\n",
       "      <td>0.679625</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.700786</td>\n",
       "      <td>0.658609</td>\n",
       "      <td>0.685898</td>\n",
       "      <td>0.679697</td>\n",
       "      <td>11.065510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67060</td>\n",
       "      <td>0.793684</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.883148</td>\n",
       "      <td>0.578665</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>11.377120</td>\n",
       "      <td>0.666985</td>\n",
       "      <td>0.790375</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>0.879526</td>\n",
       "      <td>0.577028</td>\n",
       "      <td>0.666952</td>\n",
       "      <td>11.501992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66180</td>\n",
       "      <td>0.641372</td>\n",
       "      <td>0.762951</td>\n",
       "      <td>0.556688</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.659820</td>\n",
       "      <td>11.681188</td>\n",
       "      <td>0.663754</td>\n",
       "      <td>0.633959</td>\n",
       "      <td>0.771577</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>0.696031</td>\n",
       "      <td>0.663982</td>\n",
       "      <td>11.613708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69340</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.660465</td>\n",
       "      <td>0.695178</td>\n",
       "      <td>10.589666</td>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.745791</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>0.797371</td>\n",
       "      <td>0.662990</td>\n",
       "      <td>0.697055</td>\n",
       "      <td>10.456829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46200</td>\n",
       "      <td>0.481530</td>\n",
       "      <td>0.868358</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.619519</td>\n",
       "      <td>0.458392</td>\n",
       "      <td>18.582239</td>\n",
       "      <td>0.458985</td>\n",
       "      <td>0.477269</td>\n",
       "      <td>0.876236</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.617952</td>\n",
       "      <td>0.459536</td>\n",
       "      <td>18.686393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65920</td>\n",
       "      <td>0.636333</td>\n",
       "      <td>0.751293</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.658719</td>\n",
       "      <td>11.770988</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>0.629263</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.553882</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>0.656338</td>\n",
       "      <td>11.873547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.62940</td>\n",
       "      <td>0.661648</td>\n",
       "      <td>0.684939</td>\n",
       "      <td>0.571597</td>\n",
       "      <td>0.648920</td>\n",
       "      <td>0.628268</td>\n",
       "      <td>12.800240</td>\n",
       "      <td>0.628640</td>\n",
       "      <td>0.655331</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.566001</td>\n",
       "      <td>0.648397</td>\n",
       "      <td>0.628773</td>\n",
       "      <td>12.826494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73200</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.654187</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.708061</td>\n",
       "      <td>0.731505</td>\n",
       "      <td>9.256469</td>\n",
       "      <td>0.719692</td>\n",
       "      <td>0.758315</td>\n",
       "      <td>0.644807</td>\n",
       "      <td>0.794555</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.719681</td>\n",
       "      <td>9.681567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71840</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.639717</td>\n",
       "      <td>0.800163</td>\n",
       "      <td>0.698372</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>9.726198</td>\n",
       "      <td>0.721292</td>\n",
       "      <td>0.763579</td>\n",
       "      <td>0.639357</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.695969</td>\n",
       "      <td>0.721119</td>\n",
       "      <td>9.626302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72720</td>\n",
       "      <td>0.773848</td>\n",
       "      <td>0.654467</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>0.709168</td>\n",
       "      <td>0.728413</td>\n",
       "      <td>9.422256</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.751721</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.785118</td>\n",
       "      <td>0.698944</td>\n",
       "      <td>0.719105</td>\n",
       "      <td>9.697512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.72880</td>\n",
       "      <td>0.763087</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.713803</td>\n",
       "      <td>0.729318</td>\n",
       "      <td>9.367000</td>\n",
       "      <td>0.715015</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.665958</td>\n",
       "      <td>0.763943</td>\n",
       "      <td>0.700036</td>\n",
       "      <td>0.714951</td>\n",
       "      <td>9.843114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72820</td>\n",
       "      <td>0.753292</td>\n",
       "      <td>0.682849</td>\n",
       "      <td>0.774025</td>\n",
       "      <td>0.716343</td>\n",
       "      <td>0.728437</td>\n",
       "      <td>9.387729</td>\n",
       "      <td>0.720754</td>\n",
       "      <td>0.736901</td>\n",
       "      <td>0.685764</td>\n",
       "      <td>0.755671</td>\n",
       "      <td>0.710413</td>\n",
       "      <td>0.720717</td>\n",
       "      <td>9.644918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.72692</td>\n",
       "      <td>0.766140</td>\n",
       "      <td>0.660344</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>0.709150</td>\n",
       "      <td>0.727523</td>\n",
       "      <td>9.431930</td>\n",
       "      <td>0.719197</td>\n",
       "      <td>0.749661</td>\n",
       "      <td>0.657796</td>\n",
       "      <td>0.780433</td>\n",
       "      <td>0.700466</td>\n",
       "      <td>0.719114</td>\n",
       "      <td>9.698683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81500</td>\n",
       "      <td>0.823042</td>\n",
       "      <td>0.799517</td>\n",
       "      <td>0.830286</td>\n",
       "      <td>0.811109</td>\n",
       "      <td>0.814902</td>\n",
       "      <td>6.389742</td>\n",
       "      <td>0.728723</td>\n",
       "      <td>0.737109</td>\n",
       "      <td>0.710909</td>\n",
       "      <td>0.746531</td>\n",
       "      <td>0.723772</td>\n",
       "      <td>0.728720</td>\n",
       "      <td>9.369674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.81860</td>\n",
       "      <td>0.835035</td>\n",
       "      <td>0.802590</td>\n",
       "      <td>0.835237</td>\n",
       "      <td>0.818491</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>6.265399</td>\n",
       "      <td>0.727477</td>\n",
       "      <td>0.734280</td>\n",
       "      <td>0.711141</td>\n",
       "      <td>0.743744</td>\n",
       "      <td>0.722525</td>\n",
       "      <td>0.727442</td>\n",
       "      <td>9.412716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.82020</td>\n",
       "      <td>0.846121</td>\n",
       "      <td>0.789847</td>\n",
       "      <td>0.851566</td>\n",
       "      <td>0.817016</td>\n",
       "      <td>0.820706</td>\n",
       "      <td>6.210130</td>\n",
       "      <td>0.728785</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.712436</td>\n",
       "      <td>0.745071</td>\n",
       "      <td>0.723895</td>\n",
       "      <td>0.728753</td>\n",
       "      <td>9.367550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.82560</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.802934</td>\n",
       "      <td>0.848668</td>\n",
       "      <td>0.822836</td>\n",
       "      <td>0.825801</td>\n",
       "      <td>6.023623</td>\n",
       "      <td>0.726969</td>\n",
       "      <td>0.732518</td>\n",
       "      <td>0.713898</td>\n",
       "      <td>0.740006</td>\n",
       "      <td>0.723088</td>\n",
       "      <td>0.726952</td>\n",
       "      <td>9.430253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.81320</td>\n",
       "      <td>0.819765</td>\n",
       "      <td>0.805412</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.812525</td>\n",
       "      <td>0.813241</td>\n",
       "      <td>6.451915</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.721278</td>\n",
       "      <td>0.735907</td>\n",
       "      <td>0.726390</td>\n",
       "      <td>0.728592</td>\n",
       "      <td>9.373930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.81852</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.800060</td>\n",
       "      <td>0.837365</td>\n",
       "      <td>0.816395</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>6.268162</td>\n",
       "      <td>0.728111</td>\n",
       "      <td>0.734242</td>\n",
       "      <td>0.713932</td>\n",
       "      <td>0.742252</td>\n",
       "      <td>0.723934</td>\n",
       "      <td>0.728092</td>\n",
       "      <td>9.390825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74720</td>\n",
       "      <td>0.778793</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>0.807631</td>\n",
       "      <td>0.729452</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>8.731480</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.752822</td>\n",
       "      <td>0.662933</td>\n",
       "      <td>0.782403</td>\n",
       "      <td>0.705024</td>\n",
       "      <td>0.722668</td>\n",
       "      <td>9.578487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.73520</td>\n",
       "      <td>0.774933</td>\n",
       "      <td>0.677002</td>\n",
       "      <td>0.795677</td>\n",
       "      <td>0.722664</td>\n",
       "      <td>0.736339</td>\n",
       "      <td>9.145948</td>\n",
       "      <td>0.728338</td>\n",
       "      <td>0.757845</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.787006</td>\n",
       "      <td>0.710894</td>\n",
       "      <td>0.728214</td>\n",
       "      <td>9.382942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.74400</td>\n",
       "      <td>0.792575</td>\n",
       "      <td>0.672176</td>\n",
       "      <td>0.818219</td>\n",
       "      <td>0.727428</td>\n",
       "      <td>0.745198</td>\n",
       "      <td>8.841998</td>\n",
       "      <td>0.727431</td>\n",
       "      <td>0.752808</td>\n",
       "      <td>0.675689</td>\n",
       "      <td>0.778975</td>\n",
       "      <td>0.712167</td>\n",
       "      <td>0.727332</td>\n",
       "      <td>9.414296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.74440</td>\n",
       "      <td>0.779928</td>\n",
       "      <td>0.687153</td>\n",
       "      <td>0.802663</td>\n",
       "      <td>0.730607</td>\n",
       "      <td>0.744908</td>\n",
       "      <td>8.828189</td>\n",
       "      <td>0.726185</td>\n",
       "      <td>0.749125</td>\n",
       "      <td>0.679052</td>\n",
       "      <td>0.773192</td>\n",
       "      <td>0.712370</td>\n",
       "      <td>0.726122</td>\n",
       "      <td>9.457339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73800</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.684441</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>0.724211</td>\n",
       "      <td>0.738280</td>\n",
       "      <td>9.049242</td>\n",
       "      <td>0.728062</td>\n",
       "      <td>0.748655</td>\n",
       "      <td>0.685794</td>\n",
       "      <td>0.770240</td>\n",
       "      <td>0.715847</td>\n",
       "      <td>0.728017</td>\n",
       "      <td>9.392514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.74176</td>\n",
       "      <td>0.779023</td>\n",
       "      <td>0.681352</td>\n",
       "      <td>0.803262</td>\n",
       "      <td>0.726872</td>\n",
       "      <td>0.742307</td>\n",
       "      <td>8.919372</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>0.752251</td>\n",
       "      <td>0.674578</td>\n",
       "      <td>0.778363</td>\n",
       "      <td>0.711260</td>\n",
       "      <td>0.726471</td>\n",
       "      <td>9.445116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1         0.72720         0.760951      0.657407   \n",
       "1   cardio        tree     2         0.73080         0.735317      0.737049   \n",
       "2   cardio        tree     3         0.72760         0.773550      0.656041   \n",
       "3   cardio        tree     4         0.73720         0.768923      0.684774   \n",
       "4   cardio        tree     5         0.73500         0.787234      0.647831   \n",
       "5   cardio        tree   avg         0.73156         0.765195      0.676620   \n",
       "6   cardio     log_reg     1         0.71200         0.745763      0.637681   \n",
       "7   cardio     log_reg     2         0.64640         0.622257      0.779042   \n",
       "8   cardio     log_reg     3         0.68040         0.675999      0.712712   \n",
       "9   cardio     log_reg     4         0.65080         0.650504      0.664948   \n",
       "10  cardio     log_reg     5         0.69780         0.717071      0.658575   \n",
       "11  cardio     log_reg   avg         0.67748         0.682319      0.690592   \n",
       "12  cardio  perceptron     1         0.67060         0.793684      0.455314   \n",
       "13  cardio  perceptron     2         0.66180         0.641372      0.762951   \n",
       "14  cardio  perceptron     3         0.69340         0.755319      0.586777   \n",
       "15  cardio  perceptron     4         0.46200         0.481530      0.868358   \n",
       "16  cardio  perceptron     5         0.65920         0.636333      0.751293   \n",
       "17  cardio  perceptron   avg         0.62940         0.661648      0.684939   \n",
       "18  cardio         knn     1         0.73200         0.771605      0.654187   \n",
       "19  cardio         knn     2         0.71840         0.768868      0.639717   \n",
       "20  cardio         knn     3         0.72720         0.773848      0.654467   \n",
       "21  cardio         knn     4         0.72880         0.763087      0.670500   \n",
       "22  cardio         knn     5         0.72820         0.753292      0.682849   \n",
       "23  cardio         knn   avg         0.72692         0.766140      0.660344   \n",
       "24  cardio      forest     1         0.81500         0.823042      0.799517   \n",
       "25  cardio      forest     2         0.81860         0.835035      0.802590   \n",
       "26  cardio      forest     3         0.82020         0.846121      0.789847   \n",
       "27  cardio      forest     4         0.82560         0.843750      0.802934   \n",
       "28  cardio      forest     5         0.81320         0.819765      0.805412   \n",
       "29  cardio      forest   avg         0.81852         0.833543      0.800060   \n",
       "30  cardio         svm     1         0.74720         0.778793      0.685990   \n",
       "31  cardio         svm     2         0.73520         0.774933      0.677002   \n",
       "32  cardio         svm     3         0.74400         0.792575      0.672176   \n",
       "33  cardio         svm     4         0.74440         0.779928      0.687153   \n",
       "34  cardio         svm     5         0.73800         0.768887      0.684441   \n",
       "35  cardio         svm   avg         0.74176         0.779023      0.681352   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.796105  0.705400   0.726756       9.422260       0.718092   \n",
       "1            0.724307  0.736182   0.730678       9.297947       0.716569   \n",
       "2            0.801545  0.709966   0.728793       9.408441       0.723985   \n",
       "3            0.790557  0.724413   0.737665       9.076873       0.724569   \n",
       "4            0.823080  0.710762   0.735456       9.152846       0.726877   \n",
       "5            0.787119  0.717344   0.731870       9.271673       0.722018   \n",
       "6            0.785374  0.687500   0.711527       9.947254       0.704323   \n",
       "7            0.508564  0.691879   0.643803      12.213104       0.644538   \n",
       "8            0.647011  0.693870   0.679861      11.038732       0.686446   \n",
       "9            0.636400  0.657647   0.650674      12.061085       0.660569   \n",
       "10           0.737435  0.686580   0.698005      10.437723       0.702246   \n",
       "11           0.662957  0.683495   0.676774      11.139579       0.679625   \n",
       "12           0.883148  0.578665   0.669231      11.377120       0.666985   \n",
       "13           0.556688  0.696899   0.659820      11.681188       0.663754   \n",
       "14           0.803579  0.660465   0.695178      10.589666       0.697246   \n",
       "15           0.048426  0.619519   0.458392      18.582239       0.458985   \n",
       "16           0.566144  0.689051   0.658719      11.770988       0.656231   \n",
       "17           0.571597  0.648920   0.628268      12.800240       0.628640   \n",
       "18           0.808824  0.708061   0.731505       9.256469       0.719692   \n",
       "19           0.800163  0.698372   0.719940       9.726198       0.721292   \n",
       "20           0.802359  0.709168   0.728413       9.422256       0.719231   \n",
       "21           0.788136  0.713803   0.729318       9.367000       0.715015   \n",
       "22           0.774025  0.716343   0.728437       9.387729       0.720754   \n",
       "23           0.794701  0.709150   0.727523       9.431930       0.719197   \n",
       "24           0.830286  0.811109   0.814902       6.389742       0.728723   \n",
       "25           0.835237  0.818491   0.818913       6.265399       0.727477   \n",
       "26           0.851566  0.817016   0.820706       6.210130       0.728785   \n",
       "27           0.848668  0.822836   0.825801       6.023623       0.726969   \n",
       "28           0.821070  0.812525   0.813241       6.451915       0.728600   \n",
       "29           0.837365  0.816395   0.818713       6.268162       0.728111   \n",
       "30           0.807631  0.729452   0.746811       8.731480       0.722677   \n",
       "31           0.795677  0.722664   0.736339       9.145948       0.728338   \n",
       "32           0.818219  0.727428   0.745198       8.841998       0.727431   \n",
       "33           0.802663  0.730607   0.744908       8.828189       0.726185   \n",
       "34           0.792119  0.724211   0.738280       9.049242       0.728062   \n",
       "35           0.803262  0.726872   0.742307       8.919372       0.726538   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.751375     0.651762          0.784402  0.698032  0.718082   \n",
       "1         0.713967     0.720638          0.712518  0.717287  0.716578   \n",
       "2         0.753861     0.663574          0.784166  0.705842  0.723870   \n",
       "3         0.741616     0.688172          0.760870  0.713895  0.724521   \n",
       "4         0.773141     0.641379          0.812196  0.701123  0.726788   \n",
       "5         0.746792     0.673105          0.770831  0.707236  0.721968   \n",
       "6         0.737496     0.634344          0.774281  0.682042  0.704312   \n",
       "7         0.611887     0.786316          0.503362  0.688221  0.644839   \n",
       "8         0.672761     0.723719          0.649315  0.697310  0.686517   \n",
       "9         0.652315     0.685738          0.635467  0.668609  0.660602   \n",
       "10        0.713969     0.673813          0.730620  0.693310  0.702216   \n",
       "11        0.677686     0.700786          0.658609  0.685898  0.679697   \n",
       "12        0.790375     0.454378          0.879526  0.577028  0.666952   \n",
       "13        0.633959     0.771577          0.556388  0.696031  0.663982   \n",
       "14        0.745791     0.596738          0.797371  0.662990  0.697055   \n",
       "15        0.477269     0.876236          0.042836  0.617952  0.459536   \n",
       "16        0.629263     0.758794          0.553882  0.687984  0.656338   \n",
       "17        0.655331     0.691545          0.566001  0.648397  0.628773   \n",
       "18        0.758315     0.644807          0.794555  0.696970  0.719681   \n",
       "19        0.763579     0.639357          0.802880  0.695969  0.721119   \n",
       "20        0.751721     0.653092          0.785118  0.698944  0.719105   \n",
       "21        0.737789     0.665958          0.763943  0.700036  0.714951   \n",
       "22        0.736901     0.685764          0.755671  0.710413  0.720717   \n",
       "23        0.749661     0.657796          0.780433  0.700466  0.719114   \n",
       "24        0.737109     0.710909          0.746531  0.723772  0.728720   \n",
       "25        0.734280     0.711141          0.743744  0.722525  0.727442   \n",
       "26        0.735730     0.712436          0.745071  0.723895  0.728753   \n",
       "27        0.732518     0.713898          0.740006  0.723088  0.726952   \n",
       "28        0.731575     0.721278          0.735907  0.726390  0.728592   \n",
       "29        0.734242     0.713932          0.742252  0.723934  0.728092   \n",
       "30        0.752822     0.662933          0.782403  0.705024  0.722668   \n",
       "31        0.757845     0.669421          0.787006  0.710894  0.728214   \n",
       "32        0.752808     0.675689          0.778975  0.712167  0.727332   \n",
       "33        0.749125     0.679052          0.773192  0.712370  0.726122   \n",
       "34        0.748655     0.685794          0.770240  0.715847  0.728017   \n",
       "35        0.752251     0.674578          0.778363  0.711260  0.726471   \n",
       "\n",
       "    test_logloss  \n",
       "0       9.736833  \n",
       "1       9.789467  \n",
       "2       9.533320  \n",
       "3       9.513137  \n",
       "4       9.433412  \n",
       "5       9.601234  \n",
       "6      10.212409  \n",
       "7      12.277406  \n",
       "8      10.829907  \n",
       "9      11.723669  \n",
       "10     10.284161  \n",
       "11     11.065510  \n",
       "12     11.501992  \n",
       "13     11.613708  \n",
       "14     10.456829  \n",
       "15     18.686393  \n",
       "16     11.873547  \n",
       "17     12.826494  \n",
       "18      9.681567  \n",
       "19      9.626302  \n",
       "20      9.697512  \n",
       "21      9.843114  \n",
       "22      9.644918  \n",
       "23      9.698683  \n",
       "24      9.369674  \n",
       "25      9.412716  \n",
       "26      9.367550  \n",
       "27      9.430253  \n",
       "28      9.373930  \n",
       "29      9.390825  \n",
       "30      9.578487  \n",
       "31      9.382942  \n",
       "32      9.414296  \n",
       "33      9.457339  \n",
       "34      9.392514  \n",
       "35      9.445116  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/cardio_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Australian Rain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7874 0.7874    nan 0.8418 0.7874 0.7874    nan 0.8418 0.7874 0.7874\n",
      "    nan 0.842  0.7874 0.8228    nan 0.8418 0.7874 0.8408    nan 0.8418\n",
      " 0.8338 0.8414    nan 0.8418 0.8404 0.8418    nan 0.8418 0.8418 0.8416\n",
      "    nan 0.8418 0.8418 0.8418    nan 0.8416 0.8418 0.8418    nan 0.8422\n",
      " 0.8418 0.8418    nan 0.8418 0.8418 0.8418    nan 0.8418 0.842  0.8418\n",
      "    nan 0.8418]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.78   0.78      nan 0.8418 0.78   0.78      nan 0.8412 0.78   0.78\n",
      "    nan 0.8416 0.78   0.8304    nan 0.8412 0.78   0.8412    nan 0.8416\n",
      " 0.8382 0.8414    nan 0.8416 0.8408 0.8414    nan 0.8414 0.8408 0.8414\n",
      "    nan 0.8416 0.8412 0.8414    nan 0.8416 0.8416 0.8416    nan 0.8418\n",
      " 0.8414 0.8416    nan 0.8416 0.8414 0.841     nan 0.8416 0.8416 0.8412\n",
      "    nan 0.8412]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7848 0.7848    nan 0.8366 0.7848 0.7848    nan 0.8366 0.7848 0.7848\n",
      "    nan 0.8366 0.7848 0.8252    nan 0.8366 0.7848 0.8354    nan 0.8368\n",
      " 0.8336 0.8366    nan 0.8368 0.8348 0.8368    nan 0.8364 0.8366 0.8368\n",
      "    nan 0.8366 0.8366 0.837     nan 0.8368 0.8366 0.837     nan 0.8368\n",
      " 0.8368 0.8368    nan 0.837  0.8368 0.8366    nan 0.8366 0.8368 0.8368\n",
      "    nan 0.8368]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7742 0.7742    nan 0.8368 0.7742 0.7742    nan 0.8368 0.7742 0.7742\n",
      "    nan 0.8366 0.7742 0.825     nan 0.8366 0.7742 0.8356    nan 0.8368\n",
      " 0.8292 0.8368    nan 0.8366 0.8364 0.8368    nan 0.8368 0.8366 0.8368\n",
      "    nan 0.8366 0.8368 0.8368    nan 0.8368 0.8368 0.8368    nan 0.8368\n",
      " 0.8366 0.8368    nan 0.8366 0.8368 0.8366    nan 0.8368 0.8366 0.8368\n",
      "    nan 0.8368]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7768 0.7768    nan 0.8386 0.7768 0.7768    nan 0.8382 0.7768 0.777\n",
      "    nan 0.8382 0.7768 0.8306    nan 0.8382 0.7768 0.839     nan 0.8382\n",
      " 0.8344 0.838     nan 0.8384 0.8382 0.8386    nan 0.8386 0.8382 0.8382\n",
      "    nan 0.8382 0.8382 0.8382    nan 0.8386 0.8382 0.8384    nan 0.8382\n",
      " 0.838  0.8382    nan 0.8384 0.8384 0.8384    nan 0.8384 0.8382 0.8382\n",
      "    nan 0.8382]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8494 0.8502 0.8496 0.8498 0.8486 0.8484 0.8486]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8522 0.852  0.8508 0.8506 0.8506 0.8502 0.85  ]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8408 0.8408 0.842  0.8422 0.8414 0.8418 0.8402]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8448 0.8462 0.8458 0.8458 0.8468 0.8462 0.8444]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8512 0.848  0.8496 0.85   0.848  0.8484 0.8462]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84920</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.394167</td>\n",
       "      <td>0.972060</td>\n",
       "      <td>0.526382</td>\n",
       "      <td>0.683114</td>\n",
       "      <td>5.208465e+00</td>\n",
       "      <td>0.832130</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>0.963920</td>\n",
       "      <td>0.486978</td>\n",
       "      <td>0.663550</td>\n",
       "      <td>5.798042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.760962</td>\n",
       "      <td>0.489091</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.595462</td>\n",
       "      <td>0.722879</td>\n",
       "      <td>5.049596e+00</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.670925</td>\n",
       "      <td>0.435163</td>\n",
       "      <td>0.940109</td>\n",
       "      <td>0.527917</td>\n",
       "      <td>0.687636</td>\n",
       "      <td>5.890023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84280</td>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.378253</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.508750</td>\n",
       "      <td>0.674218</td>\n",
       "      <td>5.429514e+00</td>\n",
       "      <td>0.829012</td>\n",
       "      <td>0.724368</td>\n",
       "      <td>0.355540</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.476970</td>\n",
       "      <td>0.658770</td>\n",
       "      <td>5.905746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.745074</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>0.946525</td>\n",
       "      <td>0.623390</td>\n",
       "      <td>0.741199</td>\n",
       "      <td>5.049602e+00</td>\n",
       "      <td>0.828855</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.457168</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.539068</td>\n",
       "      <td>0.695096</td>\n",
       "      <td>5.911174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86220</td>\n",
       "      <td>0.787349</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>4.759469e+00</td>\n",
       "      <td>0.830016</td>\n",
       "      <td>0.663578</td>\n",
       "      <td>0.453984</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>0.539127</td>\n",
       "      <td>0.694722</td>\n",
       "      <td>5.871091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85236</td>\n",
       "      <td>0.772432</td>\n",
       "      <td>0.464315</td>\n",
       "      <td>0.960951</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.712633</td>\n",
       "      <td>5.099329e+00</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.514012</td>\n",
       "      <td>0.679955</td>\n",
       "      <td>5.875215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84360</td>\n",
       "      <td>0.727715</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.957328</td>\n",
       "      <td>0.534524</td>\n",
       "      <td>0.689859</td>\n",
       "      <td>5.401891e+00</td>\n",
       "      <td>0.838167</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>0.401473</td>\n",
       "      <td>0.960892</td>\n",
       "      <td>0.521180</td>\n",
       "      <td>0.681183</td>\n",
       "      <td>5.589523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.84300</td>\n",
       "      <td>0.727931</td>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.951795</td>\n",
       "      <td>0.561697</td>\n",
       "      <td>0.704534</td>\n",
       "      <td>5.422618e+00</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.443773</td>\n",
       "      <td>0.950193</td>\n",
       "      <td>0.547437</td>\n",
       "      <td>0.696983</td>\n",
       "      <td>5.552891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83620</td>\n",
       "      <td>0.712397</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>0.955657</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>0.678108</td>\n",
       "      <td>5.657479e+00</td>\n",
       "      <td>0.839784</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.426674</td>\n",
       "      <td>0.955818</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.691246</td>\n",
       "      <td>5.533707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83840</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.452613</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>0.558470</td>\n",
       "      <td>0.701765</td>\n",
       "      <td>5.581497e+00</td>\n",
       "      <td>0.839193</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>0.430434</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.539576</td>\n",
       "      <td>0.692093</td>\n",
       "      <td>5.554118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84080</td>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.436380</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>0.550282</td>\n",
       "      <td>0.696692</td>\n",
       "      <td>5.498600e+00</td>\n",
       "      <td>0.837747</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.414193</td>\n",
       "      <td>0.956517</td>\n",
       "      <td>0.527884</td>\n",
       "      <td>0.685355</td>\n",
       "      <td>5.604033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.84040</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>0.954540</td>\n",
       "      <td>0.543553</td>\n",
       "      <td>0.694191</td>\n",
       "      <td>5.512417e+00</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.423310</td>\n",
       "      <td>0.955434</td>\n",
       "      <td>0.534963</td>\n",
       "      <td>0.689372</td>\n",
       "      <td>5.566854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83660</td>\n",
       "      <td>0.738372</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.965710</td>\n",
       "      <td>0.482584</td>\n",
       "      <td>0.662065</td>\n",
       "      <td>5.643658e+00</td>\n",
       "      <td>0.834245</td>\n",
       "      <td>0.767168</td>\n",
       "      <td>0.350944</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.481585</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>5.725007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83440</td>\n",
       "      <td>0.634387</td>\n",
       "      <td>0.583636</td>\n",
       "      <td>0.905128</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.744382</td>\n",
       "      <td>5.719681e+00</td>\n",
       "      <td>0.826819</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.566559</td>\n",
       "      <td>0.899848</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>0.733204</td>\n",
       "      <td>5.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.78480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.780713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>7.557171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80020</td>\n",
       "      <td>0.903448</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.207772</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>6.900850e+00</td>\n",
       "      <td>0.801096</td>\n",
       "      <td>0.867674</td>\n",
       "      <td>0.108286</td>\n",
       "      <td>0.995369</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.551828</td>\n",
       "      <td>6.869890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.80604</td>\n",
       "      <td>0.455242</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.973447</td>\n",
       "      <td>0.259662</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>6.699158e+00</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.649669</td>\n",
       "      <td>0.205256</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.252840</td>\n",
       "      <td>0.589156</td>\n",
       "      <td>6.741496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85660</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.418627</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.553827</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>4.952876e+00</td>\n",
       "      <td>0.835462</td>\n",
       "      <td>0.761172</td>\n",
       "      <td>0.364282</td>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.492746</td>\n",
       "      <td>0.666080</td>\n",
       "      <td>5.682959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>0.835463</td>\n",
       "      <td>0.475455</td>\n",
       "      <td>0.973590</td>\n",
       "      <td>0.606025</td>\n",
       "      <td>0.724522</td>\n",
       "      <td>4.697290e+00</td>\n",
       "      <td>0.837456</td>\n",
       "      <td>0.730827</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>0.957760</td>\n",
       "      <td>0.524245</td>\n",
       "      <td>0.683237</td>\n",
       "      <td>5.614114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83920</td>\n",
       "      <td>0.770916</td>\n",
       "      <td>0.359665</td>\n",
       "      <td>0.970693</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>5.553854e+00</td>\n",
       "      <td>0.836437</td>\n",
       "      <td>0.763305</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.496890</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>5.649271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84760</td>\n",
       "      <td>0.814751</td>\n",
       "      <td>0.420726</td>\n",
       "      <td>0.972100</td>\n",
       "      <td>0.554907</td>\n",
       "      <td>0.696413</td>\n",
       "      <td>5.263727e+00</td>\n",
       "      <td>0.837584</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.385001</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.509282</td>\n",
       "      <td>0.674713</td>\n",
       "      <td>5.609684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.457885</td>\n",
       "      <td>0.967817</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.712851</td>\n",
       "      <td>5.042681e+00</td>\n",
       "      <td>0.837213</td>\n",
       "      <td>0.731799</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.958359</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.681774</td>\n",
       "      <td>5.622475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85228</td>\n",
       "      <td>0.808521</td>\n",
       "      <td>0.426472</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.699141</td>\n",
       "      <td>5.102086e+00</td>\n",
       "      <td>0.836830</td>\n",
       "      <td>0.747830</td>\n",
       "      <td>0.386304</td>\n",
       "      <td>0.963268</td>\n",
       "      <td>0.508949</td>\n",
       "      <td>0.674786</td>\n",
       "      <td>5.635701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992894</td>\n",
       "      <td>0.992944</td>\n",
       "      <td>1.036163e-01</td>\n",
       "      <td>0.842881</td>\n",
       "      <td>0.768038</td>\n",
       "      <td>0.406601</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>0.686045</td>\n",
       "      <td>5.426736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844148</td>\n",
       "      <td>0.738563</td>\n",
       "      <td>0.446925</td>\n",
       "      <td>0.955608</td>\n",
       "      <td>0.556871</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>5.382972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.96800</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.852230</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.919759</td>\n",
       "      <td>0.925988</td>\n",
       "      <td>1.105241e+00</td>\n",
       "      <td>0.843963</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.426739</td>\n",
       "      <td>0.961152</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>0.693946</td>\n",
       "      <td>5.389362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94320</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>1.961805e+00</td>\n",
       "      <td>0.843144</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.424678</td>\n",
       "      <td>0.960424</td>\n",
       "      <td>0.542411</td>\n",
       "      <td>0.692551</td>\n",
       "      <td>5.417641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844532</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.445402</td>\n",
       "      <td>0.956454</td>\n",
       "      <td>0.556510</td>\n",
       "      <td>0.700928</td>\n",
       "      <td>5.369693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.919617</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.954131</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>6.341324e-01</td>\n",
       "      <td>0.843733</td>\n",
       "      <td>0.750753</td>\n",
       "      <td>0.430069</td>\n",
       "      <td>0.959825</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>5.397281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0      aus        tree     1         0.84920         0.792060      0.394167   \n",
       "1      aus        tree     2         0.85380         0.760962      0.489091   \n",
       "2      aus        tree     3         0.84280         0.776718      0.378253   \n",
       "3      aus        tree     4         0.85380         0.745074      0.535872   \n",
       "4      aus        tree     5         0.86220         0.787349      0.524194   \n",
       "5      aus        tree   avg         0.85236         0.772432      0.464315   \n",
       "6      aus     log_reg     1         0.84360         0.727715      0.422389   \n",
       "7      aus     log_reg     2         0.84300         0.727931      0.457273   \n",
       "8      aus     log_reg     3         0.83620         0.712397      0.400558   \n",
       "9      aus     log_reg     4         0.83840         0.728959      0.452613   \n",
       "10     aus     log_reg     5         0.84080         0.744648      0.436380   \n",
       "11     aus     log_reg   avg         0.84040         0.728330      0.433843   \n",
       "12     aus  perceptron     1         0.83660         0.738372      0.358420   \n",
       "13     aus  perceptron     2         0.83440         0.634387      0.583636   \n",
       "14     aus  perceptron     3         0.78480         0.000000      0.000000   \n",
       "15     aus  perceptron     4         0.77420         0.000000      0.000000   \n",
       "16     aus  perceptron     5         0.80020         0.903448      0.117384   \n",
       "17     aus  perceptron   avg         0.80604         0.455242      0.211888   \n",
       "18     aus         knn     1         0.85660         0.818015      0.418627   \n",
       "19     aus         knn     2         0.86400         0.835463      0.475455   \n",
       "20     aus         knn     3         0.83920         0.770916      0.359665   \n",
       "21     aus         knn     4         0.84760         0.814751      0.420726   \n",
       "22     aus         knn     5         0.85400         0.803459      0.457885   \n",
       "23     aus         knn   avg         0.85228         0.808521      0.426472   \n",
       "24     aus      forest     1         0.99700         1.000000      0.985889   \n",
       "25     aus      forest     2         1.00000         1.000000      1.000000   \n",
       "26     aus      forest     3         0.96800         0.998911      0.852230   \n",
       "27     aus      forest     4         0.94320         0.985075      0.759965   \n",
       "28     aus      forest     5         1.00000         1.000000      1.000000   \n",
       "29     aus      forest   avg         0.98164         0.996797      0.919617   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.972060  0.526382   0.683114   5.208465e+00       0.832130   \n",
       "1            0.956667  0.595462   0.722879   5.049596e+00       0.829467   \n",
       "2            0.970183  0.508750   0.674218   5.429514e+00       0.829012   \n",
       "3            0.946525  0.623390   0.741199   5.049602e+00       0.828855   \n",
       "4            0.959320  0.629371   0.741757   4.759469e+00       0.830016   \n",
       "5            0.960951  0.576671   0.712633   5.099329e+00       0.829896   \n",
       "6            0.957328  0.534524   0.689859   5.401891e+00       0.838167   \n",
       "7            0.951795  0.561697   0.704534   5.422618e+00       0.839228   \n",
       "8            0.955657  0.512790   0.678108   5.657479e+00       0.839784   \n",
       "9            0.950917  0.558470   0.701765   5.581497e+00       0.839193   \n",
       "10           0.957003  0.550282   0.696692   5.498600e+00       0.837747   \n",
       "11           0.954540  0.543553   0.694191   5.512417e+00       0.838824   \n",
       "12           0.965710  0.482584   0.662065   5.643658e+00       0.834245   \n",
       "13           0.905128  0.607955   0.744382   5.719681e+00       0.826819   \n",
       "14           1.000000  0.000000   0.500000   7.432745e+00       0.780713   \n",
       "15           1.000000  0.000000   0.500000   7.798856e+00       0.781197   \n",
       "16           0.996395  0.207772   0.556889   6.900850e+00       0.801096   \n",
       "17           0.973447  0.259662   0.592667   6.699158e+00       0.804814   \n",
       "18           0.974854  0.553827   0.696740   4.952876e+00       0.835462   \n",
       "19           0.973590  0.606025   0.724522   4.697290e+00       0.837456   \n",
       "20           0.970693  0.490494   0.665179   5.553854e+00       0.836437   \n",
       "21           0.972100  0.554907   0.696413   5.263727e+00       0.837584   \n",
       "22           0.967817  0.583333   0.712851   5.042681e+00       0.837213   \n",
       "23           0.971811  0.557717   0.699141   5.102086e+00       0.836830   \n",
       "24           1.000000  0.992894   0.992944   1.036163e-01       0.842881   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       0.844148   \n",
       "26           0.999745  0.919759   0.925988   1.105241e+00       0.843963   \n",
       "27           0.996642  0.858000   0.878303   1.961805e+00       0.843144   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       0.844532   \n",
       "29           0.999277  0.954131   0.959447   6.341324e-01       0.843733   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.738826     0.363179          0.963920  0.486978  0.663550   \n",
       "1         0.670925     0.435163          0.940109  0.527917  0.687636   \n",
       "2         0.724368     0.355540          0.962000  0.476970  0.658770   \n",
       "3         0.656716     0.457168          0.933025  0.539068  0.695096   \n",
       "4         0.663578     0.453984          0.935460  0.539127  0.694722   \n",
       "5         0.690883     0.413007          0.946903  0.514012  0.679955   \n",
       "6         0.742602     0.401473          0.960892  0.521180  0.681183   \n",
       "7         0.714293     0.443773          0.950193  0.547437  0.696983   \n",
       "8         0.730639     0.426674          0.955818  0.538739  0.691246   \n",
       "9         0.722869     0.430434          0.953752  0.539576  0.692093   \n",
       "10        0.727600     0.414193          0.956517  0.527884  0.685355   \n",
       "11        0.727600     0.423310          0.955434  0.534963  0.689372   \n",
       "12        0.767168     0.350944          0.970067  0.481585  0.660506   \n",
       "13        0.613504     0.566559          0.899848  0.589098  0.733204   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        1.000000     0.000488          1.000000  0.000975  0.500244   \n",
       "16        0.867674     0.108286          0.995369  0.192543  0.551828   \n",
       "17        0.649669     0.205256          0.973057  0.252840  0.589156   \n",
       "18        0.761172     0.364282          0.967878  0.492746  0.666080   \n",
       "19        0.730827     0.408714          0.957760  0.524245  0.683237   \n",
       "20        0.763305     0.368332          0.967919  0.496890  0.668125   \n",
       "21        0.752049     0.385001          0.964425  0.509282  0.674713   \n",
       "22        0.731799     0.405188          0.958359  0.521583  0.681774   \n",
       "23        0.747830     0.386304          0.963268  0.508949  0.674786   \n",
       "24        0.768038     0.406601          0.965489  0.531712  0.686045   \n",
       "25        0.738563     0.446925          0.955608  0.556871  0.701267   \n",
       "26        0.755229     0.426739          0.961152  0.545338  0.693946   \n",
       "27        0.750460     0.424678          0.960424  0.542411  0.692551   \n",
       "28        0.741476     0.445402          0.956454  0.556510  0.700928   \n",
       "29        0.750753     0.430069          0.959825  0.546568  0.694947   \n",
       "\n",
       "    test_logloss  \n",
       "0       5.798042  \n",
       "1       5.890023  \n",
       "2       5.905746  \n",
       "3       5.911174  \n",
       "4       5.871091  \n",
       "5       5.875215  \n",
       "6       5.589523  \n",
       "7       5.552891  \n",
       "8       5.533707  \n",
       "9       5.554118  \n",
       "10      5.604033  \n",
       "11      5.566854  \n",
       "12      5.725007  \n",
       "13      5.981522  \n",
       "14      7.573892  \n",
       "15      7.557171  \n",
       "16      6.869890  \n",
       "17      6.741496  \n",
       "18      5.682959  \n",
       "19      5.614114  \n",
       "20      5.649271  \n",
       "21      5.609684  \n",
       "22      5.622475  \n",
       "23      5.635701  \n",
       "24      5.426736  \n",
       "25      5.382972  \n",
       "26      5.389362  \n",
       "27      5.417641  \n",
       "28      5.369693  \n",
       "29      5.397281  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on Australian rain dataset\n",
    "aus_results_no_svm = perform_trials('aus', models_without_svm, aus_X, aus_y)\n",
    "aus_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8552</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.482596</td>\n",
       "      <td>0.955804</td>\n",
       "      <td>0.586286</td>\n",
       "      <td>0.719200</td>\n",
       "      <td>5.001243</td>\n",
       "      <td>0.843778</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.450899</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>0.558766</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>5.395760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.613233</td>\n",
       "      <td>0.734860</td>\n",
       "      <td>4.966706</td>\n",
       "      <td>0.843671</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.576182</td>\n",
       "      <td>0.714647</td>\n",
       "      <td>5.399454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.744838</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.575827</td>\n",
       "      <td>0.712622</td>\n",
       "      <td>5.139398</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>0.721490</td>\n",
       "      <td>0.462160</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>0.563417</td>\n",
       "      <td>0.706025</td>\n",
       "      <td>5.424778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.729763</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.943942</td>\n",
       "      <td>0.606625</td>\n",
       "      <td>0.731493</td>\n",
       "      <td>5.249929</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>0.694537</td>\n",
       "      <td>0.487089</td>\n",
       "      <td>0.939961</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.713525</td>\n",
       "      <td>5.497816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.758667</td>\n",
       "      <td>0.509857</td>\n",
       "      <td>0.953399</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>5.028875</td>\n",
       "      <td>0.844297</td>\n",
       "      <td>0.715122</td>\n",
       "      <td>0.480414</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.574729</td>\n",
       "      <td>0.713374</td>\n",
       "      <td>5.377814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.746196</td>\n",
       "      <td>0.499802</td>\n",
       "      <td>0.952119</td>\n",
       "      <td>0.598366</td>\n",
       "      <td>0.725960</td>\n",
       "      <td>5.077230</td>\n",
       "      <td>0.843101</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.569139</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>5.419124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0     aus   svm     1          0.8552         0.746725      0.482596   \n",
       "1     aus   svm     2          0.8562         0.750988      0.518182   \n",
       "2     aus   svm     3          0.8512         0.744838      0.469331   \n",
       "3     aus   svm     4          0.8480         0.729763      0.519043   \n",
       "4     aus   svm     5          0.8544         0.758667      0.509857   \n",
       "5     aus   svm   avg          0.8530         0.746196      0.499802   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0           0.955804  0.586286   0.719200       5.001243       0.843778   \n",
       "1           0.951538  0.613233   0.734860       4.966706       0.843671   \n",
       "2           0.955912  0.575827   0.712622       5.139398       0.842937   \n",
       "3           0.943942  0.606625   0.731493       5.249929       0.840823   \n",
       "4           0.953399  0.609861   0.731628       5.028875       0.844297   \n",
       "5           0.952119  0.598366   0.725960       5.077230       0.843101   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.734472     0.450899          0.954189  0.558766  0.702544   \n",
       "1        0.709647     0.484973          0.944321  0.576182  0.714647   \n",
       "2        0.721490     0.462160          0.949890  0.563417  0.706025   \n",
       "3        0.694537     0.487089          0.939961  0.572603  0.713525   \n",
       "4        0.715122     0.480414          0.946335  0.574729  0.713374   \n",
       "5        0.715054     0.473107          0.946939  0.569139  0.710023   \n",
       "\n",
       "   test_logloss  \n",
       "0      5.395760  \n",
       "1      5.399454  \n",
       "2      5.424778  \n",
       "3      5.497816  \n",
       "4      5.377814  \n",
       "5      5.419124  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running SVM algorithm on Australian rain dataset, generally take longer time to run than other algorithms combined\n",
    "aus_results_svm = perform_trials('aus', models_only_svm, aus_X, aus_y)\n",
    "aus_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results of svm and non-svm algorithms and save as a csv file\n",
    "aus_final_results = aus_results_no_svm.append(aus_results_svm, ignore_index=True)\n",
    "aus_final_results.to_csv('results/aus_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84920</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.394167</td>\n",
       "      <td>0.972060</td>\n",
       "      <td>0.526382</td>\n",
       "      <td>0.683114</td>\n",
       "      <td>5.208465e+00</td>\n",
       "      <td>0.832130</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>0.963920</td>\n",
       "      <td>0.486978</td>\n",
       "      <td>0.663550</td>\n",
       "      <td>5.798042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.760962</td>\n",
       "      <td>0.489091</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.595462</td>\n",
       "      <td>0.722879</td>\n",
       "      <td>5.049596e+00</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.670925</td>\n",
       "      <td>0.435163</td>\n",
       "      <td>0.940109</td>\n",
       "      <td>0.527917</td>\n",
       "      <td>0.687636</td>\n",
       "      <td>5.890023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84280</td>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.378253</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.508750</td>\n",
       "      <td>0.674218</td>\n",
       "      <td>5.429514e+00</td>\n",
       "      <td>0.829012</td>\n",
       "      <td>0.724368</td>\n",
       "      <td>0.355540</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.476970</td>\n",
       "      <td>0.658770</td>\n",
       "      <td>5.905746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.745074</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>0.946525</td>\n",
       "      <td>0.623390</td>\n",
       "      <td>0.741199</td>\n",
       "      <td>5.049602e+00</td>\n",
       "      <td>0.828855</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.457168</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.539068</td>\n",
       "      <td>0.695096</td>\n",
       "      <td>5.911174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86220</td>\n",
       "      <td>0.787349</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>4.759469e+00</td>\n",
       "      <td>0.830016</td>\n",
       "      <td>0.663578</td>\n",
       "      <td>0.453984</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>0.539127</td>\n",
       "      <td>0.694722</td>\n",
       "      <td>5.871091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85236</td>\n",
       "      <td>0.772432</td>\n",
       "      <td>0.464315</td>\n",
       "      <td>0.960951</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.712633</td>\n",
       "      <td>5.099329e+00</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.514012</td>\n",
       "      <td>0.679955</td>\n",
       "      <td>5.875215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84360</td>\n",
       "      <td>0.727715</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.957328</td>\n",
       "      <td>0.534524</td>\n",
       "      <td>0.689859</td>\n",
       "      <td>5.401891e+00</td>\n",
       "      <td>0.838167</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>0.401473</td>\n",
       "      <td>0.960892</td>\n",
       "      <td>0.521180</td>\n",
       "      <td>0.681183</td>\n",
       "      <td>5.589523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.84300</td>\n",
       "      <td>0.727931</td>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.951795</td>\n",
       "      <td>0.561697</td>\n",
       "      <td>0.704534</td>\n",
       "      <td>5.422618e+00</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.443773</td>\n",
       "      <td>0.950193</td>\n",
       "      <td>0.547437</td>\n",
       "      <td>0.696983</td>\n",
       "      <td>5.552891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83620</td>\n",
       "      <td>0.712397</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>0.955657</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>0.678108</td>\n",
       "      <td>5.657479e+00</td>\n",
       "      <td>0.839784</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.426674</td>\n",
       "      <td>0.955818</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.691246</td>\n",
       "      <td>5.533707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83840</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.452613</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>0.558470</td>\n",
       "      <td>0.701765</td>\n",
       "      <td>5.581497e+00</td>\n",
       "      <td>0.839193</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>0.430434</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.539576</td>\n",
       "      <td>0.692093</td>\n",
       "      <td>5.554118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84080</td>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.436380</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>0.550282</td>\n",
       "      <td>0.696692</td>\n",
       "      <td>5.498600e+00</td>\n",
       "      <td>0.837747</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.414193</td>\n",
       "      <td>0.956517</td>\n",
       "      <td>0.527884</td>\n",
       "      <td>0.685355</td>\n",
       "      <td>5.604033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.84040</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>0.954540</td>\n",
       "      <td>0.543553</td>\n",
       "      <td>0.694191</td>\n",
       "      <td>5.512417e+00</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.423310</td>\n",
       "      <td>0.955434</td>\n",
       "      <td>0.534963</td>\n",
       "      <td>0.689372</td>\n",
       "      <td>5.566854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83660</td>\n",
       "      <td>0.738372</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.965710</td>\n",
       "      <td>0.482584</td>\n",
       "      <td>0.662065</td>\n",
       "      <td>5.643658e+00</td>\n",
       "      <td>0.834245</td>\n",
       "      <td>0.767168</td>\n",
       "      <td>0.350944</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.481585</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>5.725007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83440</td>\n",
       "      <td>0.634387</td>\n",
       "      <td>0.583636</td>\n",
       "      <td>0.905128</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.744382</td>\n",
       "      <td>5.719681e+00</td>\n",
       "      <td>0.826819</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.566559</td>\n",
       "      <td>0.899848</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>0.733204</td>\n",
       "      <td>5.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.78480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.780713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>7.557171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80020</td>\n",
       "      <td>0.903448</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.207772</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>6.900850e+00</td>\n",
       "      <td>0.801096</td>\n",
       "      <td>0.867674</td>\n",
       "      <td>0.108286</td>\n",
       "      <td>0.995369</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.551828</td>\n",
       "      <td>6.869890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.80604</td>\n",
       "      <td>0.455242</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.973447</td>\n",
       "      <td>0.259662</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>6.699158e+00</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.649669</td>\n",
       "      <td>0.205256</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.252840</td>\n",
       "      <td>0.589156</td>\n",
       "      <td>6.741496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85660</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.418627</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.553827</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>4.952876e+00</td>\n",
       "      <td>0.835462</td>\n",
       "      <td>0.761172</td>\n",
       "      <td>0.364282</td>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.492746</td>\n",
       "      <td>0.666080</td>\n",
       "      <td>5.682959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>0.835463</td>\n",
       "      <td>0.475455</td>\n",
       "      <td>0.973590</td>\n",
       "      <td>0.606025</td>\n",
       "      <td>0.724522</td>\n",
       "      <td>4.697290e+00</td>\n",
       "      <td>0.837456</td>\n",
       "      <td>0.730827</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>0.957760</td>\n",
       "      <td>0.524245</td>\n",
       "      <td>0.683237</td>\n",
       "      <td>5.614114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83920</td>\n",
       "      <td>0.770916</td>\n",
       "      <td>0.359665</td>\n",
       "      <td>0.970693</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>5.553854e+00</td>\n",
       "      <td>0.836437</td>\n",
       "      <td>0.763305</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.496890</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>5.649271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84760</td>\n",
       "      <td>0.814751</td>\n",
       "      <td>0.420726</td>\n",
       "      <td>0.972100</td>\n",
       "      <td>0.554907</td>\n",
       "      <td>0.696413</td>\n",
       "      <td>5.263727e+00</td>\n",
       "      <td>0.837584</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.385001</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.509282</td>\n",
       "      <td>0.674713</td>\n",
       "      <td>5.609684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.457885</td>\n",
       "      <td>0.967817</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.712851</td>\n",
       "      <td>5.042681e+00</td>\n",
       "      <td>0.837213</td>\n",
       "      <td>0.731799</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.958359</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.681774</td>\n",
       "      <td>5.622475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85228</td>\n",
       "      <td>0.808521</td>\n",
       "      <td>0.426472</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.699141</td>\n",
       "      <td>5.102086e+00</td>\n",
       "      <td>0.836830</td>\n",
       "      <td>0.747830</td>\n",
       "      <td>0.386304</td>\n",
       "      <td>0.963268</td>\n",
       "      <td>0.508949</td>\n",
       "      <td>0.674786</td>\n",
       "      <td>5.635701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992894</td>\n",
       "      <td>0.992944</td>\n",
       "      <td>1.036163e-01</td>\n",
       "      <td>0.842881</td>\n",
       "      <td>0.768038</td>\n",
       "      <td>0.406601</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>0.686045</td>\n",
       "      <td>5.426736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844148</td>\n",
       "      <td>0.738563</td>\n",
       "      <td>0.446925</td>\n",
       "      <td>0.955608</td>\n",
       "      <td>0.556871</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>5.382972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.96800</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.852230</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.919759</td>\n",
       "      <td>0.925988</td>\n",
       "      <td>1.105241e+00</td>\n",
       "      <td>0.843963</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.426739</td>\n",
       "      <td>0.961152</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>0.693946</td>\n",
       "      <td>5.389362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94320</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>1.961805e+00</td>\n",
       "      <td>0.843144</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.424678</td>\n",
       "      <td>0.960424</td>\n",
       "      <td>0.542411</td>\n",
       "      <td>0.692551</td>\n",
       "      <td>5.417641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844532</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.445402</td>\n",
       "      <td>0.956454</td>\n",
       "      <td>0.556510</td>\n",
       "      <td>0.700928</td>\n",
       "      <td>5.369693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.919617</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.954131</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>6.341324e-01</td>\n",
       "      <td>0.843733</td>\n",
       "      <td>0.750753</td>\n",
       "      <td>0.430069</td>\n",
       "      <td>0.959825</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>5.397281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85520</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.482596</td>\n",
       "      <td>0.955804</td>\n",
       "      <td>0.586286</td>\n",
       "      <td>0.719200</td>\n",
       "      <td>5.001243e+00</td>\n",
       "      <td>0.843778</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.450899</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>0.558766</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>5.395760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85620</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.613233</td>\n",
       "      <td>0.734860</td>\n",
       "      <td>4.966706e+00</td>\n",
       "      <td>0.843671</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.576182</td>\n",
       "      <td>0.714647</td>\n",
       "      <td>5.399454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85120</td>\n",
       "      <td>0.744838</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.575827</td>\n",
       "      <td>0.712622</td>\n",
       "      <td>5.139398e+00</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>0.721490</td>\n",
       "      <td>0.462160</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>0.563417</td>\n",
       "      <td>0.706025</td>\n",
       "      <td>5.424778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84800</td>\n",
       "      <td>0.729763</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.943942</td>\n",
       "      <td>0.606625</td>\n",
       "      <td>0.731493</td>\n",
       "      <td>5.249929e+00</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>0.694537</td>\n",
       "      <td>0.487089</td>\n",
       "      <td>0.939961</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.713525</td>\n",
       "      <td>5.497816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85440</td>\n",
       "      <td>0.758667</td>\n",
       "      <td>0.509857</td>\n",
       "      <td>0.953399</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>5.028875e+00</td>\n",
       "      <td>0.844297</td>\n",
       "      <td>0.715122</td>\n",
       "      <td>0.480414</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.574729</td>\n",
       "      <td>0.713374</td>\n",
       "      <td>5.377814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.746196</td>\n",
       "      <td>0.499802</td>\n",
       "      <td>0.952119</td>\n",
       "      <td>0.598366</td>\n",
       "      <td>0.725960</td>\n",
       "      <td>5.077230e+00</td>\n",
       "      <td>0.843101</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.569139</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>5.419124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0      aus        tree     1         0.84920         0.792060      0.394167   \n",
       "1      aus        tree     2         0.85380         0.760962      0.489091   \n",
       "2      aus        tree     3         0.84280         0.776718      0.378253   \n",
       "3      aus        tree     4         0.85380         0.745074      0.535872   \n",
       "4      aus        tree     5         0.86220         0.787349      0.524194   \n",
       "5      aus        tree   avg         0.85236         0.772432      0.464315   \n",
       "6      aus     log_reg     1         0.84360         0.727715      0.422389   \n",
       "7      aus     log_reg     2         0.84300         0.727931      0.457273   \n",
       "8      aus     log_reg     3         0.83620         0.712397      0.400558   \n",
       "9      aus     log_reg     4         0.83840         0.728959      0.452613   \n",
       "10     aus     log_reg     5         0.84080         0.744648      0.436380   \n",
       "11     aus     log_reg   avg         0.84040         0.728330      0.433843   \n",
       "12     aus  perceptron     1         0.83660         0.738372      0.358420   \n",
       "13     aus  perceptron     2         0.83440         0.634387      0.583636   \n",
       "14     aus  perceptron     3         0.78480         0.000000      0.000000   \n",
       "15     aus  perceptron     4         0.77420         0.000000      0.000000   \n",
       "16     aus  perceptron     5         0.80020         0.903448      0.117384   \n",
       "17     aus  perceptron   avg         0.80604         0.455242      0.211888   \n",
       "18     aus         knn     1         0.85660         0.818015      0.418627   \n",
       "19     aus         knn     2         0.86400         0.835463      0.475455   \n",
       "20     aus         knn     3         0.83920         0.770916      0.359665   \n",
       "21     aus         knn     4         0.84760         0.814751      0.420726   \n",
       "22     aus         knn     5         0.85400         0.803459      0.457885   \n",
       "23     aus         knn   avg         0.85228         0.808521      0.426472   \n",
       "24     aus      forest     1         0.99700         1.000000      0.985889   \n",
       "25     aus      forest     2         1.00000         1.000000      1.000000   \n",
       "26     aus      forest     3         0.96800         0.998911      0.852230   \n",
       "27     aus      forest     4         0.94320         0.985075      0.759965   \n",
       "28     aus      forest     5         1.00000         1.000000      1.000000   \n",
       "29     aus      forest   avg         0.98164         0.996797      0.919617   \n",
       "30     aus         svm     1         0.85520         0.746725      0.482596   \n",
       "31     aus         svm     2         0.85620         0.750988      0.518182   \n",
       "32     aus         svm     3         0.85120         0.744838      0.469331   \n",
       "33     aus         svm     4         0.84800         0.729763      0.519043   \n",
       "34     aus         svm     5         0.85440         0.758667      0.509857   \n",
       "35     aus         svm   avg         0.85300         0.746196      0.499802   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.972060  0.526382   0.683114   5.208465e+00       0.832130   \n",
       "1            0.956667  0.595462   0.722879   5.049596e+00       0.829467   \n",
       "2            0.970183  0.508750   0.674218   5.429514e+00       0.829012   \n",
       "3            0.946525  0.623390   0.741199   5.049602e+00       0.828855   \n",
       "4            0.959320  0.629371   0.741757   4.759469e+00       0.830016   \n",
       "5            0.960951  0.576671   0.712633   5.099329e+00       0.829896   \n",
       "6            0.957328  0.534524   0.689859   5.401891e+00       0.838167   \n",
       "7            0.951795  0.561697   0.704534   5.422618e+00       0.839228   \n",
       "8            0.955657  0.512790   0.678108   5.657479e+00       0.839784   \n",
       "9            0.950917  0.558470   0.701765   5.581497e+00       0.839193   \n",
       "10           0.957003  0.550282   0.696692   5.498600e+00       0.837747   \n",
       "11           0.954540  0.543553   0.694191   5.512417e+00       0.838824   \n",
       "12           0.965710  0.482584   0.662065   5.643658e+00       0.834245   \n",
       "13           0.905128  0.607955   0.744382   5.719681e+00       0.826819   \n",
       "14           1.000000  0.000000   0.500000   7.432745e+00       0.780713   \n",
       "15           1.000000  0.000000   0.500000   7.798856e+00       0.781197   \n",
       "16           0.996395  0.207772   0.556889   6.900850e+00       0.801096   \n",
       "17           0.973447  0.259662   0.592667   6.699158e+00       0.804814   \n",
       "18           0.974854  0.553827   0.696740   4.952876e+00       0.835462   \n",
       "19           0.973590  0.606025   0.724522   4.697290e+00       0.837456   \n",
       "20           0.970693  0.490494   0.665179   5.553854e+00       0.836437   \n",
       "21           0.972100  0.554907   0.696413   5.263727e+00       0.837584   \n",
       "22           0.967817  0.583333   0.712851   5.042681e+00       0.837213   \n",
       "23           0.971811  0.557717   0.699141   5.102086e+00       0.836830   \n",
       "24           1.000000  0.992894   0.992944   1.036163e-01       0.842881   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       0.844148   \n",
       "26           0.999745  0.919759   0.925988   1.105241e+00       0.843963   \n",
       "27           0.996642  0.858000   0.878303   1.961805e+00       0.843144   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       0.844532   \n",
       "29           0.999277  0.954131   0.959447   6.341324e-01       0.843733   \n",
       "30           0.955804  0.586286   0.719200   5.001243e+00       0.843778   \n",
       "31           0.951538  0.613233   0.734860   4.966706e+00       0.843671   \n",
       "32           0.955912  0.575827   0.712622   5.139398e+00       0.842937   \n",
       "33           0.943942  0.606625   0.731493   5.249929e+00       0.840823   \n",
       "34           0.953399  0.609861   0.731628   5.028875e+00       0.844297   \n",
       "35           0.952119  0.598366   0.725960   5.077230e+00       0.843101   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.738826     0.363179          0.963920  0.486978  0.663550   \n",
       "1         0.670925     0.435163          0.940109  0.527917  0.687636   \n",
       "2         0.724368     0.355540          0.962000  0.476970  0.658770   \n",
       "3         0.656716     0.457168          0.933025  0.539068  0.695096   \n",
       "4         0.663578     0.453984          0.935460  0.539127  0.694722   \n",
       "5         0.690883     0.413007          0.946903  0.514012  0.679955   \n",
       "6         0.742602     0.401473          0.960892  0.521180  0.681183   \n",
       "7         0.714293     0.443773          0.950193  0.547437  0.696983   \n",
       "8         0.730639     0.426674          0.955818  0.538739  0.691246   \n",
       "9         0.722869     0.430434          0.953752  0.539576  0.692093   \n",
       "10        0.727600     0.414193          0.956517  0.527884  0.685355   \n",
       "11        0.727600     0.423310          0.955434  0.534963  0.689372   \n",
       "12        0.767168     0.350944          0.970067  0.481585  0.660506   \n",
       "13        0.613504     0.566559          0.899848  0.589098  0.733204   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        1.000000     0.000488          1.000000  0.000975  0.500244   \n",
       "16        0.867674     0.108286          0.995369  0.192543  0.551828   \n",
       "17        0.649669     0.205256          0.973057  0.252840  0.589156   \n",
       "18        0.761172     0.364282          0.967878  0.492746  0.666080   \n",
       "19        0.730827     0.408714          0.957760  0.524245  0.683237   \n",
       "20        0.763305     0.368332          0.967919  0.496890  0.668125   \n",
       "21        0.752049     0.385001          0.964425  0.509282  0.674713   \n",
       "22        0.731799     0.405188          0.958359  0.521583  0.681774   \n",
       "23        0.747830     0.386304          0.963268  0.508949  0.674786   \n",
       "24        0.768038     0.406601          0.965489  0.531712  0.686045   \n",
       "25        0.738563     0.446925          0.955608  0.556871  0.701267   \n",
       "26        0.755229     0.426739          0.961152  0.545338  0.693946   \n",
       "27        0.750460     0.424678          0.960424  0.542411  0.692551   \n",
       "28        0.741476     0.445402          0.956454  0.556510  0.700928   \n",
       "29        0.750753     0.430069          0.959825  0.546568  0.694947   \n",
       "30        0.734472     0.450899          0.954189  0.558766  0.702544   \n",
       "31        0.709647     0.484973          0.944321  0.576182  0.714647   \n",
       "32        0.721490     0.462160          0.949890  0.563417  0.706025   \n",
       "33        0.694537     0.487089          0.939961  0.572603  0.713525   \n",
       "34        0.715122     0.480414          0.946335  0.574729  0.713374   \n",
       "35        0.715054     0.473107          0.946939  0.569139  0.710023   \n",
       "\n",
       "    test_logloss  \n",
       "0       5.798042  \n",
       "1       5.890023  \n",
       "2       5.905746  \n",
       "3       5.911174  \n",
       "4       5.871091  \n",
       "5       5.875215  \n",
       "6       5.589523  \n",
       "7       5.552891  \n",
       "8       5.533707  \n",
       "9       5.554118  \n",
       "10      5.604033  \n",
       "11      5.566854  \n",
       "12      5.725007  \n",
       "13      5.981522  \n",
       "14      7.573892  \n",
       "15      7.557171  \n",
       "16      6.869890  \n",
       "17      6.741496  \n",
       "18      5.682959  \n",
       "19      5.614114  \n",
       "20      5.649271  \n",
       "21      5.609684  \n",
       "22      5.622475  \n",
       "23      5.635701  \n",
       "24      5.426736  \n",
       "25      5.382972  \n",
       "26      5.389362  \n",
       "27      5.417641  \n",
       "28      5.369693  \n",
       "29      5.397281  \n",
       "30      5.395760  \n",
       "31      5.399454  \n",
       "32      5.424778  \n",
       "33      5.497816  \n",
       "34      5.377814  \n",
       "35      5.419124  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/aus_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
