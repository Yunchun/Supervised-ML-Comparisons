{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Chess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasnaek/chess\n",
    "chess_df = pd.read_csv('Data/games.csv')\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_ply</th>\n",
       "      <th>winner_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>1500</td>\n",
       "      <td>1191</td>\n",
       "      <td>other</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>B00</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>C20</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>1439</td>\n",
       "      <td>1454</td>\n",
       "      <td>D02</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>1523</td>\n",
       "      <td>1469</td>\n",
       "      <td>C41</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated  turns victory_status  white_rating  black_rating opening_eco  \\\n",
       "0  False     13      outoftime          1500          1191       other   \n",
       "1   True     16         resign          1322          1261         B00   \n",
       "2   True     61           mate          1496          1500         C20   \n",
       "3   True     61           mate          1439          1454         D02   \n",
       "4   True     95           mate          1523          1469         C41   \n",
       "\n",
       "   opening_ply  winner_white  \n",
       "0            5          True  \n",
       "1            4         False  \n",
       "2            3          True  \n",
       "3            3          True  \n",
       "4            5          True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_df['winner_white'] = chess_df['winner'] == 'white'\n",
    "chess_df = chess_df[['rated', 'turns', 'victory_status',\n",
    "                     'white_rating', 'black_rating', 'opening_eco', 'opening_ply', 'winner_white']]\n",
    "\n",
    "max_openings = 15\n",
    "popular_opennings = chess_df['opening_eco'].value_counts()[:max_openings].index.tolist()\n",
    "def replace_opening(x):\n",
    "    if (x in popular_opennings):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "chess_df['opening_eco'] = chess_df['opening_eco'].apply(replace_opening)\n",
    "\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_df_X = chess_df.drop(columns=['winner_white'])\n",
    "chess_df_y = chess_df['winner_white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_X_cat_col = ['rated', 'victory_status', 'opening_eco']\n",
    "chess_X = pd.get_dummies(columns=chess_X_cat_col, data=chess_df_X)\n",
    "\n",
    "chess_y = chess_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Mushrooms Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: edible(e), poisonous(p)\n",
    "\n",
    "cap-shape: bell(b), conical(c), convex(x), flat(f), knobbed(k), sunken(s)\n",
    "\n",
    "cap-surface: fibrous(f), grooves(g), scaly(y), smooth(s)\n",
    "\n",
    "cap-color: brown(n), buff(b), cinnamon(c), gray(g), green(r), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "bruises: bruises(t), no(f)\n",
    "\n",
    "odor: almond(a), anise(l), creosote(c), fishy(y), foul(f), musty(m), none(n), pungent(p), spicy(s)\n",
    "\n",
    "gill-attachment: attached(a), descending(d), free(f), notched(n)\n",
    "\n",
    "gill-spacing: close(c), crowded(w), distant(d)\n",
    "\n",
    "gill-size: broad(b), narrow(n)\n",
    "\n",
    "gill-color: black(k), brown(n), buff(b), chocolate(h), gray(g), green(r), orange(o), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-shape: enlarging(e), tapering(t)\n",
    "\n",
    "stalk-root: bulbous(b), club(c), cup(u), equal(e), rhizomorphs(z), rooted(r), missing(?)\n",
    "\n",
    "stalk-surface-above-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-surface-below-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-color-above-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-color-below-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "veil-type: partial(p), universal(u)\n",
    "\n",
    "veil-color: brown(n), orange(o), white(w), yellow(y)\n",
    "\n",
    "ring-number: none(n), one(o), two(t)\n",
    "\n",
    "ring-type: cobwebby(c), evanescent(e), flaring(f), large(l), none(n), pendant(p), sheathing(s), zone(z)\n",
    "\n",
    "spore-print-color: black(k), brown(n), buff(b), chocolate(h), green(r), orange(o), purple(u), white(w), yellow(y)\n",
    "\n",
    "population: abundant(a), clustered(c), numerous(n), scattered(s), several(v), solitary(y)\n",
    "\n",
    "habitat: grasses(g), leaves(l), meadows(m), paths(p), urban(u), waste(w), woods(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/uciml/mushroom-classification\n",
    "shrooms = pd.read_csv('Data/mushrooms.csv')\n",
    "shrooms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_df_X = shrooms.drop(columns=['class'])\n",
    "shrooms_df_y = shrooms['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_X = pd.get_dummies(data=shrooms_df_X)\n",
    "shrooms_y = shrooms_df_y.replace({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Cardio Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/sulianova/cardiovascular-disease-dataset, this cardio dataset has 70000 samples and 12 variables, which were collected at the moment of medical examination. It contains a target variable that indicates the presence or absence of cardiovascular disease, as well as 11 features that might be associated with the presence of cardiovascular disease, such as age, gender, and blood pressure. There are 3 types of 11 input features:\n",
    "- objective feature: factual information\n",
    "- examination feature: results of medical examination\n",
    "- subjective feature: information given by the patient\n",
    "\n",
    "A more detailed description of 12 variables are shown below:\n",
    "\n",
    "- age: objective feature, int (days)\n",
    "- height: objective feature, int (cm)\n",
    "- weight: objective feature, float (kg)\n",
    "- gender: objective feature, categorical code, 1: male, 2:female\n",
    "- ap_hi: systolic blood pressure, examination feature, int\n",
    "- ap_lo: diastolic blood pressure, examination feature, int\n",
    "- cholesterol: examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- gluc: glucose, examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- smoke: subjective feature, binary, 0: do not smoke, 1: smoke\n",
    "- alco: alcohol intake, subjective feature, binary, 0: do not drink alcohol, 1: drink alcohol\n",
    "- active: physical activity, subjective feature, binary, 0: not physically active, 1: physically active\n",
    "- cardio: presence or absence of cardiovascular disease, target variable, binary, 0: disease not present, 1: disease present\n",
    "\n",
    "For this dataset, we want use those 11 input features and apply machine learning algorithms to predict whether a person has cardiovascular disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cardio dataset\n",
    "cardio = pd.read_csv('data/cardio.csv', delimiter = ';')\n",
    "# drop unnecessary column \"id\"\n",
    "cardio = cardio.drop(columns = ['id'])\n",
    "# convert age in days to age in years\n",
    "cardio['age'] = cardio['age'].apply(lambda x: int(x/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding categorical input features stored in cate_cols\n",
    "cate_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "cardio = pd.get_dummies(columns = cate_cols, data = cardio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cardio</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "      <th>smoke_0</th>\n",
       "      <th>smoke_1</th>\n",
       "      <th>alco_0</th>\n",
       "      <th>alco_1</th>\n",
       "      <th>active_0</th>\n",
       "      <th>active_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight  ap_hi  ap_lo  cardio  gender_1  gender_2  \\\n",
       "0   50     168    62.0    110     80       0         0         1   \n",
       "1   55     156    85.0    140     90       1         1         0   \n",
       "2   51     165    64.0    130     70       1         1         0   \n",
       "3   48     169    82.0    150    100       1         0         1   \n",
       "4   47     156    56.0    100     60       0         1         0   \n",
       "\n",
       "   cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  gluc_3  \\\n",
       "0              1              0              0       1       0       0   \n",
       "1              0              0              1       1       0       0   \n",
       "2              0              0              1       1       0       0   \n",
       "3              1              0              0       1       0       0   \n",
       "4              1              0              0       1       0       0   \n",
       "\n",
       "   smoke_0  smoke_1  alco_0  alco_1  active_0  active_1  \n",
       "0        1        0       1       0         0         1  \n",
       "1        1        0       1       0         0         1  \n",
       "2        1        0       1       0         1         0  \n",
       "3        1        0       1       0         0         1  \n",
       "4        1        0       1       0         1         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at cleaned dataset\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the cardio dataset into input features and labels \n",
    "cardio_X = cardio.drop(columns=['cardio']) # input features\n",
    "cardio_y = cardio['cardio'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Rain Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean BnB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Olympic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "tree_params = [\n",
    "    {\n",
    "        'max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "        'min_samples_split':[2,3,5,7,10,15,20],\n",
    "        'min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "    }\n",
    "]\n",
    "\n",
    "log_reg_params = [\n",
    "    {\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': 10 **np.array(np.arange(-8, 5, 1), dtype='float32')\n",
    "    }\n",
    "]\n",
    "\n",
    "perceptron_params = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_params = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'degree': [2, 3],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "        'gamma': [0.001,0.01,0.1,1,2]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_params = [\n",
    "    {\n",
    "        'n_neighbors': np.arange(1, 106, 4),\n",
    "        'metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "forest_params = [\n",
    "    {\n",
    "        'n_estimators': [1024],\n",
    "        'min_samples_split': [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    }\n",
    "]\n",
    "\n",
    "models_without_svm = {\n",
    "    'tree': (DecisionTreeClassifier(), tree_params),\n",
    "    'log_reg': (LogisticRegression(), log_reg_params),\n",
    "    'perceptron': (Perceptron(), perceptron_params),\n",
    "    'knn': (KNeighborsClassifier(), knn_params),\n",
    "    'forest': (RandomForestClassifier(), forest_params)\n",
    "}\n",
    "\n",
    "models_only_svm = {\n",
    "    'svm': (SVC(), svc_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform trials on dataset\n",
    "def perform_trials(dataset_name, models, data_X, data_y):\n",
    "    results_columns = ['dataset', 'model', 'trial',\n",
    "                       'train_accuracy', 'train_precision', 'train_recall', 'train_specificity',\n",
    "                       'train_f1', 'train_auc', 'train_logloss',\n",
    "                       'test_accuracy', 'test_precision', 'test_recall', 'test_specificity',\n",
    "                       'test_f1', 'test_auc', 'test_logloss']\n",
    "    num_trials = 5\n",
    "    \n",
    "    data_results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "    # perform trials using each model\n",
    "    for model_name in models.keys():\n",
    "        \n",
    "        model = models[model_name][0]\n",
    "        model_params = models[model_name][1]\n",
    "        \n",
    "        train_metrics = np.zeros(7)\n",
    "        test_metrics =  np.zeros(7)\n",
    "        \n",
    "        model_results = pd.DataFrame(columns=results_columns)\n",
    "        \n",
    "        # perform 5 trials on each dataset\n",
    "        for trial_count in range(num_trials):\n",
    "            # pick 5000 samples with replacement to be in the training set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, train_size=5000, random_state=trial_count)\n",
    "            \n",
    "            # grid search with 5 k-folds\n",
    "            search = GridSearchCV(model, model_params, cv=5, verbose=3, n_jobs=-1)\n",
    "            \n",
    "            # find the best parameters for the model\n",
    "            # grid search automatically refits a model on the entire validation set using the best parameters\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # use metrics to evaluate model performance on the test set\n",
    "            y_train_pred = search.predict(X_train)\n",
    "            y_test_pred = search.predict(X_test)\n",
    "            \n",
    "            # compute metrics\n",
    "            model_result = {\n",
    "                'dataset': dataset_name,\n",
    "                'model': model_name,\n",
    "                'trial': trial_count + 1,\n",
    "\n",
    "                'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "                'train_precision': precision_score(y_train, y_train_pred),\n",
    "                'train_recall': recall_score(y_train, y_train_pred),\n",
    "                'train_specificity': recall_score(y_train, y_train_pred, pos_label=0),\n",
    "                'train_f1': f1_score(y_train, y_train_pred),\n",
    "                'train_auc': roc_auc_score(y_train, y_train_pred),\n",
    "                'train_logloss': log_loss(y_train, y_train_pred),\n",
    "\n",
    "                'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "                'test_precision': precision_score(y_test, y_test_pred),\n",
    "                'test_recall': recall_score(y_test, y_test_pred),\n",
    "                'test_specificity': recall_score(y_test, y_test_pred, pos_label=0),\n",
    "                'test_f1': f1_score(y_test, y_test_pred),\n",
    "                'test_auc': roc_auc_score(y_test, y_test_pred),\n",
    "                'test_logloss': log_loss(y_test, y_test_pred)\n",
    "            }\n",
    "            \n",
    "            # append model_result to the model_results dataframe\n",
    "            model_results = model_results.append(model_result, ignore_index=True)\n",
    "        \n",
    "        # append model_results to data_results\n",
    "        data_results = data_results.append(model_results, ignore_index=True)\n",
    "        \n",
    "        avg_result = {\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'trial': 'avg',\n",
    "            \n",
    "            'train_accuracy': model_results.train_accuracy.mean(),\n",
    "            'train_precision': model_results.train_precision.mean(),\n",
    "            'train_recall': model_results.train_recall.mean(),\n",
    "            'train_specificity': model_results.train_specificity.mean(),\n",
    "            'train_f1': model_results.train_f1.mean(),\n",
    "            'train_auc': model_results.train_auc.mean(),\n",
    "            'train_logloss': model_results.train_logloss.mean(),\n",
    "            \n",
    "            'test_accuracy': model_results.test_accuracy.mean(),\n",
    "            'test_precision': model_results.test_precision.mean(),\n",
    "            'test_recall': model_results.test_recall.mean(),\n",
    "            'test_specificity': model_results.test_specificity.mean(),\n",
    "            'test_f1': model_results.test_f1.mean(),\n",
    "            'test_auc': model_results.test_auc.mean(),\n",
    "            'test_logloss': model_results.test_logloss.mean()\n",
    "        }\n",
    "        \n",
    "        # append avg_result to the data_results dataframe\n",
    "        data_results = data_results.append(avg_result, ignore_index=True)\n",
    "    \n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duy Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  2.2min finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  2.2min finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  2.0min finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  2.1min finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66640</td>\n",
       "      <td>0.634031</td>\n",
       "      <td>0.762794</td>\n",
       "      <td>0.572892</td>\n",
       "      <td>0.692478</td>\n",
       "      <td>0.667843</td>\n",
       "      <td>11.522309</td>\n",
       "      <td>0.636339</td>\n",
       "      <td>0.615471</td>\n",
       "      <td>0.729274</td>\n",
       "      <td>0.543157</td>\n",
       "      <td>0.667557</td>\n",
       "      <td>0.636216</td>\n",
       "      <td>12.560572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.68960</td>\n",
       "      <td>0.717603</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.757865</td>\n",
       "      <td>0.665661</td>\n",
       "      <td>0.689298</td>\n",
       "      <td>10.720933</td>\n",
       "      <td>0.646035</td>\n",
       "      <td>0.664754</td>\n",
       "      <td>0.585996</td>\n",
       "      <td>0.705804</td>\n",
       "      <td>0.622895</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>12.225624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68180</td>\n",
       "      <td>0.657639</td>\n",
       "      <td>0.757903</td>\n",
       "      <td>0.605758</td>\n",
       "      <td>0.704220</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>10.990396</td>\n",
       "      <td>0.645106</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.731272</td>\n",
       "      <td>0.559555</td>\n",
       "      <td>0.672469</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>12.257795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.658244</td>\n",
       "      <td>0.638409</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>0.654927</td>\n",
       "      <td>11.916010</td>\n",
       "      <td>0.637402</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>0.627396</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>0.633212</td>\n",
       "      <td>0.637380</td>\n",
       "      <td>12.523831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67580</td>\n",
       "      <td>0.645645</td>\n",
       "      <td>0.809710</td>\n",
       "      <td>0.535977</td>\n",
       "      <td>0.718430</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>11.197653</td>\n",
       "      <td>0.649489</td>\n",
       "      <td>0.612558</td>\n",
       "      <td>0.792534</td>\n",
       "      <td>0.509526</td>\n",
       "      <td>0.691020</td>\n",
       "      <td>0.651030</td>\n",
       "      <td>12.106432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67372</td>\n",
       "      <td>0.662632</td>\n",
       "      <td>0.717910</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>0.673349</td>\n",
       "      <td>11.269460</td>\n",
       "      <td>0.642874</td>\n",
       "      <td>0.630868</td>\n",
       "      <td>0.693294</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>0.657431</td>\n",
       "      <td>0.643188</td>\n",
       "      <td>12.334851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64680</td>\n",
       "      <td>0.658038</td>\n",
       "      <td>0.588546</td>\n",
       "      <td>0.703310</td>\n",
       "      <td>0.621355</td>\n",
       "      <td>0.645928</td>\n",
       "      <td>12.199216</td>\n",
       "      <td>0.648559</td>\n",
       "      <td>0.670098</td>\n",
       "      <td>0.587081</td>\n",
       "      <td>0.710201</td>\n",
       "      <td>0.625848</td>\n",
       "      <td>0.648641</td>\n",
       "      <td>12.138461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.65600</td>\n",
       "      <td>0.663966</td>\n",
       "      <td>0.625552</td>\n",
       "      <td>0.686181</td>\n",
       "      <td>0.644187</td>\n",
       "      <td>0.655867</td>\n",
       "      <td>11.881465</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>0.649202</td>\n",
       "      <td>0.628461</td>\n",
       "      <td>0.661940</td>\n",
       "      <td>0.638663</td>\n",
       "      <td>0.645201</td>\n",
       "      <td>12.253167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.64820</td>\n",
       "      <td>0.654553</td>\n",
       "      <td>0.627051</td>\n",
       "      <td>0.669332</td>\n",
       "      <td>0.640507</td>\n",
       "      <td>0.648192</td>\n",
       "      <td>12.150874</td>\n",
       "      <td>0.648492</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.633298</td>\n",
       "      <td>0.663579</td>\n",
       "      <td>0.642244</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>12.140774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.64560</td>\n",
       "      <td>0.650694</td>\n",
       "      <td>0.621937</td>\n",
       "      <td>0.669056</td>\n",
       "      <td>0.635990</td>\n",
       "      <td>0.645496</td>\n",
       "      <td>12.240675</td>\n",
       "      <td>0.649024</td>\n",
       "      <td>0.651558</td>\n",
       "      <td>0.637247</td>\n",
       "      <td>0.660747</td>\n",
       "      <td>0.644323</td>\n",
       "      <td>0.648997</td>\n",
       "      <td>12.122425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.64900</td>\n",
       "      <td>0.653007</td>\n",
       "      <td>0.667580</td>\n",
       "      <td>0.629599</td>\n",
       "      <td>0.660213</td>\n",
       "      <td>0.648590</td>\n",
       "      <td>12.123255</td>\n",
       "      <td>0.650086</td>\n",
       "      <td>0.641723</td>\n",
       "      <td>0.662146</td>\n",
       "      <td>0.638287</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.650216</td>\n",
       "      <td>12.085736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.64912</td>\n",
       "      <td>0.656051</td>\n",
       "      <td>0.626133</td>\n",
       "      <td>0.671496</td>\n",
       "      <td>0.640450</td>\n",
       "      <td>0.648814</td>\n",
       "      <td>12.119097</td>\n",
       "      <td>0.648280</td>\n",
       "      <td>0.652806</td>\n",
       "      <td>0.629646</td>\n",
       "      <td>0.666951</td>\n",
       "      <td>0.640571</td>\n",
       "      <td>0.648299</td>\n",
       "      <td>12.148113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53020</td>\n",
       "      <td>0.511988</td>\n",
       "      <td>0.980097</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.672613</td>\n",
       "      <td>0.536936</td>\n",
       "      <td>16.226685</td>\n",
       "      <td>0.543631</td>\n",
       "      <td>0.523701</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.681999</td>\n",
       "      <td>0.543054</td>\n",
       "      <td>15.762773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50280</td>\n",
       "      <td>0.500302</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.666756</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>17.173077</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>0.500901</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.667319</td>\n",
       "      <td>0.504040</td>\n",
       "      <td>17.168862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.52940</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>0.070828</td>\n",
       "      <td>0.987605</td>\n",
       "      <td>0.130772</td>\n",
       "      <td>0.529217</td>\n",
       "      <td>16.253953</td>\n",
       "      <td>0.536326</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.083178</td>\n",
       "      <td>0.986236</td>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.534707</td>\n",
       "      <td>16.014731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.52160</td>\n",
       "      <td>0.510023</td>\n",
       "      <td>0.991563</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.673581</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>16.523730</td>\n",
       "      <td>0.522181</td>\n",
       "      <td>0.510899</td>\n",
       "      <td>0.989084</td>\n",
       "      <td>0.057381</td>\n",
       "      <td>0.673770</td>\n",
       "      <td>0.523233</td>\n",
       "      <td>16.503665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.58340</td>\n",
       "      <td>0.553608</td>\n",
       "      <td>0.952232</td>\n",
       "      <td>0.198283</td>\n",
       "      <td>0.700158</td>\n",
       "      <td>0.575257</td>\n",
       "      <td>14.389168</td>\n",
       "      <td>0.562027</td>\n",
       "      <td>0.531939</td>\n",
       "      <td>0.952733</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>0.682704</td>\n",
       "      <td>0.566236</td>\n",
       "      <td>15.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.53348</td>\n",
       "      <td>0.585376</td>\n",
       "      <td>0.798783</td>\n",
       "      <td>0.269234</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.534009</td>\n",
       "      <td>16.113323</td>\n",
       "      <td>0.533417</td>\n",
       "      <td>0.584916</td>\n",
       "      <td>0.800356</td>\n",
       "      <td>0.268152</td>\n",
       "      <td>0.571486</td>\n",
       "      <td>0.534254</td>\n",
       "      <td>16.115484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66240</td>\n",
       "      <td>0.668701</td>\n",
       "      <td>0.623071</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.645080</td>\n",
       "      <td>0.661811</td>\n",
       "      <td>11.660412</td>\n",
       "      <td>0.633550</td>\n",
       "      <td>0.644213</td>\n",
       "      <td>0.598753</td>\n",
       "      <td>0.668440</td>\n",
       "      <td>0.620652</td>\n",
       "      <td>0.633597</td>\n",
       "      <td>12.656858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.65660</td>\n",
       "      <td>0.667100</td>\n",
       "      <td>0.619124</td>\n",
       "      <td>0.693748</td>\n",
       "      <td>0.642217</td>\n",
       "      <td>0.656436</td>\n",
       "      <td>11.860739</td>\n",
       "      <td>0.639394</td>\n",
       "      <td>0.643665</td>\n",
       "      <td>0.620873</td>\n",
       "      <td>0.657832</td>\n",
       "      <td>0.632064</td>\n",
       "      <td>0.639353</td>\n",
       "      <td>12.455015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.66260</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.678129</td>\n",
       "      <td>0.657183</td>\n",
       "      <td>0.662594</td>\n",
       "      <td>11.653512</td>\n",
       "      <td>0.639859</td>\n",
       "      <td>0.639962</td>\n",
       "      <td>0.633564</td>\n",
       "      <td>0.646109</td>\n",
       "      <td>0.636747</td>\n",
       "      <td>0.639837</td>\n",
       "      <td>12.438964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65720</td>\n",
       "      <td>0.655560</td>\n",
       "      <td>0.656087</td>\n",
       "      <td>0.658303</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.657195</td>\n",
       "      <td>11.840030</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.639719</td>\n",
       "      <td>0.641507</td>\n",
       "      <td>0.640339</td>\n",
       "      <td>0.640611</td>\n",
       "      <td>0.640923</td>\n",
       "      <td>12.402267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65860</td>\n",
       "      <td>0.655527</td>\n",
       "      <td>0.698904</td>\n",
       "      <td>0.616517</td>\n",
       "      <td>0.676521</td>\n",
       "      <td>0.657710</td>\n",
       "      <td>11.791688</td>\n",
       "      <td>0.636672</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>0.595454</td>\n",
       "      <td>0.648867</td>\n",
       "      <td>0.637125</td>\n",
       "      <td>12.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.65948</td>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.648849</td>\n",
       "      <td>0.669450</td>\n",
       "      <td>0.655365</td>\n",
       "      <td>0.659149</td>\n",
       "      <td>11.761276</td>\n",
       "      <td>0.638079</td>\n",
       "      <td>0.637805</td>\n",
       "      <td>0.634699</td>\n",
       "      <td>0.641635</td>\n",
       "      <td>0.635788</td>\n",
       "      <td>0.638167</td>\n",
       "      <td>12.500438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93140</td>\n",
       "      <td>0.926358</td>\n",
       "      <td>0.935012</td>\n",
       "      <td>0.927896</td>\n",
       "      <td>0.930665</td>\n",
       "      <td>0.931454</td>\n",
       "      <td>2.369389</td>\n",
       "      <td>0.662439</td>\n",
       "      <td>0.658411</td>\n",
       "      <td>0.677013</td>\n",
       "      <td>0.647826</td>\n",
       "      <td>0.667582</td>\n",
       "      <td>0.662419</td>\n",
       "      <td>11.659099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.987605</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.989980</td>\n",
       "      <td>0.990010</td>\n",
       "      <td>0.345393</td>\n",
       "      <td>0.660513</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.677316</td>\n",
       "      <td>0.643785</td>\n",
       "      <td>0.665620</td>\n",
       "      <td>0.660551</td>\n",
       "      <td>11.725619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.929172</td>\n",
       "      <td>0.920832</td>\n",
       "      <td>0.925284</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>2.590440</td>\n",
       "      <td>0.665294</td>\n",
       "      <td>0.657055</td>\n",
       "      <td>0.686484</td>\n",
       "      <td>0.644256</td>\n",
       "      <td>0.671447</td>\n",
       "      <td>0.665370</td>\n",
       "      <td>11.560472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98660</td>\n",
       "      <td>0.984788</td>\n",
       "      <td>0.988349</td>\n",
       "      <td>0.984867</td>\n",
       "      <td>0.986565</td>\n",
       "      <td>0.986608</td>\n",
       "      <td>0.462826</td>\n",
       "      <td>0.665626</td>\n",
       "      <td>0.653832</td>\n",
       "      <td>0.700745</td>\n",
       "      <td>0.630665</td>\n",
       "      <td>0.676476</td>\n",
       "      <td>0.665705</td>\n",
       "      <td>11.549008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.97280</td>\n",
       "      <td>0.968242</td>\n",
       "      <td>0.978857</td>\n",
       "      <td>0.966476</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>0.972666</td>\n",
       "      <td>0.939468</td>\n",
       "      <td>0.665427</td>\n",
       "      <td>0.648796</td>\n",
       "      <td>0.705250</td>\n",
       "      <td>0.626462</td>\n",
       "      <td>0.675846</td>\n",
       "      <td>0.665856</td>\n",
       "      <td>11.555892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.96116</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.964751</td>\n",
       "      <td>0.957545</td>\n",
       "      <td>0.961203</td>\n",
       "      <td>0.961148</td>\n",
       "      <td>1.341503</td>\n",
       "      <td>0.663860</td>\n",
       "      <td>0.654483</td>\n",
       "      <td>0.689362</td>\n",
       "      <td>0.638599</td>\n",
       "      <td>0.671394</td>\n",
       "      <td>0.663980</td>\n",
       "      <td>11.610018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0    chess        tree     1         0.66640         0.634031      0.762794   \n",
       "1    chess        tree     2         0.68960         0.717603      0.620731   \n",
       "2    chess        tree     3         0.68180         0.657639      0.757903   \n",
       "3    chess        tree     4         0.65500         0.658244      0.638409   \n",
       "4    chess        tree     5         0.67580         0.645645      0.809710   \n",
       "5    chess        tree   avg         0.67372         0.662632      0.717910   \n",
       "6    chess     log_reg     1         0.64680         0.658038      0.588546   \n",
       "7    chess     log_reg     2         0.65600         0.663966      0.625552   \n",
       "8    chess     log_reg     3         0.64820         0.654553      0.627051   \n",
       "9    chess     log_reg     4         0.64560         0.650694      0.621937   \n",
       "10   chess     log_reg     5         0.64900         0.653007      0.667580   \n",
       "11   chess     log_reg   avg         0.64912         0.656051      0.626133   \n",
       "12   chess  perceptron     1         0.53020         0.511988      0.980097   \n",
       "13   chess  perceptron     2         0.50280         0.500302      0.999196   \n",
       "14   chess  perceptron     3         0.52940         0.850962      0.070828   \n",
       "15   chess  perceptron     4         0.52160         0.510023      0.991563   \n",
       "16   chess  perceptron     5         0.58340         0.553608      0.952232   \n",
       "17   chess  perceptron   avg         0.53348         0.585376      0.798783   \n",
       "18   chess         knn     1         0.66240         0.668701      0.623071   \n",
       "19   chess         knn     2         0.65660         0.667100      0.619124   \n",
       "20   chess         knn     3         0.66260         0.667630      0.647059   \n",
       "21   chess         knn     4         0.65720         0.655560      0.656087   \n",
       "22   chess         knn     5         0.65860         0.655527      0.698904   \n",
       "23   chess         knn   avg         0.65948         0.662904      0.648849   \n",
       "24   chess      forest     1         0.93140         0.926358      0.935012   \n",
       "25   chess      forest     2         0.99000         0.987605      0.992366   \n",
       "26   chess      forest     3         0.92500         0.921429      0.929172   \n",
       "27   chess      forest     4         0.98660         0.984788      0.988349   \n",
       "28   chess      forest     5         0.97280         0.968242      0.978857   \n",
       "29   chess      forest   avg         0.96116         0.957684      0.964751   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.572892  0.692478   0.667843      11.522309       0.636339   \n",
       "1            0.757865  0.665661   0.689298      10.720933       0.646035   \n",
       "2            0.605758  0.704220   0.681830      10.990396       0.645106   \n",
       "3            0.671446  0.648175   0.654927      11.916010       0.637402   \n",
       "4            0.535977  0.718430   0.672844      11.197653       0.649489   \n",
       "5            0.628788  0.685793   0.673349      11.269460       0.642874   \n",
       "6            0.703310  0.621355   0.645928      12.199216       0.648559   \n",
       "7            0.686181  0.644187   0.655867      11.881465       0.645238   \n",
       "8            0.669332  0.640507   0.648192      12.150874       0.648492   \n",
       "9            0.669056  0.635990   0.645496      12.240675       0.649024   \n",
       "10           0.629599  0.660213   0.648590      12.123255       0.650086   \n",
       "11           0.671496  0.640450   0.648814      12.119097       0.648280   \n",
       "12           0.093775  0.672613   0.536936      16.226685       0.543631   \n",
       "13           0.010753  0.666756   0.504975      17.173077       0.502922   \n",
       "14           0.987605  0.130772   0.529217      16.253953       0.536326   \n",
       "15           0.055755  0.673581   0.523659      16.523730       0.522181   \n",
       "16           0.198283  0.700158   0.575257      14.389168       0.562027   \n",
       "17           0.269234  0.568776   0.534009      16.113323       0.533417   \n",
       "18           0.700552  0.645080   0.661811      11.660412       0.633550   \n",
       "19           0.693748  0.642217   0.656436      11.860739       0.639394   \n",
       "20           0.678129  0.657183   0.662594      11.653512       0.639859   \n",
       "21           0.658303  0.655823   0.657195      11.840030       0.640922   \n",
       "22           0.616517  0.676521   0.657710      11.791688       0.636672   \n",
       "23           0.669450  0.655365   0.659149      11.761276       0.638079   \n",
       "24           0.927896  0.930665   0.931454       2.369389       0.662439   \n",
       "25           0.987654  0.989980   0.990010       0.345393       0.660513   \n",
       "26           0.920832  0.925284   0.925002       2.590440       0.665294   \n",
       "27           0.984867  0.986565   0.986608       0.462826       0.665626   \n",
       "28           0.966476  0.973520   0.972666       0.939468       0.665427   \n",
       "29           0.957545  0.961203   0.961148       1.341503       0.663860   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.615471     0.729274          0.543157  0.667557  0.636216   \n",
       "1         0.664754     0.585996          0.705804  0.622895  0.645900   \n",
       "2         0.622419     0.731272          0.559555  0.672469  0.645413   \n",
       "3         0.639138     0.627396          0.647363  0.633212  0.637380   \n",
       "4         0.612558     0.792534          0.509526  0.691020  0.651030   \n",
       "5         0.630868     0.693294          0.593081  0.657431  0.643188   \n",
       "6         0.670098     0.587081          0.710201  0.625848  0.648641   \n",
       "7         0.649202     0.628461          0.661940  0.638663  0.645201   \n",
       "8         0.651447     0.633298          0.663579  0.642244  0.648438   \n",
       "9         0.651558     0.637247          0.660747  0.644323  0.648997   \n",
       "10        0.641723     0.662146          0.638287  0.651775  0.650216   \n",
       "11        0.652806     0.629646          0.666951  0.640571  0.648299   \n",
       "12        0.523701     0.977451          0.108658  0.681999  0.543054   \n",
       "13        0.500901     0.999334          0.008746  0.667319  0.504040   \n",
       "14        0.857143     0.083178          0.986236  0.151640  0.534707   \n",
       "15        0.510899     0.989084          0.057381  0.673770  0.523233   \n",
       "16        0.531939     0.952733          0.179740  0.682704  0.566236   \n",
       "17        0.584916     0.800356          0.268152  0.571486  0.534254   \n",
       "18        0.644213     0.598753          0.668440  0.620652  0.633597   \n",
       "19        0.643665     0.620873          0.657832  0.632064  0.639353   \n",
       "20        0.639962     0.633564          0.646109  0.636747  0.639837   \n",
       "21        0.639719     0.641507          0.640339  0.640611  0.640923   \n",
       "22        0.621465     0.678797          0.595454  0.648867  0.637125   \n",
       "23        0.637805     0.634699          0.641635  0.635788  0.638167   \n",
       "24        0.658411     0.677013          0.647826  0.667582  0.662419   \n",
       "25        0.654321     0.677316          0.643785  0.665620  0.660551   \n",
       "26        0.657055     0.686484          0.644256  0.671447  0.665370   \n",
       "27        0.653832     0.700745          0.630665  0.676476  0.665705   \n",
       "28        0.648796     0.705250          0.626462  0.675846  0.665856   \n",
       "29        0.654483     0.689362          0.638599  0.671394  0.663980   \n",
       "\n",
       "    test_logloss  \n",
       "0      12.560572  \n",
       "1      12.225624  \n",
       "2      12.257795  \n",
       "3      12.523831  \n",
       "4      12.106432  \n",
       "5      12.334851  \n",
       "6      12.138461  \n",
       "7      12.253167  \n",
       "8      12.140774  \n",
       "9      12.122425  \n",
       "10     12.085736  \n",
       "11     12.148113  \n",
       "12     15.762773  \n",
       "13     17.168862  \n",
       "14     16.014731  \n",
       "15     16.503665  \n",
       "16     15.127389  \n",
       "17     16.115484  \n",
       "18     12.656858  \n",
       "19     12.455015  \n",
       "20     12.438964  \n",
       "21     12.402267  \n",
       "22     12.549084  \n",
       "23     12.500438  \n",
       "24     11.659099  \n",
       "25     11.725619  \n",
       "26     11.560472  \n",
       "27     11.549008  \n",
       "28     11.555892  \n",
       "29     11.610018  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_results_no_svm = perform_trials('chess', models_without_svm, chess_X, chess_y)\n",
    "chess_results_no_svm.to_csv('results/chess_no_svm.csv')\n",
    "chess_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   23.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   23.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   23.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   23.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   39.6s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   35.1s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   35.6s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   36.0s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:   35.5s finished\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\duyph\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    1.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   40.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   38.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   42.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   36.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>2.072327e-02</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>5.527973e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>4.144653e-03</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>1.105595e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.105595e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>2.211189e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   shrooms        tree     1         1.00000              1.0       1.00000   \n",
       "1   shrooms        tree     2         0.99940              1.0       0.99875   \n",
       "2   shrooms        tree     3         1.00000              1.0       1.00000   \n",
       "3   shrooms        tree     4         1.00000              1.0       1.00000   \n",
       "4   shrooms        tree     5         1.00000              1.0       1.00000   \n",
       "5   shrooms        tree   avg         0.99988              1.0       0.99975   \n",
       "6   shrooms     log_reg     1         1.00000              1.0       1.00000   \n",
       "7   shrooms     log_reg     2         1.00000              1.0       1.00000   \n",
       "8   shrooms     log_reg     3         1.00000              1.0       1.00000   \n",
       "9   shrooms     log_reg     4         1.00000              1.0       1.00000   \n",
       "10  shrooms     log_reg     5         1.00000              1.0       1.00000   \n",
       "11  shrooms     log_reg   avg         1.00000              1.0       1.00000   \n",
       "12  shrooms  perceptron     1         1.00000              1.0       1.00000   \n",
       "13  shrooms  perceptron     2         1.00000              1.0       1.00000   \n",
       "14  shrooms  perceptron     3         1.00000              1.0       1.00000   \n",
       "15  shrooms  perceptron     4         1.00000              1.0       1.00000   \n",
       "16  shrooms  perceptron     5         1.00000              1.0       1.00000   \n",
       "17  shrooms  perceptron   avg         1.00000              1.0       1.00000   \n",
       "18  shrooms         knn     1         1.00000              1.0       1.00000   \n",
       "19  shrooms         knn     2         1.00000              1.0       1.00000   \n",
       "20  shrooms         knn     3         1.00000              1.0       1.00000   \n",
       "21  shrooms         knn     4         1.00000              1.0       1.00000   \n",
       "22  shrooms         knn     5         1.00000              1.0       1.00000   \n",
       "23  shrooms         knn   avg         1.00000              1.0       1.00000   \n",
       "24  shrooms      forest     1         1.00000              1.0       1.00000   \n",
       "25  shrooms      forest     2         1.00000              1.0       1.00000   \n",
       "26  shrooms      forest     3         1.00000              1.0       1.00000   \n",
       "27  shrooms      forest     4         1.00000              1.0       1.00000   \n",
       "28  shrooms      forest     5         1.00000              1.0       1.00000   \n",
       "29  shrooms      forest   avg         1.00000              1.0       1.00000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1                 1.0  0.999375   0.999375   2.072327e-02       0.998399   \n",
       "2                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5                 1.0  0.999875   0.999875   4.144653e-03       0.999680   \n",
       "6                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "7                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "8                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "9                 1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "10                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "11                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "12                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14                1.0  1.000000   1.000000   9.992007e-16       0.999680   \n",
       "15                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "16                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17                1.0  1.000000   1.000000   9.992007e-16       0.999936   \n",
       "18                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "19                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "20                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "21                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "22                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "23                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "24                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "28                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29                1.0  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "1              1.0     0.996702               1.0  0.998348  0.998351   \n",
       "2              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "3              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "4              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "5              1.0     0.999340               1.0  0.999670  0.999670   \n",
       "6              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "7              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "8              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "9              1.0     1.000000               1.0  1.000000  1.000000   \n",
       "10             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "11             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "12             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "13             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "14             1.0     0.999316               1.0  0.999658  0.999658   \n",
       "15             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "16             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "17             1.0     0.999863               1.0  0.999932  0.999932   \n",
       "18             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "19             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "20             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "21             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "22             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "23             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "24             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "25             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "26             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "27             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "28             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "29             1.0     1.000000               1.0  1.000000  1.000000   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   5.527973e-02  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   1.105595e-02  \n",
       "6   9.992007e-16  \n",
       "7   9.992007e-16  \n",
       "8   9.992007e-16  \n",
       "9   9.992007e-16  \n",
       "10  9.992007e-16  \n",
       "11  9.992007e-16  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  1.105595e-02  \n",
       "15  9.992007e-16  \n",
       "16  9.992007e-16  \n",
       "17  2.211189e-03  \n",
       "18  9.992007e-16  \n",
       "19  9.992007e-16  \n",
       "20  9.992007e-16  \n",
       "21  9.992007e-16  \n",
       "22  9.992007e-16  \n",
       "23  9.992007e-16  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  9.992007e-16  \n",
       "28  9.992007e-16  \n",
       "29  9.992007e-16  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_results_no_svm = perform_trials('shrooms', models_without_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_no_svm.to_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  7.8min\n"
     ]
    }
   ],
   "source": [
    "chess_results_svm = perform_trials('chess', models_only_svm, chess_X, chess_y)\n",
    "chess_results_svm.to_csv('results/chess_svm.csv')\n",
    "chess_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_svm = perform_trials('shrooms', models_only_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_svm.to_csv('results/shrooms_svm.csv')\n",
    "shrooms_results_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Cardio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.516     nan 0.7178    nan 0.6468    nan 0.7178    nan 0.7112\n",
      "    nan 0.7178    nan 0.7202    nan 0.7178    nan 0.7276    nan 0.7178\n",
      "    nan 0.7138    nan 0.7178    nan 0.7162    nan 0.7178    nan 0.7166\n",
      "    nan 0.7178    nan 0.7182    nan 0.7178    nan 0.7182    nan 0.7178\n",
      "    nan 0.715     nan 0.7178    nan 0.7184    nan 0.7178    nan 0.7186\n",
      "    nan 0.7178]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.5096    nan 0.6582    nan 0.5518    nan 0.6582    nan 0.6512\n",
      "    nan 0.6582    nan 0.6512    nan 0.6582    nan 0.6518    nan 0.6582\n",
      "    nan 0.6478    nan 0.6582    nan 0.6546    nan 0.6582    nan 0.6552\n",
      "    nan 0.6582    nan 0.654     nan 0.6582    nan 0.655     nan 0.6582\n",
      "    nan 0.6578    nan 0.6582    nan 0.6562    nan 0.6582    nan 0.6568\n",
      "    nan 0.6582]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.5082    nan 0.7142    nan 0.6242    nan 0.7142    nan 0.7158\n",
      "    nan 0.7142    nan 0.716     nan 0.7142    nan 0.719     nan 0.7142\n",
      "    nan 0.71      nan 0.7142    nan 0.7122    nan 0.7142    nan 0.7126\n",
      "    nan 0.7142    nan 0.7126    nan 0.7142    nan 0.7142    nan 0.7142\n",
      "    nan 0.7148    nan 0.7142    nan 0.7126    nan 0.7142    nan 0.7152\n",
      "    nan 0.7142]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.5044    nan 0.6604    nan 0.6654    nan 0.6604    nan 0.6568\n",
      "    nan 0.6604    nan 0.6426    nan 0.6604    nan 0.6452    nan 0.6604\n",
      "    nan 0.6462    nan 0.6604    nan 0.6546    nan 0.6604    nan 0.661\n",
      "    nan 0.6604    nan 0.659     nan 0.6604    nan 0.6578    nan 0.6604\n",
      "    nan 0.6594    nan 0.6604    nan 0.659     nan 0.6604    nan 0.6574\n",
      "    nan 0.6604]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.5386    nan 0.7094    nan 0.7048    nan 0.7094    nan 0.7086\n",
      "    nan 0.7094    nan 0.7144    nan 0.7094    nan 0.7168    nan 0.7094\n",
      "    nan 0.708     nan 0.7094    nan 0.714     nan 0.7094    nan 0.7106\n",
      "    nan 0.7094    nan 0.7108    nan 0.7094    nan 0.709     nan 0.7094\n",
      "    nan 0.7092    nan 0.7094    nan 0.7092    nan 0.7094    nan 0.709\n",
      "    nan 0.7094]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7134 0.7224 0.7254 0.7282 0.7316 0.7374 0.7392]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7074 0.708  0.7132 0.715  0.7174 0.719  0.7192]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.715  0.7202 0.7228 0.7228 0.727  0.7276 0.7284]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7058 0.7078 0.7152 0.714  0.7182 0.7196 0.7218]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.704  0.7116 0.7142 0.7142 0.7206 0.724  0.7242]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72720</td>\n",
       "      <td>0.760951</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.796105</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>9.422260</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.784402</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>9.736833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.73080</td>\n",
       "      <td>0.735317</td>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.724307</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>9.297947</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.720638</td>\n",
       "      <td>0.712518</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>9.789467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72760</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.656041</td>\n",
       "      <td>0.801545</td>\n",
       "      <td>0.709966</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>9.408441</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.784166</td>\n",
       "      <td>0.705842</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>9.533320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73720</td>\n",
       "      <td>0.768923</td>\n",
       "      <td>0.684774</td>\n",
       "      <td>0.790557</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>9.076873</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.741616</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>9.513137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.647831</td>\n",
       "      <td>0.823080</td>\n",
       "      <td>0.710762</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>9.152846</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.773141</td>\n",
       "      <td>0.641379</td>\n",
       "      <td>0.812196</td>\n",
       "      <td>0.701123</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>9.433412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.73156</td>\n",
       "      <td>0.765195</td>\n",
       "      <td>0.676620</td>\n",
       "      <td>0.787119</td>\n",
       "      <td>0.717344</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>9.271673</td>\n",
       "      <td>0.722018</td>\n",
       "      <td>0.746792</td>\n",
       "      <td>0.673105</td>\n",
       "      <td>0.770831</td>\n",
       "      <td>0.707236</td>\n",
       "      <td>0.721968</td>\n",
       "      <td>9.601234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72780</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>0.649356</td>\n",
       "      <td>0.805246</td>\n",
       "      <td>0.703292</td>\n",
       "      <td>0.727301</td>\n",
       "      <td>9.401533</td>\n",
       "      <td>0.719323</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.649269</td>\n",
       "      <td>0.789355</td>\n",
       "      <td>0.698147</td>\n",
       "      <td>0.719312</td>\n",
       "      <td>9.694322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64900</td>\n",
       "      <td>0.661771</td>\n",
       "      <td>0.636578</td>\n",
       "      <td>0.661909</td>\n",
       "      <td>0.648930</td>\n",
       "      <td>0.649243</td>\n",
       "      <td>12.123243</td>\n",
       "      <td>0.647708</td>\n",
       "      <td>0.652171</td>\n",
       "      <td>0.629829</td>\n",
       "      <td>0.665510</td>\n",
       "      <td>0.640806</td>\n",
       "      <td>0.647670</td>\n",
       "      <td>12.167879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71780</td>\n",
       "      <td>0.755425</td>\n",
       "      <td>0.657615</td>\n",
       "      <td>0.779992</td>\n",
       "      <td>0.703135</td>\n",
       "      <td>0.718803</td>\n",
       "      <td>9.746929</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.741978</td>\n",
       "      <td>0.672945</td>\n",
       "      <td>0.766875</td>\n",
       "      <td>0.705778</td>\n",
       "      <td>0.719910</td>\n",
       "      <td>9.670951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67520</td>\n",
       "      <td>0.661395</td>\n",
       "      <td>0.729580</td>\n",
       "      <td>0.619855</td>\n",
       "      <td>0.693816</td>\n",
       "      <td>0.674717</td>\n",
       "      <td>11.218345</td>\n",
       "      <td>0.676892</td>\n",
       "      <td>0.653113</td>\n",
       "      <td>0.752719</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.699387</td>\n",
       "      <td>0.676992</td>\n",
       "      <td>11.159904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72020</td>\n",
       "      <td>0.746460</td>\n",
       "      <td>0.671309</td>\n",
       "      <td>0.769602</td>\n",
       "      <td>0.706893</td>\n",
       "      <td>0.720456</td>\n",
       "      <td>9.664041</td>\n",
       "      <td>0.718215</td>\n",
       "      <td>0.736259</td>\n",
       "      <td>0.679110</td>\n",
       "      <td>0.757239</td>\n",
       "      <td>0.706531</td>\n",
       "      <td>0.718175</td>\n",
       "      <td>9.732593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.69800</td>\n",
       "      <td>0.718410</td>\n",
       "      <td>0.668888</td>\n",
       "      <td>0.727321</td>\n",
       "      <td>0.691213</td>\n",
       "      <td>0.698104</td>\n",
       "      <td>10.430818</td>\n",
       "      <td>0.696428</td>\n",
       "      <td>0.707701</td>\n",
       "      <td>0.676775</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.690130</td>\n",
       "      <td>0.696412</td>\n",
       "      <td>10.485130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67060</td>\n",
       "      <td>0.793684</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.883148</td>\n",
       "      <td>0.578665</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>11.377120</td>\n",
       "      <td>0.666985</td>\n",
       "      <td>0.790375</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>0.879526</td>\n",
       "      <td>0.577028</td>\n",
       "      <td>0.666952</td>\n",
       "      <td>11.501992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66180</td>\n",
       "      <td>0.641372</td>\n",
       "      <td>0.762951</td>\n",
       "      <td>0.556688</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.659820</td>\n",
       "      <td>11.681188</td>\n",
       "      <td>0.663754</td>\n",
       "      <td>0.633959</td>\n",
       "      <td>0.771577</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>0.696031</td>\n",
       "      <td>0.663982</td>\n",
       "      <td>11.613708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69340</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.660465</td>\n",
       "      <td>0.695178</td>\n",
       "      <td>10.589666</td>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.745791</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>0.797371</td>\n",
       "      <td>0.662990</td>\n",
       "      <td>0.697055</td>\n",
       "      <td>10.456829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46200</td>\n",
       "      <td>0.481530</td>\n",
       "      <td>0.868358</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.619519</td>\n",
       "      <td>0.458392</td>\n",
       "      <td>18.582239</td>\n",
       "      <td>0.458985</td>\n",
       "      <td>0.477269</td>\n",
       "      <td>0.876236</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.617952</td>\n",
       "      <td>0.459536</td>\n",
       "      <td>18.686393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65920</td>\n",
       "      <td>0.636333</td>\n",
       "      <td>0.751293</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.658719</td>\n",
       "      <td>11.770988</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>0.629263</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.553882</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>0.656338</td>\n",
       "      <td>11.873547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.62940</td>\n",
       "      <td>0.661648</td>\n",
       "      <td>0.684939</td>\n",
       "      <td>0.571597</td>\n",
       "      <td>0.648920</td>\n",
       "      <td>0.628268</td>\n",
       "      <td>12.800240</td>\n",
       "      <td>0.628640</td>\n",
       "      <td>0.655331</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.566001</td>\n",
       "      <td>0.648397</td>\n",
       "      <td>0.628773</td>\n",
       "      <td>12.826494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73200</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.654187</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.708061</td>\n",
       "      <td>0.731505</td>\n",
       "      <td>9.256469</td>\n",
       "      <td>0.719692</td>\n",
       "      <td>0.758315</td>\n",
       "      <td>0.644807</td>\n",
       "      <td>0.794555</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.719681</td>\n",
       "      <td>9.681567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71840</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.639717</td>\n",
       "      <td>0.800163</td>\n",
       "      <td>0.698372</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>9.726198</td>\n",
       "      <td>0.721292</td>\n",
       "      <td>0.763579</td>\n",
       "      <td>0.639357</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.695969</td>\n",
       "      <td>0.721119</td>\n",
       "      <td>9.626302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72720</td>\n",
       "      <td>0.773848</td>\n",
       "      <td>0.654467</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>0.709168</td>\n",
       "      <td>0.728413</td>\n",
       "      <td>9.422256</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.751721</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.785118</td>\n",
       "      <td>0.698944</td>\n",
       "      <td>0.719105</td>\n",
       "      <td>9.697512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.72880</td>\n",
       "      <td>0.763087</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.713803</td>\n",
       "      <td>0.729318</td>\n",
       "      <td>9.367000</td>\n",
       "      <td>0.715015</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.665958</td>\n",
       "      <td>0.763943</td>\n",
       "      <td>0.700036</td>\n",
       "      <td>0.714951</td>\n",
       "      <td>9.843114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72820</td>\n",
       "      <td>0.753292</td>\n",
       "      <td>0.682849</td>\n",
       "      <td>0.774025</td>\n",
       "      <td>0.716343</td>\n",
       "      <td>0.728437</td>\n",
       "      <td>9.387729</td>\n",
       "      <td>0.720754</td>\n",
       "      <td>0.736901</td>\n",
       "      <td>0.685764</td>\n",
       "      <td>0.755671</td>\n",
       "      <td>0.710413</td>\n",
       "      <td>0.720717</td>\n",
       "      <td>9.644918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.72692</td>\n",
       "      <td>0.766140</td>\n",
       "      <td>0.660344</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>0.709150</td>\n",
       "      <td>0.727523</td>\n",
       "      <td>9.431930</td>\n",
       "      <td>0.719197</td>\n",
       "      <td>0.749661</td>\n",
       "      <td>0.657796</td>\n",
       "      <td>0.780433</td>\n",
       "      <td>0.700466</td>\n",
       "      <td>0.719114</td>\n",
       "      <td>9.698683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81460</td>\n",
       "      <td>0.822627</td>\n",
       "      <td>0.799114</td>\n",
       "      <td>0.829889</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>0.814502</td>\n",
       "      <td>6.403558</td>\n",
       "      <td>0.728862</td>\n",
       "      <td>0.737048</td>\n",
       "      <td>0.711463</td>\n",
       "      <td>0.746254</td>\n",
       "      <td>0.724030</td>\n",
       "      <td>0.728859</td>\n",
       "      <td>9.364892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.81880</td>\n",
       "      <td>0.835102</td>\n",
       "      <td>0.802983</td>\n",
       "      <td>0.835237</td>\n",
       "      <td>0.818727</td>\n",
       "      <td>0.819110</td>\n",
       "      <td>6.258491</td>\n",
       "      <td>0.728554</td>\n",
       "      <td>0.735215</td>\n",
       "      <td>0.712590</td>\n",
       "      <td>0.744450</td>\n",
       "      <td>0.723725</td>\n",
       "      <td>0.728520</td>\n",
       "      <td>9.375520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.81860</td>\n",
       "      <td>0.844145</td>\n",
       "      <td>0.788666</td>\n",
       "      <td>0.849532</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.819099</td>\n",
       "      <td>6.265393</td>\n",
       "      <td>0.728754</td>\n",
       "      <td>0.735803</td>\n",
       "      <td>0.712189</td>\n",
       "      <td>0.745255</td>\n",
       "      <td>0.723804</td>\n",
       "      <td>0.728722</td>\n",
       "      <td>9.368612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.82800</td>\n",
       "      <td>0.845962</td>\n",
       "      <td>0.805710</td>\n",
       "      <td>0.850686</td>\n",
       "      <td>0.825345</td>\n",
       "      <td>0.828198</td>\n",
       "      <td>5.940729</td>\n",
       "      <td>0.726662</td>\n",
       "      <td>0.732569</td>\n",
       "      <td>0.712820</td>\n",
       "      <td>0.740466</td>\n",
       "      <td>0.722560</td>\n",
       "      <td>0.726643</td>\n",
       "      <td>9.440880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.81460</td>\n",
       "      <td>0.822883</td>\n",
       "      <td>0.804218</td>\n",
       "      <td>0.825090</td>\n",
       "      <td>0.813443</td>\n",
       "      <td>0.814654</td>\n",
       "      <td>6.403559</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.731742</td>\n",
       "      <td>0.721555</td>\n",
       "      <td>0.736030</td>\n",
       "      <td>0.726613</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>9.367022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.81892</td>\n",
       "      <td>0.834144</td>\n",
       "      <td>0.800138</td>\n",
       "      <td>0.838087</td>\n",
       "      <td>0.816736</td>\n",
       "      <td>0.819112</td>\n",
       "      <td>6.254346</td>\n",
       "      <td>0.728326</td>\n",
       "      <td>0.734475</td>\n",
       "      <td>0.714123</td>\n",
       "      <td>0.742491</td>\n",
       "      <td>0.724146</td>\n",
       "      <td>0.728307</td>\n",
       "      <td>9.383385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1         0.72720         0.760951      0.657407   \n",
       "1   cardio        tree     2         0.73080         0.735317      0.737049   \n",
       "2   cardio        tree     3         0.72760         0.773550      0.656041   \n",
       "3   cardio        tree     4         0.73720         0.768923      0.684774   \n",
       "4   cardio        tree     5         0.73500         0.787234      0.647831   \n",
       "5   cardio        tree   avg         0.73156         0.765195      0.676620   \n",
       "6   cardio     log_reg     1         0.72780         0.767000      0.649356   \n",
       "7   cardio     log_reg     2         0.64900         0.661771      0.636578   \n",
       "8   cardio     log_reg     3         0.71780         0.755425      0.657615   \n",
       "9   cardio     log_reg     4         0.67520         0.661395      0.729580   \n",
       "10  cardio     log_reg     5         0.72020         0.746460      0.671309   \n",
       "11  cardio     log_reg   avg         0.69800         0.718410      0.668888   \n",
       "12  cardio  perceptron     1         0.67060         0.793684      0.455314   \n",
       "13  cardio  perceptron     2         0.66180         0.641372      0.762951   \n",
       "14  cardio  perceptron     3         0.69340         0.755319      0.586777   \n",
       "15  cardio  perceptron     4         0.46200         0.481530      0.868358   \n",
       "16  cardio  perceptron     5         0.65920         0.636333      0.751293   \n",
       "17  cardio  perceptron   avg         0.62940         0.661648      0.684939   \n",
       "18  cardio         knn     1         0.73200         0.771605      0.654187   \n",
       "19  cardio         knn     2         0.71840         0.768868      0.639717   \n",
       "20  cardio         knn     3         0.72720         0.773848      0.654467   \n",
       "21  cardio         knn     4         0.72880         0.763087      0.670500   \n",
       "22  cardio         knn     5         0.72820         0.753292      0.682849   \n",
       "23  cardio         knn   avg         0.72692         0.766140      0.660344   \n",
       "24  cardio      forest     1         0.81460         0.822627      0.799114   \n",
       "25  cardio      forest     2         0.81880         0.835102      0.802983   \n",
       "26  cardio      forest     3         0.81860         0.844145      0.788666   \n",
       "27  cardio      forest     4         0.82800         0.845962      0.805710   \n",
       "28  cardio      forest     5         0.81460         0.822883      0.804218   \n",
       "29  cardio      forest   avg         0.81892         0.834144      0.800138   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.796105  0.705400   0.726756       9.422260       0.718092   \n",
       "1            0.724307  0.736182   0.730678       9.297947       0.716569   \n",
       "2            0.801545  0.709966   0.728793       9.408441       0.723985   \n",
       "3            0.790557  0.724413   0.737665       9.076873       0.724569   \n",
       "4            0.823080  0.710762   0.735456       9.152846       0.726877   \n",
       "5            0.787119  0.717344   0.731870       9.271673       0.722018   \n",
       "6            0.805246  0.703292   0.727301       9.401533       0.719323   \n",
       "7            0.661909  0.648930   0.649243      12.123243       0.647708   \n",
       "8            0.779992  0.703135   0.718803       9.746929       0.720000   \n",
       "9            0.619855  0.693816   0.674717      11.218345       0.676892   \n",
       "10           0.769602  0.706893   0.720456       9.664041       0.718215   \n",
       "11           0.727321  0.691213   0.698104      10.430818       0.696428   \n",
       "12           0.883148  0.578665   0.669231      11.377120       0.666985   \n",
       "13           0.556688  0.696899   0.659820      11.681188       0.663754   \n",
       "14           0.803579  0.660465   0.695178      10.589666       0.697246   \n",
       "15           0.048426  0.619519   0.458392      18.582239       0.458985   \n",
       "16           0.566144  0.689051   0.658719      11.770988       0.656231   \n",
       "17           0.571597  0.648920   0.628268      12.800240       0.628640   \n",
       "18           0.808824  0.708061   0.731505       9.256469       0.719692   \n",
       "19           0.800163  0.698372   0.719940       9.726198       0.721292   \n",
       "20           0.802359  0.709168   0.728413       9.422256       0.719231   \n",
       "21           0.788136  0.713803   0.729318       9.367000       0.715015   \n",
       "22           0.774025  0.716343   0.728437       9.387729       0.720754   \n",
       "23           0.794701  0.709150   0.727523       9.431930       0.719197   \n",
       "24           0.829889  0.810700   0.814502       6.403558       0.728862   \n",
       "25           0.835237  0.818727   0.819110       6.258491       0.728554   \n",
       "26           0.849532  0.815463   0.819099       6.265393       0.728754   \n",
       "27           0.850686  0.825345   0.828198       5.940729       0.726662   \n",
       "28           0.825090  0.813443   0.814654       6.403559       0.728800   \n",
       "29           0.838087  0.816736   0.819112       6.254346       0.728326   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.751375     0.651762          0.784402  0.698032  0.718082   \n",
       "1         0.713967     0.720638          0.712518  0.717287  0.716578   \n",
       "2         0.753861     0.663574          0.784166  0.705842  0.723870   \n",
       "3         0.741616     0.688172          0.760870  0.713895  0.724521   \n",
       "4         0.773141     0.641379          0.812196  0.701123  0.726788   \n",
       "5         0.746792     0.673105          0.770831  0.707236  0.721968   \n",
       "6         0.754983     0.649269          0.789355  0.698147  0.719312   \n",
       "7         0.652171     0.629829          0.665510  0.640806  0.647670   \n",
       "8         0.741978     0.672945          0.766875  0.705778  0.719910   \n",
       "9         0.653113     0.752719          0.601266  0.699387  0.676992   \n",
       "10        0.736259     0.679110          0.757239  0.706531  0.718175   \n",
       "11        0.707701     0.676775          0.716049  0.690130  0.696412   \n",
       "12        0.790375     0.454378          0.879526  0.577028  0.666952   \n",
       "13        0.633959     0.771577          0.556388  0.696031  0.663982   \n",
       "14        0.745791     0.596738          0.797371  0.662990  0.697055   \n",
       "15        0.477269     0.876236          0.042836  0.617952  0.459536   \n",
       "16        0.629263     0.758794          0.553882  0.687984  0.656338   \n",
       "17        0.655331     0.691545          0.566001  0.648397  0.628773   \n",
       "18        0.758315     0.644807          0.794555  0.696970  0.719681   \n",
       "19        0.763579     0.639357          0.802880  0.695969  0.721119   \n",
       "20        0.751721     0.653092          0.785118  0.698944  0.719105   \n",
       "21        0.737789     0.665958          0.763943  0.700036  0.714951   \n",
       "22        0.736901     0.685764          0.755671  0.710413  0.720717   \n",
       "23        0.749661     0.657796          0.780433  0.700466  0.719114   \n",
       "24        0.737048     0.711463          0.746254  0.724030  0.728859   \n",
       "25        0.735215     0.712590          0.744450  0.723725  0.728520   \n",
       "26        0.735803     0.712189          0.745255  0.723804  0.728722   \n",
       "27        0.732569     0.712820          0.740466  0.722560  0.726643   \n",
       "28        0.731742     0.721555          0.736030  0.726613  0.728792   \n",
       "29        0.734475     0.714123          0.742491  0.724146  0.728307   \n",
       "\n",
       "    test_logloss  \n",
       "0       9.736833  \n",
       "1       9.789467  \n",
       "2       9.533320  \n",
       "3       9.513137  \n",
       "4       9.433412  \n",
       "5       9.601234  \n",
       "6       9.694322  \n",
       "7      12.167879  \n",
       "8       9.670951  \n",
       "9      11.159904  \n",
       "10      9.732593  \n",
       "11     10.485130  \n",
       "12     11.501992  \n",
       "13     11.613708  \n",
       "14     10.456829  \n",
       "15     18.686393  \n",
       "16     11.873547  \n",
       "17     12.826494  \n",
       "18      9.681567  \n",
       "19      9.626302  \n",
       "20      9.697512  \n",
       "21      9.843114  \n",
       "22      9.644918  \n",
       "23      9.698683  \n",
       "24      9.364892  \n",
       "25      9.375520  \n",
       "26      9.368612  \n",
       "27      9.440880  \n",
       "28      9.367022  \n",
       "29      9.383385  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_results_no_svm = perform_trials('cardio', models_without_svm, cardio_X, cardio_y)\n",
    "cardio_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.4996 0.497     nan 0.7066 0.4992 0.5376    nan 0.7066 0.4996 0.7072\n",
      "    nan 0.7066 0.5032 0.71      nan 0.7066 0.498  0.7086    nan 0.7066\n",
      " 0.7098 0.7068    nan 0.7066 0.7068 0.7066    nan 0.7066 0.7064 0.7066\n",
      "    nan 0.7066 0.7066 0.7066    nan 0.7066 0.7066 0.7066    nan 0.7066\n",
      " 0.7066 0.7066    nan 0.7066 0.7066 0.7066    nan 0.7066 0.7066 0.7066\n",
      "    nan 0.7066]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.5056 0.5096    nan 0.6474 0.5096 0.509     nan 0.6474 0.5096 0.6106\n",
      "    nan 0.647  0.5096 0.6476    nan 0.6472 0.5094 0.6472    nan 0.6476\n",
      " 0.6324 0.6474    nan 0.6476 0.6478 0.6472    nan 0.6476 0.6472 0.6474\n",
      "    nan 0.6474 0.6476 0.647     nan 0.6474 0.6476 0.6478    nan 0.6468\n",
      " 0.6474 0.6476    nan 0.6476 0.6476 0.6474    nan 0.6474 0.647  0.6476\n",
      "    nan 0.6472]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.5014 0.5082    nan 0.6794 0.505  0.5078    nan 0.6792 0.5082 0.6406\n",
      "    nan 0.6794 0.5082 0.6804    nan 0.6798 0.5082 0.6804    nan 0.6798\n",
      " 0.6744 0.6798    nan 0.6798 0.6794 0.6802    nan 0.6794 0.6794 0.68\n",
      "    nan 0.68   0.6796 0.6796    nan 0.6798 0.6796 0.6802    nan 0.6796\n",
      " 0.6792 0.6798    nan 0.6802 0.6798 0.6796    nan 0.6802 0.6796 0.6802\n",
      "    nan 0.68  ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.5024 0.5044    nan 0.6594 0.5028 0.5058    nan 0.6594 0.5008 0.6502\n",
      "    nan 0.6592 0.5044 0.6602    nan 0.6596 0.5046 0.6594    nan 0.6598\n",
      " 0.6598 0.6596    nan 0.6596 0.6596 0.6596    nan 0.6598 0.6596 0.66\n",
      "    nan 0.6596 0.6596 0.6598    nan 0.6598 0.6596 0.6592    nan 0.6596\n",
      " 0.6596 0.66      nan 0.6596 0.6598 0.6596    nan 0.6592 0.6596 0.6598\n",
      "    nan 0.6598]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.501  0.5026    nan 0.6966 0.5002 0.5078    nan 0.6968 0.499  0.6796\n",
      "    nan 0.6966 0.5018 0.6964    nan 0.6966 0.5026 0.6966    nan 0.6966\n",
      " 0.6898 0.6966    nan 0.6966 0.6964 0.6968    nan 0.6966 0.6968 0.6966\n",
      "    nan 0.6966 0.6966 0.6966    nan 0.6968 0.6966 0.6966    nan 0.6968\n",
      " 0.6968 0.6966    nan 0.6966 0.6966 0.6966    nan 0.6966 0.6966 0.6968\n",
      "    nan 0.6968]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71200</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.785374</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.711527</td>\n",
       "      <td>9.947254</td>\n",
       "      <td>0.704323</td>\n",
       "      <td>0.737496</td>\n",
       "      <td>0.634344</td>\n",
       "      <td>0.774281</td>\n",
       "      <td>0.682042</td>\n",
       "      <td>0.704312</td>\n",
       "      <td>10.212409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64640</td>\n",
       "      <td>0.624125</td>\n",
       "      <td>0.769623</td>\n",
       "      <td>0.518352</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.643988</td>\n",
       "      <td>12.213100</td>\n",
       "      <td>0.644646</td>\n",
       "      <td>0.613317</td>\n",
       "      <td>0.778792</td>\n",
       "      <td>0.511069</td>\n",
       "      <td>0.686220</td>\n",
       "      <td>0.644930</td>\n",
       "      <td>12.273683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68080</td>\n",
       "      <td>0.676109</td>\n",
       "      <td>0.713892</td>\n",
       "      <td>0.646604</td>\n",
       "      <td>0.694487</td>\n",
       "      <td>0.680248</td>\n",
       "      <td>11.024916</td>\n",
       "      <td>0.686585</td>\n",
       "      <td>0.672717</td>\n",
       "      <td>0.724397</td>\n",
       "      <td>0.648916</td>\n",
       "      <td>0.697601</td>\n",
       "      <td>0.686657</td>\n",
       "      <td>10.825125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65160</td>\n",
       "      <td>0.649197</td>\n",
       "      <td>0.672879</td>\n",
       "      <td>0.629944</td>\n",
       "      <td>0.660826</td>\n",
       "      <td>0.651411</td>\n",
       "      <td>12.033456</td>\n",
       "      <td>0.660677</td>\n",
       "      <td>0.650499</td>\n",
       "      <td>0.692547</td>\n",
       "      <td>0.628891</td>\n",
       "      <td>0.670865</td>\n",
       "      <td>0.660719</td>\n",
       "      <td>11.719952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.69740</td>\n",
       "      <td>0.716638</td>\n",
       "      <td>0.658177</td>\n",
       "      <td>0.737033</td>\n",
       "      <td>0.686165</td>\n",
       "      <td>0.697605</td>\n",
       "      <td>10.451538</td>\n",
       "      <td>0.702138</td>\n",
       "      <td>0.713903</td>\n",
       "      <td>0.673597</td>\n",
       "      <td>0.730620</td>\n",
       "      <td>0.693165</td>\n",
       "      <td>0.702109</td>\n",
       "      <td>10.287881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.67764</td>\n",
       "      <td>0.682366</td>\n",
       "      <td>0.690451</td>\n",
       "      <td>0.663461</td>\n",
       "      <td>0.683651</td>\n",
       "      <td>0.676956</td>\n",
       "      <td>11.134053</td>\n",
       "      <td>0.679674</td>\n",
       "      <td>0.677586</td>\n",
       "      <td>0.700735</td>\n",
       "      <td>0.658755</td>\n",
       "      <td>0.685978</td>\n",
       "      <td>0.679745</td>\n",
       "      <td>11.063810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset    model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  cardio  log_reg     1         0.71200         0.745763      0.637681   \n",
       "1  cardio  log_reg     2         0.64640         0.624125      0.769623   \n",
       "2  cardio  log_reg     3         0.68080         0.676109      0.713892   \n",
       "3  cardio  log_reg     4         0.65160         0.649197      0.672879   \n",
       "4  cardio  log_reg     5         0.69740         0.716638      0.658177   \n",
       "5  cardio  log_reg   avg         0.67764         0.682366      0.690451   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0           0.785374  0.687500   0.711527       9.947254       0.704323   \n",
       "1           0.518352  0.689279   0.643988      12.213100       0.644646   \n",
       "2           0.646604  0.694487   0.680248      11.024916       0.686585   \n",
       "3           0.629944  0.660826   0.651411      12.033456       0.660677   \n",
       "4           0.737033  0.686165   0.697605      10.451538       0.702138   \n",
       "5           0.663461  0.683651   0.676956      11.134053       0.679674   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.737496     0.634344          0.774281  0.682042  0.704312   \n",
       "1        0.613317     0.778792          0.511069  0.686220  0.644930   \n",
       "2        0.672717     0.724397          0.648916  0.697601  0.686657   \n",
       "3        0.650499     0.692547          0.628891  0.670865  0.660719   \n",
       "4        0.713903     0.673597          0.730620  0.693165  0.702109   \n",
       "5        0.677586     0.700735          0.658755  0.685978  0.679745   \n",
       "\n",
       "   test_logloss  \n",
       "0     10.212409  \n",
       "1     12.273683  \n",
       "2     10.825125  \n",
       "3     11.719952  \n",
       "4     10.287881  \n",
       "5     11.063810  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_trials('cardio', models_without_svm, cardio_X, cardio_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
